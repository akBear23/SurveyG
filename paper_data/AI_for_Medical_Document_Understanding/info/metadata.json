{
    "9b90291103892b9f9665c11461d7bc9ea40ea9ec.pdf": {
        "title": "MONAI: An open-source framework for deep learning in healthcare",
        "authors": [
            "M. Cardoso",
            "Wenqi Li",
            "Richard Brown",
            "Nic Ma",
            "E. Kerfoot",
            "Yiheng Wang",
            "Benjamin Murrey",
            "A. Myronenko",
            "Can Zhao",
            "Dong Yang",
            "V. Nath",
            "Yufan He",
            "Ziyue Xu",
            "Ali Hatamizadeh",
            "Wenjie Zhu",
            "Yun Liu",
            "Mingxin Zheng",
            "Yucheng Tang",
            "Isaac Yang",
            "Michael Zephyr",
            "Behrooz Hashemian",
            "Sachidanand Alle",
            "Mohammad Zalbagi Darestani",
            "C. Budd",
            "M. Modat",
            "Tom Kamiel Magda Vercauteren",
            "Guotai Wang",
            "Yiwen Li",
            "Yipeng Hu",
            "Yunguan Fu",
            "Benjamin L. Gorman",
            "Hans J. Johnson",
            "Brad W. Genereaux",
            "B. S. Erdal",
            "Vikash Gupta",
            "A. Diaz-Pinto",
            "Andre Dourson",
            "L. Maier-Hein",
            "P. Jaeger",
            "M. Baumgartner",
            "Jayashree Kalpathy-Cramer",
            "Mona G. Flores",
            "J. Kirby",
            "L. Cooper",
            "H. Roth",
            "Daguang Xu",
            "David Bericat",
            "R. Floca",
            "S. K. Zhou",
            "Haris Shuaib",
            "K. Farahani",
            "K. Maier-Hein",
            "S. Aylward",
            "Prerna Dogra",
            "S. Ourselin",
            "Andrew Feng"
        ],
        "published_date": "2022",
        "abstract": "Artificial Intelligence (AI) is having a tremendous impact across most areas of science. Applications of AI in healthcare have the potential to improve our ability to detect, diagnose, prognose, and intervene on human disease. For AI models to be used clinically, they need to be made safe, reproducible and robust, and the underlying software framework must be aware of the particularities (e.g. geometry, physiology, physics) of medical data being processed. This work introduces MONAI, a freely available, community-supported, and consortium-led PyTorch-based framework for deep learning in healthcare. MONAI extends PyTorch to support medical data, with a particular focus on imaging, and provide purpose-specific AI model architectures, transformations and utilities that streamline the development and deployment of medical AI models. MONAI follows best practices for software-development, providing an easy-to-use, robust, well-documented, and well-tested software framework. MONAI preserves the simple, additive, and compositional approach of its underlying PyTorch libraries. MONAI is being used by and receiving contributions from research, clinical and industrial teams from around the world, who are pursuing applications spanning nearly every aspect of healthcare.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/9b90291103892b9f9665c11461d7bc9ea40ea9ec.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "69d49a06f09cf934310ccbf3bb2a360fa719272d.pdf": {
        "title": "Common pitfalls and recommendations for using machine learning to detect and prognosticate for COVID-19 using chest radiographs and CT scans",
        "authors": [
            "M. Roberts",
            "D. Driggs",
            "Matthew Thorpe",
            "J. Gilbey",
            "Michael Yeung",
            "S. Ursprung",
            "Angelica I. Avil\u00e9s-Rivero",
            "Christian Etmann",
            "C. McCague",
            "L. Beer",
            "J. Weir-McCall",
            "Z. Teng",
            "E. Gkrania-Klotsas",
            "Alessandro Anna Emily Emmanuel Georg Ghassem Guang Helmut Jac Ruggiero Korhonen Jefferson Ako Langs Gozaliasl Ya",
            "A. Ruggiero",
            "A. Korhonen",
            "E. Jefferson",
            "E. Ako",
            "G. Langs",
            "G. Gozaliasl",
            "Guang Yang",
            "H. Prosch",
            "J. Preller",
            "Jan Stanczuk",
            "Jingjing Tang",
            "J. Hofmanninger",
            "J. Babar",
            "L. E. Sanchez",
            "M. Thillai",
            "Paula Martin Gonzalez",
            "P. Teare",
            "Xiaoxiang Zhu",
            "Mishal N. Patel",
            "Conor Cafolla",
            "Hojjat Azadbakht",
            "Joseph Jacob",
            "Josh Lowe",
            "Kang Zhang",
            "Kyle Bradley",
            "Marcel Wassin",
            "Markus Holzer",
            "Kangyu Ji",
            "Maria Delgado Ortet",
            "T. Ai",
            "N. Walton",
            "P. Li\u00f2",
            "S. Stranks",
            "Tolou Shadbahr",
            "Weizhe Lin",
            "Y. Zha",
            "Zhangming Niu",
            "J. H. Rudd",
            "E. Sala",
            "C. Sch\u00f6nlieb"
        ],
        "published_date": "2020",
        "abstract": "Machine learning methods offer great promise for fast and accurate detection and prognostication of coronavirus disease 2019 (COVID-19) from standard-of-care chest radiographs (CXR) and chest computed tomography (CT) images. Many articles have been published in 2020 describing new machine learning-based models for both of these tasks, but it is unclear which are of potential clinical utility. In this systematic review, we consider all published papers and preprints, for the period from 1 January 2020 to 3 October 2020, which describe new machine learning models for the diagnosis or prognosis of COVID-19 from CXR or CT images. All manuscripts uploaded to bioRxiv, medRxiv and arXiv along with all entries in EMBASE and MEDLINE in this timeframe are considered. Our search identified 2,212 studies, of which 415 were included after initial screening and, after quality screening, 62 studies were included in this systematic review. Our review finds that none of the models identified are of potential clinical use due to methodological flaws and/or underlying biases. This is a major weakness, given the urgency with which validated COVID-19 models are needed. To address this, we give many recommendations which, if followed, will solve these issues and lead to higher-quality model development and well-documented manuscripts. Many machine learning-based approaches have been developed for the prognosis and diagnosis of COVID-19 from medical images and this Analysis identifies over 2,200 relevant published papers and preprints in this area. After initial screening, 62 studies are analysed and the authors find they all have methodological flaws standing in the way of clinical utility. The authors have several recommendations to address these issues.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/69d49a06f09cf934310ccbf3bb2a360fa719272d.pdf",
        "venue": "Nature Machine Intelligence",
        "citationCount": 0,
        "score": 0
    },
    "47f7e6326f7ee042966130f673743abbb99b8a7f.pdf": {
        "title": "AI in Medical Imaging Informatics: Current Challenges and Future Directions",
        "authors": [
            "A. Panayides",
            "A. Amini",
            "N. Filipovic",
            "Ashish Sharma",
            "S. Tsaftaris",
            "A. Young",
            "D. Foran",
            "N. Do",
            "S. Golemati",
            "T. Kur\u00e7",
            "Kun Huang",
            "K. Nikita",
            "B. Veasey",
            "M. Zervakis",
            "J. Saltz",
            "C. Pattichis"
        ],
        "published_date": "2020",
        "abstract": "This paper reviews state-of-the-art research solutions across the spectrum of medical imaging informatics, discusses clinical translation, and provides future directions for advancing clinical practice. More specifically, it summarizes advances in medical imaging acquisition technologies for different modalities, highlighting the necessity for efficient medical data management strategies in the context of AI in big healthcare data analytics. It then provides a synopsis of contemporary and emerging algorithmic methods for disease classification and organ/ tissue segmentation, focusing on AI and deep learning architectures that have already become the de facto approach. The clinical benefits of in-silico modelling advances linked with evolving 3D reconstruction and visualization applications are further documented. Concluding, integrative analytics approaches driven by associate research branches highlighted in this study promise to revolutionize imaging informatics as known today across the healthcare continuum for both radiology and digital pathology applications. The latter, is projected to enable informed, more accurate diagnosis, timely prognosis, and effective treatment planning, underpinning precision medicine.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/47f7e6326f7ee042966130f673743abbb99b8a7f.pdf",
        "venue": "IEEE journal of biomedical and health informatics",
        "citationCount": 0,
        "score": 0
    },
    "e4599e4561888b1406a521dec5ba37275e83e727.pdf": {
        "title": "Machine learning based approaches for detecting COVID-19 using clinical text data",
        "authors": [
            "A. Khanday",
            "Syed Tanzeel Rabani",
            "Q. Khan",
            "N. Rouf",
            "Masarat Mohi Ud Din"
        ],
        "published_date": "2020",
        "abstract": "Technology advancements have a rapid effect on every field of life, be it medical field or any other field. Artificial intelligence has shown the promising results in health care through its decision making by analysing the data. COVID-19 has affected more than 100 countries in a matter of no time. People all over the world are vulnerable to its consequences in future. It is imperative to develop a control system that will detect the coronavirus. One of the solution to control the current havoc can be the diagnosis of disease with the help of various AI tools. In this paper, we classified textual clinical reports into four classes by using classical and ensemble machine learning algorithms. Feature engineering was performed using techniques like Term frequency/inverse document frequency (TF/IDF), Bag of words (BOW) and report length. These features were supplied to traditional and ensemble machine learning classifiers. Logistic regression and Multinomial Na\u00efve Bayes showed better results than other ML algorithms by having 96.2% testing accuracy. In future recurrent neural network can be used for better accuracy.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/e4599e4561888b1406a521dec5ba37275e83e727.pdf",
        "venue": "International journal of information technology",
        "citationCount": 0,
        "score": 0
    },
    "f106ef1bad05ed38011cbd711d7c397080023b86.pdf": {
        "title": "Beware explanations from AI in health care",
        "authors": [
            "Boris Babic",
            "S. Gerke",
            "T. Evgeniou",
            "I. Cohen"
        ],
        "published_date": "2021",
        "abstract": "The benefits of explainable artificial intelligence are not what they appear Artificial intelligence and machine learning (AI/ML) algorithms are increasingly developed in health care for diagnosis and treatment of a variety of medical conditions (1). However, despite the technical prowess of such systems, their adoption has been challenging, and whether and how much they will actually improve health care remains to be seen. A central reason for this is that the effectiveness of AI/ML-based medical devices depends largely on the behavioral characteristics of its users, who, for example, are often vulnerable to well-documented biases or algorithmic aversion (2). Many stakeholders increasingly identify the so-called black-box nature of predictive algorithms as the core source of users' skepticism, lack of trust, and slow uptake (3, 4). As a result, lawmakers have been moving in the direction of requiring the availability of explanations for black-box algorithmic decisions (5). Indeed, a near-consensus is emerging in favor of explainable AI/ML among academics, governments, and civil society groups. Many are drawn to this approach to harness the accuracy benefits of noninterpretable AI/ML such as deep learning or neural nets while also supporting transparency, trust, and adoption. We argue that this consensus, at least as applied to health care, both overstates the benefits and undercounts the drawbacks of requiring black-box algorithms to be explainable.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/f106ef1bad05ed38011cbd711d7c397080023b86.pdf",
        "venue": "Science",
        "citationCount": 0,
        "score": 0
    },
    "1bfc69cd9a06be740ea6a0f421e0852a90856220.pdf": {
        "title": "Experimental evidence of effective human\u2013AI collaboration in medical decision-making",
        "authors": [
            "C. Reverberi",
            "T. Rigon",
            "A. Solari",
            "C. Hassan",
            "P. Cherubini",
            "Giulio Halim Sebastian Sabela M\u00e1rio Agn\u00e8s Gl\u00f2ria Fern\u00e1nde Antonelli Awadie Bernhofer Carballal Dinis-Ribeiro",
            "G. Antonelli",
            "H. Awadie",
            "Sebastian Bernhofer",
            "S. Carballal",
            "M. Dinis-Ribeiro",
            "Agn\u00e8s Fern\u00e1ndez-Clotett",
            "G. F. Esparrach",
            "I. Gralnek",
            "Yuta Higasa",
            "Takuro Hirabayashi",
            "Tatsuki Hirai",
            "Mineo Iwatate",
            "Miki Kawano",
            "Markus Mader",
            "A. Maieron",
            "Sebastian Mattes",
            "Tastuya Nakai",
            "I. Ord\u00e1s",
            "R. Ortig\u00e3o",
            "Oswaldo Ortiz Z\u00fa\u00f1iga",
            "M. Pellis\u00e9",
            "C. Pinto",
            "F. Riedl",
            "Ariadna S\u00e1nchez",
            "E. Steiner",
            "Yukari Tanaka",
            "Andrea Cherubini"
        ],
        "published_date": "2022",
        "abstract": "Artificial Intelligence (ai) systems are precious support for decision-making, with many applications also in the medical domain. The interaction between mds and ai enjoys a renewed interest following the increased possibilities of deep learning devices. However, we still have limited evidence-based knowledge of the context, design, and psychological mechanisms that craft an optimal human\u2013ai collaboration. In this multicentric study, 21 endoscopists reviewed 504 videos of lesions prospectively acquired from real colonoscopies. They were asked to provide an optical diagnosis with and without the assistance of an ai support system. Endoscopists were influenced by ai (OR=3.05\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$\\textsc {or}=3.05$$\\end{document}), but not erratically: they followed the ai advice more when it was correct (OR=3.48\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$\\textsc {or}=3.48$$\\end{document}) than incorrect (OR=1.85\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$\\textsc {or}=1.85$$\\end{document}). Endoscopists achieved this outcome through a weighted integration of their and the ai opinions, considering the case-by-case estimations of the two reliabilities. This Bayesian-like rational behavior allowed the human\u2013ai hybrid team to outperform both agents taken alone. We discuss the features of the human\u2013ai interaction that determined this favorable outcome.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/1bfc69cd9a06be740ea6a0f421e0852a90856220.pdf",
        "venue": "Scientific Reports",
        "citationCount": 0,
        "score": 0
    },
    "f079d2c49646735ffe09e4117b075f4e900f4420.pdf": {
        "title": "Developing, implementing and governing artificial intelligence in medicine: a step-by-step approach to prevent an artificial intelligence winter",
        "authors": [
            "Davy van de Sande",
            "M. V. van Genderen",
            "J. M. Smit",
            "Joost Huiskens",
            "J. J. Visser",
            "Robert E. R. Veen",
            "E. van Unen",
            "Oliver Hilgers Ba",
            "D. Gommers",
            "J. Bommel"
        ],
        "published_date": "2022",
        "abstract": "Objective Although the role of artificial intelligence (AI) in medicine is increasingly studied, most patients do not benefit because the majority of AI models remain in the testing and prototyping environment. The development and implementation trajectory of clinical AI models are complex and a structured overview is missing. We therefore propose a step-by-step overview to enhance clinicians\u2019 understanding and to promote quality of medical AI research. Methods We summarised key elements (such as current guidelines, challenges, regulatory documents and good practices) that are needed to develop and safely implement AI in medicine. Conclusion This overview complements other frameworks in a way that it is accessible to stakeholders without prior AI knowledge and as such provides a step-by-step approach incorporating all the key elements and current guidelines that are essential for implementation, and can thereby help to move AI from bytes to bedside.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/f079d2c49646735ffe09e4117b075f4e900f4420.pdf",
        "venue": "BMJ Health & Care Informatics",
        "citationCount": 0,
        "score": 0
    },
    "216fd02c57bce4f280134c2bf166447d5ad1e97e.pdf": {
        "title": "Guidelines for Artificial Intelligence in Medicine: Literature Review and Content Analysis of Frameworks",
        "authors": [
            "Norah L. Crossnohere",
            "Mohamed I. Elsaid",
            "J. Paskett",
            "S. Bose-Brill",
            "John F. P. Bridges"
        ],
        "published_date": "2022",
        "abstract": "Background Artificial intelligence (AI) is rapidly expanding in medicine despite a lack of consensus on its application and evaluation. Objective We sought to identify current frameworks guiding the application and evaluation of AI for predictive analytics in medicine and to describe the content of these frameworks. We also assessed what stages along the AI translational spectrum (ie, AI development, reporting, evaluation, implementation, and surveillance) the content of each framework has been discussed. Methods We performed a literature review of frameworks regarding the oversight of AI in medicine. The search included key topics such as \u201cartificial intelligence,\u201d \u201cmachine learning,\u201d \u201cguidance as topic,\u201d and \u201ctranslational science,\u201d and spanned the time period 2014-2022. Documents were included if they provided generalizable guidance regarding the use or evaluation of AI in medicine. Included frameworks are summarized descriptively and were subjected to content analysis. A novel evaluation matrix was developed and applied to appraise the frameworks\u2019 coverage of content areas across translational stages. Results Fourteen frameworks are featured in the review, including six frameworks that provide descriptive guidance and eight that provide reporting checklists for medical applications of AI. Content analysis revealed five considerations related to the oversight of AI in medicine across frameworks: transparency, reproducibility, ethics, effectiveness, and engagement. All frameworks include discussions regarding transparency, reproducibility, ethics, and effectiveness, while only half of the frameworks discuss engagement. The evaluation matrix revealed that frameworks were most likely to report AI considerations for the translational stage of development and were least likely to report considerations for the translational stage of surveillance. Conclusions Existing frameworks for the application and evaluation of AI in medicine notably offer less input on the role of engagement in oversight and regarding the translational stage of surveillance. Identifying and optimizing strategies for engagement are essential to ensure that AI can meaningfully benefit patients and other end users.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/216fd02c57bce4f280134c2bf166447d5ad1e97e.pdf",
        "venue": "Journal of Medical Internet Research",
        "citationCount": 0,
        "score": 0
    },
    "9d53177352bd6019f42ec1a7b32feff353b7bd3f.pdf": {
        "title": "Acupuncture for Chronic Severe Functional Constipation",
        "authors": [
            "Zhishun Liu",
            "Shiyan Yan",
            "Jiani Wu",
            "Liyun He",
            "Ning Li",
            "Guirong Dong",
            "J. Fang",
            "W. Fu",
            "Lixin Fu",
            "Jianhua Sun",
            "Linpeng Wang",
            "Shun Wang",
            "Jun Yang",
            "Hongxing Zhang",
            "Jianbin Zhang",
            "Jiping Zhao",
            "W. Zhou",
            "Zhongyu Zhou",
            "Yanke Ai",
            "Kehua Zhou",
            "Jia Liu",
            "Huanfang Xu",
            "Yuying Cai",
            "Baoyan Liu"
        ],
        "published_date": "2016",
        "abstract": "",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/9d53177352bd6019f42ec1a7b32feff353b7bd3f.pdf",
        "venue": "Annals of Internal Medicine",
        "citationCount": 0,
        "score": 0
    },
    "3b0dbd77778d22e332a9618b321b425cec96a0b5.pdf": {
        "title": "Utilization of Self-Diagnosis Health Chatbots in Real-World Settings: Case Study",
        "authors": [
            "Xiang-hong Fan",
            "Daren Chao",
            "Zhan Zhang",
            "Dakuo Wang",
            "Xiaohua Li",
            "Feng Tian"
        ],
        "published_date": "2020",
        "abstract": "Background Artificial intelligence (AI)-driven chatbots are increasingly being used in health care, but most chatbots are designed for a specific population and evaluated in controlled settings. There is little research documenting how health consumers (eg, patients and caregivers) use chatbots for self-diagnosis purposes in real-world scenarios. Objective The aim of this research was to understand how health chatbots are used in a real-world context, what issues and barriers exist in their usage, and how the user experience of this novel technology can be improved. Methods We employed a data-driven approach to analyze the system log of a widely deployed self-diagnosis chatbot in China. Our data set consisted of 47,684 consultation sessions initiated by 16,519 users over 6 months. The log data included a variety of information, including users\u2019 nonidentifiable demographic information, consultation details, diagnostic reports, and user feedback. We conducted both statistical analysis and content analysis on this heterogeneous data set. Results The chatbot users spanned all age groups, including middle-aged and older adults. Users consulted the chatbot on a wide range of medical conditions, including those that often entail considerable privacy and social stigma issues. Furthermore, we distilled 2 prominent issues in the use of the chatbot: (1) a considerable number of users dropped out in the middle of their consultation sessions, and (2) some users pretended to have health concerns and used the chatbot for nontherapeutic purposes. Finally, we identified a set of user concerns regarding the use of the chatbot, including insufficient actionable information and perceived inaccurate diagnostic suggestions. Conclusions Although health chatbots are considered to be convenient tools for enhancing patient-centered care, there are issues and barriers impeding the optimal use of this novel technology. Designers and developers should employ user-centered approaches to address the issues and user concerns to achieve the best uptake and utilization. We conclude the paper by discussing several design implications, including making the chatbots more informative, easy-to-use, and trustworthy, as well as improving the onboarding experience to enhance user engagement.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/3b0dbd77778d22e332a9618b321b425cec96a0b5.pdf",
        "venue": "Journal of Medical Internet Research",
        "citationCount": 0,
        "score": 0
    },
    "06773aeb019c078fcda6a20e7bd1afc27aaf07dc.pdf": {
        "title": "COVID-19 Mortality Among American Indian and Alaska Native Persons \u2014 14 States, January\u2013June 2020",
        "authors": [
            "Jessica Arrazola",
            "Matthew M Masiello",
            "Sujata Joshi",
            "Adrian E Dominguez",
            "Amy J. Poel",
            "C. Wilkie",
            "J. Bressler",
            "J. Mclaughlin",
            "J. Kraszewski",
            "K. Komatsu",
            "Xandy Peterson Pompa",
            "Megan Jespersen",
            "Gillian Richardson",
            "N. Lehnertz",
            "Pamela Lemaster",
            "Britney Rust",
            "Alison Keyser Metobo",
            "B. Doman",
            "David Casey",
            "Jessica Kumar",
            "Alyssa L Rowell",
            "T. Miller",
            "Mike Mannell",
            "Ozair H Naqvi",
            "A. Wendelboe",
            "R. Leman",
            "J. Clayton",
            "Bree Barbeau",
            "Samantha K Rice",
            "V. Warren-Mears",
            "Abigail Echo-Hawk",
            "Andria Apostolou",
            "M. Landen"
        ],
        "published_date": "2020",
        "abstract": "American Indian/Alaska Native (AI/AN) persons experienced disproportionate mortality during the 2009 influenza A(H1N1) pandemic (1,2). Concerns of a similar trend during the coronavirus disease 2019 (COVID-19) pandemic led to the formation of a workgroup* to assess the prevalence of COVID-19 deaths in the AI/AN population. As of December 2, 2020, CDC has reported 2,689 COVID-19-associated deaths among non-Hispanic AI/AN persons in the United States.\u2020 A recent analysis found that the cumulative incidence of laboratory-confirmed COVID-19 cases among AI/AN persons was 3.5 times that among White persons (3). Among 14 participating states, the age-adjusted AI/AN COVID-19 mortality rate (55.8 deaths per 100,000; 95% confidence interval [CI] =\u00a052.5-59.3) was 1.8 (95% CI =\u00a01.7-2.0) times that among White persons (30.3 deaths per 100,000; 95% CI =\u00a029.9-30.7). Although COVID-19 mortality rates increased with age among both AI/AN and White persons, the disparity was largest among those aged 20-49 years. Among persons aged 20-29 years, 30-39 years, and 40-49 years, the COVID-19 mortality rates among AI/AN were 10.5, 11.6, and 8.2 times, respectively, those among White persons. Evidence that AI/AN communities might be at increased risk for COVID-19 illness and death demonstrates the importance of documenting and understanding the reasons for these disparities while developing collaborative approaches with federal, state, municipal, and tribal agencies to minimize the impact of COVID-19 on AI/AN communities. Together, public health partners can plan for medical countermeasures and prevention activities for AI/AN communities.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/06773aeb019c078fcda6a20e7bd1afc27aaf07dc.pdf",
        "venue": "MMWR. Morbidity and mortality weekly report",
        "citationCount": 0,
        "score": 0
    },
    "1e3e86fe20ab0fc072855ce1e405560d0bdca7b8.pdf": {
        "title": "Predicting Mortality Risk in Patients with COVID-19 Using Artificial Intelligence to Help Medical Decision-Making",
        "authors": [
            "M. Pourhomayoun",
            "Mahdi Shakibi"
        ],
        "published_date": "2020",
        "abstract": "In the wake of COVID-19 disease, caused by the SARS-CoV-2 virus, we designed and developed a predictive model based on Artificial Intelligence (AI) and Machine Learning algorithms to determine the health risk and predict the mortality risk of patients with COVID-19. In this study, we used documented data of 117,000 patients world-wide with laboratory-confirmed COVID-19. This study proposes an AI model to help hospitals and medical facilities decide who needs to get attention first, who has higher priority to be hospitalized, triage patients when the system is overwhelmed by overcrowding, and eliminate delays in providing the necessary care. The results demonstrate 93% overall accuracy in predicting the mortality rate. We used several machine learning algorithms including Support Vector Machine (SVM), Artificial Neural Networks, Random Forest, Decision Tree, Logistic Regression, and K-Nearest Neighbor (KNN) to predict the mortality rate in patients with COVID-19. In this study, the most alarming symptoms and features were also identified. Finally, we used a separate dataset of COVID-19 patients to evaluate our developed model accuracy, and used confusion matrix to make an in-depth analysis of our classifiers and calculate the sensitivity and specificity of our model.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/1e3e86fe20ab0fc072855ce1e405560d0bdca7b8.pdf",
        "venue": "medRxiv",
        "citationCount": 0,
        "score": 0
    },
    "9381bd3acdbda98aa1a9b549c729e2601e16cd41.pdf": {
        "title": "Overview of Automatic Clinical Coding: Annotations, Guidelines, and Solutions for non-English Clinical Cases at CodiEsp Track of CLEF eHealth 2020",
        "authors": [
            "Antonio Miranda-Escalada",
            "Aitor Gonzalez-Agirre",
            "Jordi Armengol-Estap\u00e9",
            "Martin Krallinger"
        ],
        "published_date": "2020",
        "abstract": "",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/9381bd3acdbda98aa1a9b549c729e2601e16cd41.pdf",
        "venue": "Conference and Labs of the Evaluation Forum",
        "citationCount": 0,
        "score": 0
    },
    "6ab6e6f62323132e299fc6717ad0f5ca000414d5.pdf": {
        "title": "Natural language processing in clinical neuroscience and psychiatry: A review",
        "authors": [
            "C. Crema",
            "Giuseppe Attardi",
            "Daniele Sartiano",
            "A. Redolfi"
        ],
        "published_date": "2022",
        "abstract": "Natural language processing (NLP) is rapidly becoming an important topic in the medical community. The ability to automatically analyze any type of medical document could be the key factor to fully exploit the data it contains. Cutting-edge artificial intelligence (AI) architectures, particularly machine learning and deep learning, have begun to be applied to this topic and have yielded promising results. We conducted a literature search for 1,024 papers that used NLP technology in neuroscience and psychiatry from 2010 to early 2022. After a selection process, 115 papers were evaluated. Each publication was classified into one of three categories: information extraction, classification, and data inference. Automated understanding of clinical reports in electronic health records has the potential to improve healthcare delivery. Overall, the performance of NLP applications is high, with an average F1-score and AUC above 85%. We also derived a composite measure in the form of Z-scores to better compare the performance of NLP models and their different classes as a whole. No statistical differences were found in the unbiased comparison. Strong asymmetry between English and non-English models, difficulty in obtaining high-quality annotated data, and train biases causing low generalizability are the main limitations. This review suggests that NLP could be an effective tool to help clinicians gain insights from medical reports, clinical research forms, and more, making NLP an effective tool to improve the quality of healthcare services.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/6ab6e6f62323132e299fc6717ad0f5ca000414d5.pdf",
        "venue": "Frontiers in Psychiatry",
        "citationCount": 0,
        "score": 0
    },
    "a63d98ba89060ded321bfe482f69c7edd33953dd.pdf": {
        "title": "Explainable machine learning practices: opening another black box for reliable medical AI",
        "authors": [
            "E. Ratti",
            "Mark Graves"
        ],
        "published_date": "2022",
        "abstract": "In the past few years, machine learning (ML) tools have been implemented with success in the medical context. However, several practitioners have raised concerns about the lack of transparency\u2014at the algorithmic level\u2014of many of these tools; and solutions from the field of explainable AI (XAI) have been seen as a way to open the \u2018black box\u2019 and make the tools more trustworthy. Recently, Alex London has argued that in the medical context we do not need machine learning tools to be interpretable at the algorithmic level to make them trustworthy, as long as they meet some strict empirical desiderata. In this paper, we analyse and develop London\u2019s position. In particular, we make two claims. First, we claim that London\u2019s solution to the problem of trust can potentially address another problem, which is how to evaluate the reliability of ML tools in medicine for regulatory purposes. Second, we claim that to deal with this problem, we need to develop London\u2019s views by shifting the focus from the opacity of algorithmic details to the opacity of the way in which ML tools are trained and built. We claim that to regulate AI tools and evaluate their reliability, agencies need an explanation of how ML tools have been built, which requires documenting and justifying the technical choices that practitioners have made in designing such tools. This is because different algorithmic designs may lead to different outcomes, and to the realization of different purposes. However, given that technical choices underlying algorithmic design are shaped by value-laden considerations, opening the black box of the design process means also making transparent and\u00a0motivating (technical and ethical) values and preferences behind such choices. Using tools from philosophy of technology and philosophy of science, we elaborate a framework showing how an explanation of the training processes of ML tools in medicine should look like.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/a63d98ba89060ded321bfe482f69c7edd33953dd.pdf",
        "venue": "AI and Ethics",
        "citationCount": 0,
        "score": 0
    },
    "253b7d3ebd12adb21ad4ad7a79b2d9084edc0565.pdf": {
        "title": "Overview of DisTEMIST at BioASQ: Automatic detection and normalization of diseases from clinical texts: results, methods, evaluation and multilingual resources",
        "authors": [
            "Antonio Miranda-Escalada",
            "Luis Gasco",
            "Salvador Lima-L\u00f3pez",
            "Eul\u00e0lia Farr\u00e9-Maduell",
            "D. Estrada",
            "A. Nentidis",
            "Anastasia Krithara",
            "Georgios Katsimpras",
            "G. Paliouras",
            "Martin Krallinger"
        ],
        "published_date": "2022",
        "abstract": "",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/253b7d3ebd12adb21ad4ad7a79b2d9084edc0565.pdf",
        "venue": "Conference and Labs of the Evaluation Forum",
        "citationCount": 0,
        "score": 0
    },
    "982c80d77d9ee37abfc357b5929dcec8c059e7a7.pdf": {
        "title": "Process Knowledge-Infused AI: Toward User-Level Explainability, Interpretability, and Safety",
        "authors": [
            "Amit P. Sheth",
            "Manas Gaur",
            "Kaushik Roy",
            "Revathy Venkataraman",
            "Vedant Khandelwal",
            "Amit P. Sheth"
        ],
        "published_date": "2022",
        "abstract": "AI has seen wide adoption for automating tasks in several domains. However, AI's use in high-value, sensitive, or safety-critical applications such as self-management for personalized health or personalized nutrition has been challenging. These require that the AI system follows guidelines or well-defined processes set by experts, community, or standards. We characterize these as process knowledge (PK). For example, to diagnose the severity of depression, the AI system should incorporate PK that is part of the clinical decision-making process, such as the Patient Health Questionnaire (PHQ-9). Likewise, a nutritionist's knowledge and dietary guidelines are needed to create food plans for diabetic patients. Furthermore, the BlackBox nature of purely data-reliant statistical AI systems falls short in providing user-understandable explanations, such as what a clinician would need to ensure and document compliance with medical guidelines before relying on a recommendation. Using the examples of mental health and cooking recipes for diabetic patients, we show why, what, and how to incorporate PK along with domain knowledge in machine learning. We discuss methods for infusing PK and present performance evaluation metrics. Support for safety and user-level explainability of the PK-infused learning improves confidence and trust in the AI system.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/982c80d77d9ee37abfc357b5929dcec8c059e7a7.pdf",
        "venue": "IEEE Internet Computing",
        "citationCount": 0,
        "score": 0
    },
    "43561ac2f7e9612d3d48951f0d2aa290829adf3e.pdf": {
        "title": "Human-centered AI: ensuring human control while increasing automation",
        "authors": [
            "B. Shneiderman"
        ],
        "published_date": "2022",
        "abstract": "A new synthesis is emerging that integrates Artificial Intelligence (AI) technologies with Human-Computer Interaction to produce Human-Centered AI (HCAI). Advocates of this new synthesis seek to amplify, augment, and enhance human abilities, so as to empower people, build their self-efficacy, support creativity, recognize responsibility, and promote social connections. Researchers, developers, business leaders, policy makers and others are expanding the technology-centered scope of AI to include HCAI ways of thinking. This expansion from an algorithm-focused view to embrace a human-centered perspective, can shape the future of technology so as to better serve human needs. Educators, designers, software engineers, product managers, evaluators, and government agency staffers can build on AI-driven technologies to design products and services that make life better for the users. These human-centered products and services will enable people to better care for each other, build sustainable communities, and restore the environment. The passionate advocates of HCAI are devoted to furthering human values, rights, justice, and dignity, by building reliable, safe, and trustworthy systems. Early hypertext systems required user assigned links for text files, giving full control to users, while providing readers with an understandable and predictable design. However, innovators quickly realized that there were many strategies to improve hypertext designs by giving users spatial presentations of the related documents, recommendations for links, ways to collaborate, and interactive animated graphical presentations. Other features supported history-keeping, note-taking, and audio for all users, but especially for users with visual disabilities. Over time improved hypertext systems incorporated machine learning and other artificial intelligence techniques that provided automation of features, but sometimes produced unexpected and incomprehensible results. Current strategies are to give users more control by providing previews of potential traversals, reminders, alerts, and suggestions that guide human reflection about their goals and methods. Atzenbeck et al. suggest that hypertext is a method of inquiry, opening the door to creativity support tools that accelerate exploration and discovery, amplified by the Al-infused supertools of Human-Centered AI [1]. A medical hypertext scenario could enable a physician to provide a patient history, lab tests, and current symptoms as a starting point. The hypertext system could respond with a set of possible diagnoses, which could be selected by the physician, leading to a refined analysis, links to recent clinical trial results, suggestions of consulting specialists, and recommendations for leading treatment centers. The physician could share the analysis with teammates or specialists to get feedback. The physician's exploration records could be saved to the patient's history, so that the treatment plan could be formulated based on reliable resources and then refined by discussions with patients, who would be given links to patient-centered descriptions of the diagnosis and treatment plan. The physician is responsible for what happens, but this scenario provides a strong history for retrospective analyzes of the choices that were made and the outcomes. If human-centered AI design scenarios like this one are oriented to amplifying, augmenting, empowering and enhancing human performance, then the chance of successful outcomes will increase. The passionate advocates of HCAI are devoted to furthering human values, rights, justice, and dignity, by building reliable, safe, and trustworthy systems. The talk will include examples, references to further work, and discussion time for questions. These ideas are drawn from Ben Shneiderman's new book Human-Centered AI [6]. Further information at: https://hcil.umd.edu/human-centered-ai",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/43561ac2f7e9612d3d48951f0d2aa290829adf3e.pdf",
        "venue": "HUMAN@HT",
        "citationCount": 0,
        "score": 0
    },
    "b9492da3d4c0d80ff83b2b661d774b0f20b9da11.pdf": {
        "title": "Will the EU Medical Device Regulation help to improve the safety and performance of medical AI devices?",
        "authors": [
            "E. Niemiec"
        ],
        "published_date": "2022",
        "abstract": "Concerns have been raised over the quality of evidence on the performance of medical artificial intelligence devices, including devices that are already on the market in the USA and Europe. Recently, the Medical Device Regulation, which aims to set high standards of safety and quality, has become applicable in the European Union. The aim of this article is to discuss whether, and how, the Medical Device Regulation will help improve the safety and performance of medical artificial intelligence devices entering the market. The Medical Device Regulation introduces new rules for risk classification of the devices, which will result in more devices subjected to a higher degree of scrutiny before entering the market; more stringent requirements on clinical evaluation, including the requirement for appraisal of clinical data; new requirements for post-market surveillance, which may help spot early on any new, unexpected side effects and risks of the devices; and requirements for notified bodies, including for expertise of the personnel and consideration of relevant best practice documents. The guidance of the Medical Device Coordination Group on clinical evaluation of medical device software and the MEDDEV2.7 guideline on clinical evaluation also attend to some of the problems identified in studies on medical artificial intelligence devices. The Medical Device Regulation will likely help improve the safety and performance of the medical artificial intelligence devices on the European market. The impact of the Regulation, however, is also dependent on its adequate enforcement by the European Union member states.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/b9492da3d4c0d80ff83b2b661d774b0f20b9da11.pdf",
        "venue": "Digital Health",
        "citationCount": 0,
        "score": 0
    },
    "4c2983fed4f4efde7d4fe2ba53319010ef2c51bb.pdf": {
        "title": "A dataset of simulated patient-physician medical interviews with a focus on respiratory cases",
        "authors": [
            "Faiha Fareez",
            "Tishya Parikh",
            "Christopher Wavell",
            "Saba Shahab",
            "Meghan Chevalier",
            "Scott Good",
            "Isabella De Blasi",
            "Rafik Rhouma",
            "Christopher McMahon",
            "Jean-Paul Lam",
            "T. Lo",
            "Christopher W. Smith"
        ],
        "published_date": "2022",
        "abstract": "Artificial Intelligence (AI) is playing a major role in medical education, diagnosis, and outbreak detection through Natural Language Processing (NLP), machine learning models and deep learning tools. However, in order to train AI to facilitate these medical fields, well-documented and accurate medical conversations are needed. The dataset presented covers a series of medical conversations in the format of Objective Structured Clinical Examinations (OSCE), with a focus on respiratory cases in audio format and corresponding text documents. These cases were simulated, recorded, transcribed, and manually corrected with the underlying aim of providing a comprehensive set of medical conversation data to the academic and industry community. Potential applications include speech recognition detection for speech-to-text errors, training NLP models to extract symptoms, detecting diseases, or for educational purposes, including training an avatar to converse with healthcare professional students as a standardized patient during clinical examinations. The application opportunities for the presented dataset are vast, given that this calibre of data is difficult to access and costly to develop. Measurement(s) conversations Technology Type(s) audio recording and transcription Factor Type(s) N/A Sample Characteristic - Organism simulated medical exams Sample Characteristic - Environment simulation Sample Characteristic - Location simulation Measurement(s) conversations Technology Type(s) audio recording and transcription Factor Type(s) N/A Sample Characteristic - Organism simulated medical exams Sample Characteristic - Environment simulation Sample Characteristic - Location simulation",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/4c2983fed4f4efde7d4fe2ba53319010ef2c51bb.pdf",
        "venue": "Scientific Data",
        "citationCount": 0,
        "score": 0
    },
    "1adb84ff58a2ed6d7a5345820489997edef66033.pdf": {
        "title": "What Does This Acronym Mean? Introducing a New Dataset for Acronym Identification and Disambiguation",
        "authors": [
            "Amir Pouran Ben Veyseh",
            "Franck Dernoncourt",
            "Quan Hung Tran",
            "Thien Huu Nguyen"
        ],
        "published_date": "2020",
        "abstract": "Acronyms are the short forms of phrases that facilitate conveying lengthy sentences in documents and serve as one of the mainstays of writing. Due to their importance, identifying acronyms and corresponding phrases (i.e., acronym identification (AI)) and finding the correct meaning of each acronym (i.e., acronym disambiguation (AD)) are crucial for text understanding. Despite the recent progress on this task, there are some limitations in the existing datasets which hinder further improvement. More specifically, limited size of manually annotated AI datasets or noises in the automatically created acronym identification datasets obstruct designing advanced high-performing acronym identification models. Moreover, the existing datasets are mostly limited to the medical domain and ignore other domains. In order to address these two limitations, we first create a manually annotated large AI dataset for scientific domain. This dataset contains 17,506 sentences which is substantially larger than previous scientific AI datasets. Next, we prepare an AD dataset for scientific domain with 62,441 samples which is significantly larger than previous scientific AD dataset. Our experiments show that the existing state-of-the-art models fall far behind human-level performance on both datasets proposed by this work. In addition, we propose a new deep learning model which utilizes the syntactical structure of the sentence to expand an ambiguous acronym in a sentence. The proposed model outperforms the state-of-the-art models on the new AD dataset, providing a strong baseline for future research on this dataset.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/1adb84ff58a2ed6d7a5345820489997edef66033.pdf",
        "venue": "International Conference on Computational Linguistics",
        "citationCount": 0,
        "score": 0
    },
    "4ed6906e5f0d41ab1ee17bcf225653b61765ec10.pdf": {
        "title": "Artificial intelligence in medical imaging practice in Africa: a qualitative content analysis study of radiographers\u2019 perspectives",
        "authors": [
            "W. Antwi",
            "T. Akudjedu",
            "B. Botwe"
        ],
        "published_date": "2021",
        "abstract": "Purpose Studies have documented the clinical potentials of artificial intelligence (AI) in medical imaging practice to improving patient care. This study aimed to qualitatively explore the perception of radiographers relating to the integration of AI in medical imaging practice in Africa. Methods The study employed a qualitative design using an open-ended online instrument administered between March and August 2020. Participants consisted of radiographers working within Africa during the time of the study. Data obtained were analysed using qualitative content analysis. Six themes of concerns were generated: expectant tool; career insecurity; cost of new technology, equipment preservation and data insecurity; service delivery quality; need for expanding AI awareness. Results A total of 475 valid responses were obtained. Participants demonstrated a positive outlook about AI in relation to clinical quality improvement, competent diagnosis, radiation dose reduction and improvement in research. They however expressed concerns relating to the implementation of this technology, including job security and loss of core professional radiographer skills and roles. In addition, concerns regarding AI equipment maintenance, lack of awareness about AI and education and training opportunities were evident. Conclusion Awareness of the importance of AI in medical imaging practice was acknowledged; however, concerns relating to job security, data protection must be given critical attention for successful implementation of these advanced technologies in medical imaging in Africa. Inclusion of AI modules in the training of future radiographers is highly recommended.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/4ed6906e5f0d41ab1ee17bcf225653b61765ec10.pdf",
        "venue": "Insights into Imaging",
        "citationCount": 0,
        "score": 0
    },
    "55283517de38f4d5870e2f6f4ef42122d2229e5a.pdf": {
        "title": "COVID-19 disease diagnosis with light-weight CNN using modified MFCC and enhanced GFCC from human respiratory sounds",
        "authors": [
            "Lella Kranthi Kumar",
            "P. Alphonse"
        ],
        "published_date": "2022",
        "abstract": "In the last 2 years, medical researchers and clinical scientists have paid close attention to the problem of respiratory sound classification to classify COVID-19 disease symptoms. In the physical world, very few AI-based (Artificial Intelligence) techniques are often used to detect COVID-19/SARS-CoV-2 respiratory disease symptoms from the human respiratory system-generated acoustic sounds such as acoustic voice sound, breathing (inhale and exhale) sounds, and cough sound. We propose a light-weight Convolutional Neural Network (CNN) with Modified-Mel-frequency Cepstral Coefficient (M-MFCC) using different depths and kernel sizes to classify COVID-19 and other respiratory sound disease symptoms such as Asthma, Pertussis, and Bronchitis. The proposed network outperforms conventional feature extraction models and existing Deep Learning (DL) models for COVID-19/SARS-CoV-2 classification accuracy in the range of 4\u201310%. The model\u2019s performance is compared with the COVID-19 crowdsourced benchmark dataset and gives a competitive performance. We applied different receptive fields and depths in the proposed model to get different contextual information that should aid in classification. And our experiments suggested 1 \\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$\\times $$\\end{document}\u00d7 12 receptive fields and a depth of 5-Layer for the light-weight CNN to extract and identify the features from respiratory sound data. The model is also trained and tested with different modalities of data to showcase its effectiveness in classification.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/55283517de38f4d5870e2f6f4ef42122d2229e5a.pdf",
        "venue": "The European Physical Journal Special Topics",
        "citationCount": 0,
        "score": 0
    },
    "473c62a48d1c2b7c8e41589d29668faf0458ebb3.pdf": {
        "title": "Explicability of artificial intelligence in radiology: Is a fifth bioethical principle conceptually necessary?",
        "authors": [
            "F. Ursin",
            "C. Timmermann",
            "F. Steger"
        ],
        "published_date": "2021",
        "abstract": "Recent years have witnessed intensive efforts to specify which requirements ethical artificial intelligence (AI) must meet. General guidelines for ethical AI consider a varying number of principles important. A frequent novel element in these guidelines, that we have bundled together under the term explicability, aims to reduce the black-box character of machine learning algorithms. The centrality of this element invites reflection on the conceptual relation between explicability and the four bioethical principles. This is important because the application of general ethical frameworks to clinical decision-making entails conceptual questions: Is explicability a free-standing principle? Is it already covered by the well-established four bioethical principles? Or is it an independent value that needs to be recognized as such in medical practice? We discuss these questions in a conceptual-ethical analysis, which builds upon the findings of an empirical document analysis. On the example of the medical specialty of radiology, we analyze the position of radiological associations on the ethical use of medical AI. We address three questions: Are there references to explicability or a similar concept? What are the reasons for such inclusion? Which ethical concepts are referred to?",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/473c62a48d1c2b7c8e41589d29668faf0458ebb3.pdf",
        "venue": "Bioethics",
        "citationCount": 0,
        "score": 0
    },
    "9993b3d0c2442318af77dd4b3604255d8bf7a8b0.pdf": {
        "title": "Burnout within UK surgical specialties: a systematic review.",
        "authors": [
            "B. Balendran",
            "MF Bath",
            "AI Awopetu",
            "SM Kreckler"
        ],
        "published_date": "2021",
        "abstract": "INTRODUCTION\nBurnout is of growing concern within the surgical workforce, having been shown to result in reduced job satisfaction, decreased patient satisfaction and higher rates of medical errors. Determining the extent of burnout and identifying its risk factors within UK surgical practice is essential to ensure appropriate interventions can be implemented to improve mental wellbeing.\n\n\nMATERIALS\nA systematic search of PubMed, Medline, Embase, PsychINFO and Cochrane databases was performed, following PRISMA guidelines. Studies published between January 2000 and October 2019 that reported prevalence data or risk factors on burnout for surgeons working within the UK and/or the Republic of Ireland were included.\n\n\nFINDINGS\nTen papers met the inclusion criteria. The overall prevalence of burnout amongst surgeons in the UK was 32.0% (IQR 28.9-41.0%), with surgical trainees having the highest prevalence (59.0%) of burnout documented for any subgroup. The most common risk factors identified for burnout were younger surgeon age and lower clinical grade. Being married or living with a partner was found to be protective.\n\n\nCONCLUSIONS\nBurnout is highly prevalent in UK surgical specialties, mostly amongst surgical trainees. Targeted pre-emptive interventions based upon relevant risk factors for burnout should be prioritised, at both individual and institutional levels.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/9993b3d0c2442318af77dd4b3604255d8bf7a8b0.pdf",
        "venue": "Annals of the Royal College of Surgeons of England",
        "citationCount": 0,
        "score": 0
    },
    "68d210d739fd92e3b2854a093cb0fc9f4a622bd5.pdf": {
        "title": "Prevalence and risk factors for vascular calcification in Chinese patients receiving dialysis: baseline results from a prospective cohort study",
        "authors": [
            "Zhi-Hong Liu",
            "Xue-Qing Yu",
            "Jun-Wei Yang",
            "Aili Jiang",
            "Bi-cheng Liu",
            "C. Xing",
            "Ji-zhuang Lou",
            "Mei Wang",
            "Hong Cheng",
            "Jun Liu",
            "Jun-zhou Fu",
            "Ai-hua Zhang",
            "Miao-jia Zhang",
            "Qiao-ling Zhou",
            "Chen Yu",
            "Rong Wang",
            "Li Wang",
            "Yuqing Chen",
            "Tian-Jun Guan",
            "Ai Peng",
            "N. Chen",
            "C. Hao",
            "Xu-yang Cheng"
        ],
        "published_date": "2018",
        "abstract": "",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/68d210d739fd92e3b2854a093cb0fc9f4a622bd5.pdf",
        "venue": "Current Medical Research and Opinion",
        "citationCount": 0,
        "score": 0
    },
    "7aabd2566ddc3980c07bbd3652ac903f20153a12.pdf": {
        "title": "Legal concerns in health-related artificial intelligence: a scoping review protocol",
        "authors": [
            "Michael Da Silva",
            "T. Horsley",
            "Devin Singh",
            "Emily Ann Da Silva",
            "Valentina Ly",
            "Bryan Thomas",
            "Ryan C. Daniel",
            "Karni Chagal-Feferkorn",
            "Samantha Iantomasi",
            "Kelli White",
            "Arianne Kent",
            "C. Flood"
        ],
        "published_date": "2022",
        "abstract": "Background Medical innovations offer tremendous hope. Yet, similar innovations in governance (law, policy, ethics) are likely necessary if society is to realize medical innovations\u2019 fruits and avoid their pitfalls. As innovations in artificial intelligence (AI) advance at a rapid pace, scholars across multiple disciplines are articulating concerns in health-related AI that likely require legal responses to ensure the requisite balance. These scholarly perspectives may provide critical insights into the most pressing challenges that will help shape and advance future regulatory reforms. Yet, to the best of our knowledge, there is no comprehensive summary of the literature examining legal concerns in relation to health-related AI. We thus aim to summarize and map the literature examining legal concerns in health-related AI using a scoping review approach. Methods The scoping review framework developed by (J Soc Res Methodol 8:19-32, 2005) and extended by (Implement Sci 5:69, 2010) and the Preferred Reporting Items for Systematic Reviews and Meta-Analysis extension for scoping reviews (PRISMA-ScR) guided our protocol development. In close consultation with trained librarians, we will develop a highly sensitive search for MEDLINE\u00ae\u00a0(OVID) and adapt it for multiple databases designed to comprehensively capture texts in law, medicine, nursing, pharmacy, other healthcare professions (e.g., dentistry, nutrition), public health, computer science, and engineering. English- and French-language records will be included if they examine health-related AI, describe or prioritize a legal concern in health-related AI or propose a solution thereto, and were published in 2012 or later. Eligibility assessment will be conducted independently and in duplicate at all review stages. Coded data will be analyzed along themes and stratified across discipline-specific literatures. Discussion This first-of-its-kind scoping review will summarize available literature examining, documenting, or prioritizing legal concerns in health-related AI to advance law and policy reform(s). The review may also reveal discipline-specific concerns, priorities, and proposed solutions to the concerns. It will thereby identify priority areas that should be the focus of future reforms and regulatory options available to stakeholders in reform processes. Trial registration This protocol was submitted to the Open Science Foundation registration database. See https://osf.io/zav7w .",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/7aabd2566ddc3980c07bbd3652ac903f20153a12.pdf",
        "venue": "Systematic Reviews",
        "citationCount": 0,
        "score": 0
    },
    "7c813d1ffa86b9937c04e68507c6ab1b69d8484d.pdf": {
        "title": "Defining the concepts of a smart nursing home and its potential technology utilities that integrate medical services and are acceptable to stakeholders: a scoping review",
        "authors": [
            "Yuanyuan Zhao",
            "F. Rokhani",
            "S. Sazlina",
            "N. Devaraj",
            "Jing Su",
            "Boon-How Chew"
        ],
        "published_date": "2021",
        "abstract": "Background and objectives Smart technology in nursing home settings has the potential to elevate an operation that manages more significant number of older residents.\u00a0However, the concepts, definitions, and types of smart technology, integrated medical services, and stakeholders\u2019 acceptability of smart nursing homes are less clear. This scoping review aims to define a smart nursing home and examine the qualitative evidence on technological feasibility, integration of medical services, and acceptability of the stakeholders. Methods Comprehensive searches were conducted on stakeholders\u2019 websites (Phase 1) and 11 electronic databases (Phase 2), for existing concepts of smart nursing home, on what and how technologies and medical services were implemented in nursing home settings, and acceptability assessment by the stakeholders. The publication year was inclusive from January 1999 to September 2021. The language was limited to English and Chinese. Included articles must report nursing home settings related to older adults\u2009\u2265\u200960\u00a0years old with or without medical demands but not bed-bound. Technology Readiness Levels were used to measure the readiness of new technologies and system designs. The analysis was guided by the Framework Method and the smart technology adoption behaviours of elder consumers theoretical model. The results were reported according to the PRISMA-ScR. Results A\u00a0total of\u00a0177 literature\u00a0(13 website documents and 164 journal articles) were selected. Smart nursing homes are technology-assisted nursing homes that allow the life enjoyment of their residents. They used IoT, computing technologies, cloud computing, big data and AI, information management systems, and digital health to integrate medical services in monitoring abnormal events,\u00a0assisting daily living, conducting teleconsultation, managing health information,\u00a0and improving the interaction between providers and residents. Fifty-five percent of the new technologies were ready for use in nursing homes (levels 6\u20137), and the remaining were proven the technical feasibility (levels 1\u20135). Healthcare professionals with higher education, better tech-savviness, fewer years at work, and older adults with more severe illnesses were more acceptable to smart technologies. Conclusions Smart nursing homes with integrated medical services have great potential to improve the quality of care and ensure older residents\u2019 quality of life.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/7c813d1ffa86b9937c04e68507c6ab1b69d8484d.pdf",
        "venue": "BMC Geriatrics",
        "citationCount": 0,
        "score": 0
    },
    "0c3ceda44c277b83a48eda5c12b1d8fbdc44056b.pdf": {
        "title": "Artificial Intelligence (AI) in Breast Imaging: A Scientometric Umbrella Review",
        "authors": [
            "X. Tan",
            "W. L. Cheor",
            "Li Li Lim",
            "Khairul Shakir Ab Rahman",
            "I. Bakrin"
        ],
        "published_date": "2022",
        "abstract": "Artificial intelligence (AI), a rousing advancement disrupting a wide spectrum of applications with remarkable betterment, has continued to gain momentum over the past decades. Within breast imaging, AI, especially machine learning and deep learning, honed with unlimited cross-data/case referencing, has found great utility encompassing four facets: screening and detection, diagnosis, disease monitoring, and data management as a whole. Over the years, breast cancer has been the apex of the cancer cumulative risk ranking for women across the six continents, existing in variegated forms and offering a complicated context in medical decisions. Realizing the ever-increasing demand for quality healthcare, contemporary AI has been envisioned to make great strides in clinical data management and perception, with the capability to detect indeterminate significance, predict prognostication, and correlate available data into a meaningful clinical endpoint. Here, the authors captured the review works over the past decades, focusing on AI in breast imaging, and systematized the included works into one usable document, which is termed an umbrella review. The present study aims to provide a panoramic view of how AI is poised to enhance breast imaging procedures. Evidence-based scientometric analysis was performed in accordance with the Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) guideline, resulting in 71 included review works. This study aims to synthesize, collate, and correlate the included review works, thereby identifying the patterns, trends, quality, and types of the included works, captured by the structured search strategy. The present study is intended to serve as a \u201cone-stop center\u201d synthesis and provide a holistic bird\u2019s eye view to readers, ranging from newcomers to existing researchers and relevant stakeholders, on the topic of interest.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/0c3ceda44c277b83a48eda5c12b1d8fbdc44056b.pdf",
        "venue": "Diagnostics",
        "citationCount": 0,
        "score": 0
    },
    "3d8d80cf9acf0d6ca7e5e5e95756dd639054829d.pdf": {
        "title": "An Analysis of Body Language of Patients Using Artificial Intelligence",
        "authors": [
            "Rawad Abdulghafor",
            "Abdelrahman M Abdelmohsen",
            "S. Turaev",
            "Mohammed A. H. Ali",
            "Sharyar Wani"
        ],
        "published_date": "2022",
        "abstract": "In recent decades, epidemic and pandemic illnesses have grown prevalent and are a regular source of concern throughout the world. The extent to which the globe has been affected by the COVID-19 epidemic is well documented. Smart technology is now widely used in medical applications, with the automated detection of status and feelings becoming a significant study area. As a result, a variety of studies have begun to focus on the automated detection of symptoms in individuals infected with a pandemic or epidemic disease by studying their body language. The recognition and interpretation of arm and leg motions, facial recognition, and body postures is still a developing field, and there is a dearth of comprehensive studies that might aid in illness diagnosis utilizing artificial intelligence techniques and technologies. This literature review is a meta review of past papers that utilized AI for body language classification through full-body tracking or facial expressions detection for various tasks such as fall detection and COVID-19 detection, it looks at different methods proposed by each paper, their significance and their results.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/3d8d80cf9acf0d6ca7e5e5e95756dd639054829d.pdf",
        "venue": "Healthcare",
        "citationCount": 0,
        "score": 0
    },
    "346c603c39f71d8ff19e87728a3a276c927edada.pdf": {
        "title": "Artificial Intelligence Advances in the World of Cardiovascular Imaging",
        "authors": [
            "Bhakti Patel",
            "A. Makaryus"
        ],
        "published_date": "2022",
        "abstract": "The tremendous advances in digital information and communication technology have entered everything from our daily lives to the most intricate aspects of medical and surgical care. These advances are seen in electronic and mobile health and allow many new applications to further improve and make the diagnoses of patient diseases and conditions more precise. In the area of digital radiology with respect to diagnostics, the use of advanced imaging tools and techniques is now at the center of evaluation and treatment. Digital acquisition and analysis are central to diagnostic capabilities, especially in the field of cardiovascular imaging. Furthermore, the introduction of artificial intelligence (AI) into the world of digital cardiovascular imaging greatly broadens the capabilities of the field both with respect to advancement as well as with respect to complete and accurate diagnosis of cardiovascular conditions. The application of AI in recognition, diagnostics, protocol automation, and quality control for the analysis of cardiovascular imaging modalities such as echocardiography, nuclear cardiac imaging, cardiovascular computed tomography, cardiovascular magnetic resonance imaging, and other imaging, is a major advance that is improving rapidly and continuously. We document the innovations in the field of cardiovascular imaging that have been brought about by the acceptance and implementation of AI in relation to healthcare professionals and patients in the cardiovascular field.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/346c603c39f71d8ff19e87728a3a276c927edada.pdf",
        "venue": "Healthcare",
        "citationCount": 0,
        "score": 0
    },
    "1a19bd0444ace3458fbf2b5ea3ddcb269c5ea2b2.pdf": {
        "title": "Risk and Protective Factors Related to the Wellness of American Indian and Alaska Native Youth: A Systematic Review",
        "authors": [
            "Catherine E. Burnette",
            "Charles R. Figley"
        ],
        "published_date": "2016",
        "abstract": "",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/1a19bd0444ace3458fbf2b5ea3ddcb269c5ea2b2.pdf",
        "venue": "",
        "citationCount": 0,
        "score": 0
    },
    "b5501ca7d40be9a87cff3486ea2f14c77a9d2244.pdf": {
        "title": "Appositeness of Optimized and Reliable Machine Learning for Healthcare: A Survey",
        "authors": [
            "S. Swain",
            "Bharat Bhushan",
            "Gaurav Dhiman",
            "Wattana Viriyasitavat"
        ],
        "published_date": "2022",
        "abstract": "Machine Learning (ML) has been categorized as a branch of Artificial Intelligence (AI) under the Computer Science domain wherein programmable machines imitate human learning behavior with the help of statistical methods and data. The Healthcare industry is one of the largest and busiest sectors in the world, functioning with an extensive amount of manual moderation at every stage. Most of the clinical documents concerning patient care are hand-written by experts, selective reports are machine-generated. This process elevates the chances of misdiagnosis thereby, imposing a risk to a patient's life. Recent technological adoptions for automating manual operations have witnessed extensive use of ML in its applications. The paper surveys the applicability of ML approaches in automating medical systems. The paper discusses most of the optimized statistical ML frameworks that encourage better service delivery in clinical aspects. The universal adoption of various Deep Learning (DL) and ML techniques as the underlying systems for a variety of wellness applications, is delineated by challenges and elevated by myriads of security. This work tries to recognize a variety of vulnerabilities occurring in medical procurement, admitting the concerns over its predictive performance from a privacy point of view. Finally providing possible risk delimiting facts and directions for active challenges in the future.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/b5501ca7d40be9a87cff3486ea2f14c77a9d2244.pdf",
        "venue": "Archives of Computational Methods in Engineering",
        "citationCount": 0,
        "score": 0
    },
    "9000711dcaf9cd851722fde9bea0bd9101a692f1.pdf": {
        "title": "Clinical Natural Language Processing with Deep Learning",
        "authors": [
            "Sadid A. Hasan",
            "Oladimeji Farri"
        ],
        "published_date": "2019",
        "abstract": "",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/9000711dcaf9cd851722fde9bea0bd9101a692f1.pdf",
        "venue": "Data Science for Healthcare",
        "citationCount": 0,
        "score": 0
    },
    "1fc228642851ba6c2cb6cc7f8050d2a016145862.pdf": {
        "title": "Applying Artificial Intelligence to Address the Knowledge Gaps in Cancer Care.",
        "authors": [
            "G. Simon",
            "C. Dinardo",
            "Koichi Takahashi",
            "T. Cascone",
            "Cynthia A. Powers",
            "Rick J Stevens",
            "Joshua Allen",
            "M. Antonoff",
            "D. Gomez",
            "P. Keane",
            "Fernando Jose Suarez Saiz",
            "Q. Nguyen",
            "Emily B. Roarty",
            "S. Pierce",
            "Jianjun Zhang",
            "Emily Hardeman Barnhill",
            "Kate Lakhani",
            "K. Shaw",
            "Brett Smith",
            "S. Swisher",
            "Rob High",
            "P. Futreal",
            "J. Heymach",
            "L. Chin"
        ],
        "published_date": "2018",
        "abstract": "BACKGROUND\nRapid advances in science challenge the timely adoption of evidence-based care in community settings. To bridge the gap between what is possible and what is practiced, we researched approaches to developing an artificial intelligence (AI) application that can provide real-time patient-specific decision support.\n\n\nMATERIALS AND METHODS\nThe Oncology Expert Advisor (OEA) was designed to simulate peer-to-peer consultation with three core functions: patient history summarization, treatment options recommendation, and management advisory. Machine-learning algorithms were trained to construct a dynamic summary of patients cancer history and to suggest approved therapy or investigative trial options. All patient data used were retrospectively accrued. Ground truth was established for approximately 1,000 unique patients. The full Medline database of more than 23 million published abstracts was used as the literature corpus.\n\n\nRESULTS\nOEA's accuracies of searching disparate sources within electronic medical records to extract complex clinical concepts from unstructured text documents varied, with F1 scores of 90%-96% for non-time-dependent concepts (e.g., diagnosis) and F1 scores of 63%-65% for time-dependent concepts (e.g., therapy history timeline). Based on constructed patient profiles, OEA suggests approved therapy options linked to supporting evidence (99.9% recall; 88% precision), and screens for eligible clinical trials on ClinicalTrials.gov (97.9% recall; 96.9% precision).\n\n\nCONCLUSION\nOur results demonstrated technical feasibility of an AI-powered application to construct longitudinal patient profiles in context and to suggest evidence-based treatment and trial options. Our experience highlighted the necessity of collaboration across clinical and AI domains, and the requirement of clinical expertise throughout the process, from design to training to testing.\n\n\nIMPLICATIONS FOR PRACTICE\nArtificial intelligence (AI)-powered digital advisors such as the Oncology Expert Advisor have the potential to augment the capacity and update the knowledge base of practicing oncologists. By constructing dynamic patient profiles from disparate data sources and organizing and vetting vast literature for relevance to a specific patient, such AI applications could empower oncologists to consider all therapy options based on the latest scientific evidence for their patients, and help them spend less time on information \"hunting and gathering\" and more time with the patients. However, realization of this will require not only AI technology maturation but also active participation and leadership by clincial experts.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/1fc228642851ba6c2cb6cc7f8050d2a016145862.pdf",
        "venue": "The Oncologist",
        "citationCount": 0,
        "score": 0
    },
    "04354a01838734e4cb97dd35bc3019e22f6ed1f5.pdf": {
        "title": "A Literature Review on Ethics for AI in Biomedical Research and Biobanking",
        "authors": [
            "Michael Kargl",
            "M. Plass",
            "Heimo M\u00fcller"
        ],
        "published_date": "2022",
        "abstract": "Summary Background : Artificial Intelligence (AI) is becoming more and more important especially in datacentric fields, such as biomedical research and biobanking. However, AI does not only offer advantages and promising benefits, but brings about also ethical risks and perils. In recent years, there has been growing interest in AI ethics, as reflected by a huge number of (scientific) literature dealing with the topic of AI ethics. The main objectives of this review are: (1) to provide an overview about important (upcoming) AI ethics regulations and international recommendations as well as available AI ethics tools and frameworks relevant to biomedical research, (2) to identify what AI ethics can learn from findings in ethics of traditional biomedical research - in particular looking at ethics in the domain of biobanking, and (3) to provide an overview about the main research questions in the field of AI ethics in biomedical research. Methods : We adopted a modified thematic review approach focused on understanding AI ethics aspects relevant to biomedical research. For this review, four scientific literature databases at the cross-section of medical, technical, and ethics science literature were queried: PubMed, BMC Medical Ethics, IEEE Xplore, and Google Scholar. In addition, a grey literature search was conducted to identify current trends in legislation and standardization. Results : More than 2,500 potentially relevant publications were retrieved through the initial search and 57 documents were included in the final review. The review found many documents describing high-level principles of AI ethics, and some publications describing approaches for making AI ethics more actionable and bridging the principles-to-practice gap. Also, some ongoing regulatory and standardization initiatives related to AI ethics were identified. It was found that ethical aspects of AI implementation in biobanks are often like those in biomedical research, for example with regards to handling big data or tackling informed consent. The review revealed current \u2018hot\u2019 topics in AI ethics related to biomedical research. Furthermore, several published tools and methods aiming to support practical implementation of AI ethics, as well as tools and frameworks specifically addressing complete and transparent reporting of biomedical studies involving AI are described in the review results. Conclusions : The review results provide a practically useful overview of research strands as well as regulations, guidelines, and tools regarding AI ethics in biomedical research. Furthermore, the review results show the need for an ethical-mindful and balanced approach to AI in biomedical research, and specifically reveal the need for AI ethics research focused on understanding and resolving practical problems arising from the use of AI in science and society.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/04354a01838734e4cb97dd35bc3019e22f6ed1f5.pdf",
        "venue": "Yearbook of Medical Informatics",
        "citationCount": 0,
        "score": 0
    },
    "3a8547a9293d65d8a7bf204c1966be4615110dcf.pdf": {
        "title": "Interfacing With the Electronic Health Record (EHR): A Comparative Review of Modes of Documentation",
        "authors": [
            "John P. Avendano",
            "Daniel O Gallagher",
            "Joseph D Hawes",
            "J. Boyle",
            "L. Glasser",
            "Jomar N A Aryee",
            "Brian M. Katt"
        ],
        "published_date": "2022",
        "abstract": "Electronic health records (EHRs) have provided physicians with a systematic framework for collecting patient data, organizing notes from the healthcare team, and managing the daily workflow in the modern era of healthcare. Despite these advantages, EHRs have proven to be problematic for clinicians. The burdensome regulations requiring increased documentation with the EHR paradigm have led to inefficiencies from data-entry requirements forcing physicians to spend an inordinate amount of time on it, affecting the time available for direct patient care as well as leading to professional burnout. As a result, new modalities such as speech recognition, medical scribes, pre-made EHR templates, and digital scribes [a form of artificial intelligence (AI) based on ambient speech recognition] are increasingly being used to reduce charting time and increase the time available for patient care. The purpose of our review is to provide an up-to-date review of the literature on these modalities including their benefits and shortcomings, to help physicians and other medical professionals choose the best methods to document their patient-care encounters efficiently and effectively.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/3a8547a9293d65d8a7bf204c1966be4615110dcf.pdf",
        "venue": "Cureus",
        "citationCount": 0,
        "score": 0
    },
    "0140588666895742e1e6be2c8e710112d0c16e5d.pdf": {
        "title": "Towards Interpretable Clinical Diagnosis with Bayesian Network Ensembles Stacked on Entity-Aware CNNs",
        "authors": [
            "Jun Chen",
            "Xiaoya Dai",
            "Quan Yuan",
            "Chao Lu",
            "Hai-ting Huang"
        ],
        "published_date": "2020",
        "abstract": "The automatic text-based diagnosis remains a challenging task for clinical use because it requires appropriate balance between accuracy and interpretability. In this paper, we attempt to propose a solution by introducing a novel framework that stacks Bayesian Network Ensembles on top of Entity-Aware Convolutional Neural Networks (CNN) towards building an accurate yet interpretable diagnosis system. The proposed framework takes advantage of the high accuracy and generality of deep neural networks as well as the interpretability of Bayesian Networks, which is critical for AI-empowered healthcare. The evaluation conducted on the real Electronic Medical Record (EMR) documents from hospitals and annotated by professional doctors proves that, the proposed framework outperforms the previous automatic diagnosis methods in accuracy performance and the diagnosis explanation of the framework is reasonable.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/0140588666895742e1e6be2c8e710112d0c16e5d.pdf",
        "venue": "Annual Meeting of the Association for Computational Linguistics",
        "citationCount": 0,
        "score": 0
    },
    "bc182bf3daf3c03d246fa86b1ad008dc9fd0fe23.pdf": {
        "title": "Medicare program; hospital inpatient prospective payment systems for acute care hospitals and the long-term care hospital prospective payment system and fiscal year 2015 rates; quality reporting requirements for specific providers; reasonable compensation equivalents for physician services in exclud",
        "authors": [
            "Hhs Centers for Medicare Medicare Services"
        ],
        "published_date": "2014",
        "abstract": "",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/bc182bf3daf3c03d246fa86b1ad008dc9fd0fe23.pdf",
        "venue": "Federal register",
        "citationCount": 0,
        "score": 0
    },
    "a3260f8cdc050ffa8e76aa4843d16d70efddaa65.pdf": {
        "title": "Methodology for Conducting Post-Marketing Surveillance of Software as a Medical Device Based on Artificial Intelligence Technologies",
        "authors": [
            "V. Zinchenko",
            "K. Arzamasov",
            "S. Chetverikov",
            "A. Maltsev",
            "V. Novik",
            "E. Akhmad",
            "D. Sharova",
            "A. Andreychenko",
            "A. Vladzymyrskyy",
            "S. Morozov"
        ],
        "published_date": "2022",
        "abstract": "The aim of the study was to develop a methodology for conducting post-registration clinical monitoring of software as a medical device based on artificial intelligence technologies (SaMD-AI). Materials and Methods The methodology of post-registration clinical monitoring is based on the requirements of regulatory legal acts issued by the Board of the Eurasian Economic Commission. To comply with these requirements, the monitoring involves submission of the review of adverse events reports, the review of developers\u2019 routine reports on the safety and efficiency of SaMD-AI, and the assessment of the system for collecting and analyzing developers\u2019 post-registration data on the safety and efficiency of medical devices. The methodology was developed with regard to the recommendations of the International Medical Device Regulators Forum and the documents issued by the Food and Drug Administration (USA). Field-testing of this methodology was carried out using SaMD-AI designed for diagnostic imaging. Results The post-registration monitoring of SaMD-AI consists of three key stages: collecting user feedback, technical monitoring and clinical validation. Technical monitoring involves routine evaluation of SaMD-AI output data quality to detect and remove flaws in a timely manner, and to secure the product stability. Major outcomes include an ordered list of technical flaws in SaMD-AI and their classification using evidence from diagnostic imaging studies. The application of this methodology resulted in a gradual reduction in the number of studies with flaws due to timely improvements in artificial intelligence algorithms: the number of flaws decreased to 5% in various aspects during subsequent testing. Clinical validation confirmed that SaMD-AI is capable of producing clinically meaningful outputs related to its intended use within the functionality determined by the developer. The testing procedure and the baseline testing framework were established during the field testing. Conclusion The developed methodology will ensure the safety and efficiency of SaMD-AI taking into account its specifics as intangible medical devices. The methodology presented in this paper can be used by SaMD-AI developers to plan and carry out the post-registration clinical monitoring.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/a3260f8cdc050ffa8e76aa4843d16d70efddaa65.pdf",
        "venue": "Sovremennye tekhnologii v meditsine",
        "citationCount": 0,
        "score": 0
    },
    "376de00d07ed1a9a8a842dc3d192a9131cf36001.pdf": {
        "title": "Facial asymmetry index in normal young adults.",
        "authors": [
            "C. S. Huang",
            "X. Q. Liu",
            "Y. R. Chen"
        ],
        "published_date": "2013",
        "abstract": "",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/376de00d07ed1a9a8a842dc3d192a9131cf36001.pdf",
        "venue": "Orthodontics & craniofacial research",
        "citationCount": 0,
        "score": 0
    },
    "aeb5a82400a2ea187d74d60d53cb000a06f8e881.pdf": {
        "title": "Use of Artificial Intelligence for Medical Literature Search: Randomized Controlled Trial Using the Hackathon Format",
        "authors": [
            "D. Schoeb",
            "R. Suarez-Ibarrola",
            "S. Hein",
            "F. F. Dressler",
            "F. Adams",
            "D. Schlager",
            "A. Miernik"
        ],
        "published_date": "2020",
        "abstract": "Background Mapping out the research landscape around a project is often time consuming and difficult. Objective This study evaluates a commercial artificial intelligence (AI) search engine (IRIS.AI) for its applicability in an automated literature search on a specific medical topic. Methods To evaluate the AI search engine in a standardized manner, the concept of a science hackathon was applied. Three groups of researchers were tasked with performing a literature search on a clearly defined scientific project. All participants had a high level of expertise for this specific field of research. Two groups were given access to the AI search engine IRIS.AI. All groups were given the same amount of time for their search and were instructed to document their results. Search results were summarized and ranked according to a predetermined scoring system. Results The final scoring awarded 49 and 39 points out of 60 to AI groups 1 and 2, respectively, and the control group received 46 points. A total of 20 scientific studies with high relevance were identified, and 5 highly relevant studies (\u201cspot on\u201d) were reported by each group. Conclusions AI technology is a promising approach to facilitate literature searches and the management of medical libraries. In this study, however, the application of AI technology lead to a more focused literature search without a significant improvement in the number of results.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/aeb5a82400a2ea187d74d60d53cb000a06f8e881.pdf",
        "venue": "Interactive Journal of Medical Research",
        "citationCount": 0,
        "score": 0
    },
    "845b4bfa329180b290b3d858dccc1fa38e7e0622.pdf": {
        "title": "Infection-related ventilator-associated complications in ICU patients colonised with extended-spectrum \u03b2-lactamase-producing Enterobacteriaceae",
        "authors": [
            "F. Barbier",
            "S. Bailly",
            "C. Schwebel",
            "L. Papazian",
            "\u00c9. Azoulay",
            "H. Kallel",
            "S. Siami",
            "L. Argaud",
            "G. Marcotte",
            "B. Misset",
            "J. Reignier",
            "M. Darmon",
            "J. Zahar",
            "D. Goldgran\u2011Toledano",
            "E. Montmollin",
            "B. Souweine",
            "B. Mourvillier",
            "J. Timsit",
            "F. T. F. Group"
        ],
        "published_date": "2018",
        "abstract": "",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/845b4bfa329180b290b3d858dccc1fa38e7e0622.pdf",
        "venue": "Intensive Care Medicine",
        "citationCount": 0,
        "score": 0
    },
    "22299ef4fd0d02935917a0a3c99677dbb07b31a3.pdf": {
        "title": "Expert-level aspiration and penetration detection during flexible endoscopic evaluation of swallowing with artificial intelligence-assisted diagnosis",
        "authors": [
            "Weihao Weng",
            "Mitsuyoshi Imaizumi",
            "S. Murono",
            "Xin Zhu"
        ],
        "published_date": "2022",
        "abstract": "Flexible endoscopic evaluation of swallowing (FEES) is considered the gold standard in diagnosing oropharyngeal dysphagia. Recent advances in deep learning have led to a resurgence of artificial intelligence-assisted computer-aided diagnosis (AI-assisted CAD) for a variety of applications. AI-assisted CAD would be a remarkable benefit in providing medical services to populations with inadequate access to dysphagia experts, especially in aging societies. This paper presents an AI-assisted CAD named FEES-CAD for aspiration and penetration detection on video recording during FEES. FEES-CAD segments the input FEES video and classifies penetration, aspiration, residue in the vallecula, and residue in the hypopharynx based on the segmented FEES video. We collected and annotated FEES videos from 199 patients to train the network and tested the performance of FEES-CAD using FEES videos from other 40 patients. These patients consecutively underwent FEES between December 2016 and August 2019 at Fukushima Medical University Hospital. FEES videos were deidentified, randomized, and rated by FEES-CAD and laryngologists with over 15 years of experience in performing FEES. FEES-CAD achieved an average Dice similarity coefficient of 98.6\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$\\%$$\\end{document}%. FEES-CAD achieved expert-level accuracy performance on penetration (92.5\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$\\%$$\\end{document}%), aspiration (92.5\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$\\%$$\\end{document}%), residue in the vallecula (100\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$\\%$$\\end{document}%), and residue in the hypopharynx (87.5\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$\\%$$\\end{document}%) classification tasks. To the best of our knowledge, FEES-CAD is the first CNN-based system that achieves expert-level performance in detecting aspiration and penetration.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/22299ef4fd0d02935917a0a3c99677dbb07b31a3.pdf",
        "venue": "Scientific Reports",
        "citationCount": 0,
        "score": 0
    },
    "abf3e27f04960692433d85a79a21b1332d4cdc9d.pdf": {
        "title": "The promise and perils of AI in medicine",
        "authors": [
            "Robert W. Sparrow",
            "Joshua Hatherley"
        ],
        "published_date": "2019",
        "abstract": "LANGUAGE NOTE | Document text in English; abstract also in Chinese.\u4eba\u5de5\u667a\u80fd\uff08\uff21\uff29\uff09\u5c07\u5982\u4f55\u4fc3\u9032\u4eba\u985e\u7684\u91ab\u7642\u4fdd\u5065\uff1f\u5982\u679c\u6211\u5011\u64d4\u5fc3\u4eba\u5de5\u667a\u80fd\u4ecb\u5165\u91ab\u7642\u7684\u98a8\u96aa\uff0c\u6211\u5011\u53c8\u61c9\u8a72\u95dc\u6ce8\u4ec0\u9ebd\u5462\uff1f\u672c\u6587\u8a66\u5716\u6982\u8ff0\u6b64\u985e\u554f\u984c\uff0c\u4e26\u5c0d\u4eba\u5de5\u667a\u80fd\u4ecb\u5165\u91ab\u7642\u7684\u98a8\u96aa\u8207\u5e0c\u671b\u4f5c\u4e00\u500b\u521d\u6b65\u8a55\u50f9\u3002\u4eba\u5de5\u667a\u80fd\u4f5c\u70ba\u4e00\u7a2e\u7814\u7a76\u5de5\u5177\u548c\u8a3a\u65b7\u5de5\u5177\u5177\u6709\u5de8\u5927\u7684\u6f5b\u529b\uff0c\u7279\u5225\u662f\u5728\u57fa\u56e0\u7d44\u5b78\u548c\u516c\u5171\u885b\u751f\u9818\u57df\u4e2d\u3002\u4eba\u5de5\u667a\u80fd\u5728\u91ab\u7642\u4e2d\u7684\u5ee3\u6cdb\u4f7f\u7528\u53ef\u80fd\u9084\u6703\u5c0d\u91ab\u7642\u7cfb\u7d71\u7684\u7d44\u7e54\u65b9\u5f0f\u548c\u5546\u696d\u5be6\u8e10\u7522\u751f\u6df1\u523b\u7684\u5f71\u97ff\uff0c\u800c\u9019\u4e9b\u5f71\u97ff\u7684\u65b9\u5f0f\u8207\u7a0b\u5ea6\u9084\u6c92\u6709\u88ab\u5145\u5206\u8a8d\u8b58\u5230\u3002\u5728\u4eba\u5de5\u667a\u80fd\u91ab\u5b78\u7684\u71b1\u60c5\u64c1\u8b77\u8005\u770b\u4f86\uff0c\u61c9\u7528\u4eba\u5de5\u667a\u80fd\u53ef\u4ee5\u5e6b\u52a9\u91ab\u751f\u96c6\u4e2d\u7cbe\u529b\u5728\u5c0d\u4ed6\u5011\u548c\u75c5\u4eba\u800c\u8a00\u771f\u6b63\u91cd\u8981\u7684\u554f\u984c\u4e0a\u3002\u7136\u800c\uff0c\u672c\u6587\u5c07\u8ad6\u8b49\u9019\u4e9b\u6a02\u89c0\u7684\u5224\u65b7\u662f\u57fa\u65bc\u5c0d\u73fe\u4ee3\u91ab\u7642\u74b0\u5883\u4e0b\u6a5f\u69cb\u548c\u7d93\u6fdf\u904b\u884c\u898f\u5247\u7684\u4e00\u4e9b\u4e0d\u5408\u60c5\u7406\u7684\u5047\u8a2d\u4e4b\u4e0a\u3002\u672c\u6587\u5c07\u805a\u7126\u65bc\u5982\u4e0b\u4e00 \u4e9b\u91cd\u8981\u8b70\u984c\uff1a\u5927\u8cc7\u6599\u4e2d\u7684\u96b1\u79c1\u3001\u76e3\u7ba1\u548c\u504f\u898b\uff0c\u904e\u5206\u4fe1\u4efb\u6a5f\u5668\u7684\u98a8\u96aa\uff0c\u900f\u660e\u5ea6\u554f\u984c\uff0c\u91ab\u7642\u5c08\u696d\u4eba\u58eb\u7684\u201c\u53bb\u6280\u80fd\u5316\u201d\u554f\u984c\uff0c\u4eba\u5de5\u667a\u80fd\u91cd\u5851\u91ab\u7642\u4fdd\u5065\u7684\u65b9\u5f0f\uff0c\u4ee5\u53ca\u4eba\u5de5\u667a\u80fd\u5c0d\u91ab\u7642\u4fdd\u5065\u4e2d\u6b0a\u529b\u5206\u914d\u7684\u5f71\u97ff\u3002\u5176\u4e2d\u6709\u5169\u500b\u95dc\u9375\u7684\u554f\u984c\u5c24\u5176\u503c\u5f97\u54f2\u5b78\u5bb6\u548c\u751f\u547d\u502b\u7406\u5b78\u5bb6\u7684\u9032\u4e00\u6b65\u95dc\u6ce8\u3002\u7b2c\u4e00\uff0c\u7576\u91ab\u751f\u4e0d\u50c5\u9700\u8981\u8655\u7406\u4eba\u800c\u4e14\u9700\u8981\u8655\u7406\u8cc7\u6599\u7684\u6642\u5019\uff0c\u91ab\u7642\u5be6\u8e10\u6703\u5448\u73fe\u51fa\u4ec0\u9ebd\u6a23\u7684\u5f62\u614b\uff1f\u7b2c\u4e8c\uff0c\u5728\u91ab\u7642\u6c7a\u7b56\u6b0a\u8861\u4e2d\uff0c\u6211\u5011\u61c9\u8a72\u7ed9\u4e88\u4f86\u81ea\u6a5f\u5668\u7684\u610f\u898b\u4ee5\u591a\u5927\u7684\u6b0a\u91cd\uff1fWhat does Artificial Intelligence (AI) have to contribute to health care? And what should we be looking out for if we are worried about its risks? In this paper we offer a survey, and initial evaluation, of hopes and fears about the applications of artificial intelligence in medicine. AI clearly has enormous potential as a research tool, in genomics and public health especially, as well as a diagnostic aid. It\u2019s also highly likely to impact on the organisational and business practices of healthcare systems in ways that are perhaps under-appreciated. Enthusiasts for AI have held out the prospect that it will free physicians up to spend more time attending to what really matters to them and their patients. We will argue that this claim depends upon implausible assumptions about the institutional and economic imperatives operating in contemporary healthcare settings. We will also highlight important concerns about privacy, surveillance, and bias in big data, as well as the risks of over trust in machines, the challenges of transparency, the deskilling of healthcare practitioners, the way AI reframes healthcare, and the implications of AI for the distribution of power in healthcare institutions. We will suggest that two questions, in particular, are deserving of further attention from philosophers and bioethicists. What does care look like when one is dealing with data as much as people? And, what weight should we give to the advice of machines in our own deliberations about medical decisions?DOWNLOAD HISTORY | This article has been downloaded 119 times in Digital Commons before migrating into this platform.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/abf3e27f04960692433d85a79a21b1332d4cdc9d.pdf",
        "venue": "International Journal of Chinese & Comparative Philosophy of Medicine",
        "citationCount": 0,
        "score": 0
    },
    "2e7e9a40e852d83bca34ff4cb44fda727b281b84.pdf": {
        "title": "A novel endoimaging system for endoscopic 3D reconstruction in bladder cancer patients",
        "authors": [
            "R. Suarez-Ibarrola",
            "M. Kriegmair",
            "F. Waldbillig",
            "B. Gr\u00fcne",
            "Misgana Negassi",
            "Ujwala Parupalli",
            "Annette Schmitt",
            "A. Reiterer",
            "Christoph M\u00fcller",
            "A. Scheurer",
            "S. Baur",
            "K. Klein",
            "J. Fallert",
            "L. M\u00fcndermann",
            "Jenshika Yoganathan",
            "Marco Probst",
            "P. Ihle",
            "Neven Bobic",
            "T. Schumm",
            "H. Rehn",
            "A. Betke",
            "Michael Graurock",
            "M. Forrer",
            "C. Gratzke",
            "A. Miernik",
            "S. Hein"
        ],
        "published_date": "2020",
        "abstract": "Abstract Introduction The methods employed to document cystoscopic findings in bladder cancer patients lack accuracy and are subject to observer variability. We propose a novel endoimaging system and an online documentation platform to provide post-procedural 3D bladder reconstructions for improved diagnosis, management and follow-up. Material and methods The RaVeNNA4pi consortium is comprised of five industrial partners, two university hospitals and two technical institutes. These are grouped into hardware, software and clinical partners according to their professional expertise. The envisaged endoimaging system consists of an innovative cystoscope that generates 3D bladder reconstructions allowing users to remotely access a cloud-based centralized database to visualize individualized 3D bladder models from previous cystoscopies archived in DICOM format. Results Preliminary investigations successfully tracked the endoscope's rotational and translational movements. The structure-from-motion pipeline was tested in a bladder phantom and satisfactorily demonstrated 3D reconstructions of the processing sequence. AI-based semantic image segmentation achieved a 0.67 dice-score-coefficient over all classes. An online-platform allows physicians and patients to digitally visualize endoscopic findings by navigating a 3D bladder model. Conclusions Our work demonstrates the current developments of a novel endoimaging system equipped with the potential to generate 3D bladder reconstructions from cystoscopy videos and AI-assisted automated detection of bladder tumors.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/2e7e9a40e852d83bca34ff4cb44fda727b281b84.pdf",
        "venue": "MITAT. Minimally invasive therapy & allied technologies",
        "citationCount": 0,
        "score": 0
    },
    "ad2d689b1f0901930d7c3408e322c9aac360f4ea.pdf": {
        "title": "Economic and utilization outcomes of medication management at a large Medicaid plan with disease management pharmacists using a novel artificial intelligence platform from 2018 to 2019: a retrospective observational study using regression methods",
        "authors": [],
        "published_date": "2021",
        "abstract": "BACKGROUND: Medication therapy management (MTM) and comprehensive medication management (CMM) have been practiced by clinical pharmacists as a predominantly manual activity with interventions documented in a record-keeping system. Program evaluations, largely based on estimations of projected savings and utilization reductions, have not accurately predicted actual claims and utilization changes, leading many to doubt the efficacy of medication management. OBJECTIVE: To assess the impact on actual medical claims of a novel artificial intelligence (AI) platform that identifies members and provides decision support to clinicians in performing telephonic interventions similar to MTM and CMM with high-risk Medicaid members. METHODS: This retrospective observational study used mixed-effects regression models that flexibly account for general trends in cost, as measured by actual claims, to identify the amount of savings and associated impact. To study the economics, total cost of care (TCoC), defined as all medication costs plus all noncapitated medical costs, was evaluated. Utilization was evaluated through the number of emergency department (ED) visits, hospital admissions, bed days, and readmissions. The study included 2,150 predominantly middle-aged (aged 40-64 years) Medicaid members with an average of 10 medications for chronic conditions among an average of 25 total medications. The analysis considered cost and utilization data from August 2017 through April 2019. Interventions occurred between January 2018 and February 2019. RESULTS: Statistically significant correlations were found between receiving interventions and decreased costs and utilization. The economic study found a 19.3% reduction in the TCoC (P < 0.001) that, applied to a preintervention monthly cost of $2,872, yielded a savings of $554 per member per month (PMPM). Medication costs showed a 17.4% reduction (P < 0.001), which, when applied to preintervention cost of $1,110, yielded a savings of $192 PMPM. The utilization study found a 15.1% reduction in ED visits (P = 0.002), a 9.4% reduction in hospital admissions (P = 0.008), and a 10.2% reduction in bed days (P = 0.01). Return on investment is 12.4:1 based on TCoC savings and program costs. CONCLUSIONS: This study evaluated the CMM-Wrap program, which used an advanced AI platform integrated with health plan data, clinical pharmacists trained in disease management, telephonic patient engagement, and closed-loop provider coordination. The results correlate cost and utilization savings with the program. The TCoC savings of $554 PMPM translates to approximately $1.2M a month and more than $14M annually for the 2,150 members in the study. We believe Medicaid and Medicare payment of AI enhanced telephonic CMM services would substantially decrease government health care expenditures, whereas improving health program expansion to Medicaid members with similar risks could save the Health Plan $109M annually. For instance, we estimate that California\u2019s Medicaid (Medi-Cal) program could save more than $1B annually by applying the program\u2019s observed impact to a similar high-risk cohort (about 1.6%) of Medi-Cal members. Additionally, benefits will accrue to nonmanaged health plans based on the savings themselves.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/ad2d689b1f0901930d7c3408e322c9aac360f4ea.pdf",
        "venue": "Journal of Managed Care & Specialty Pharmacy",
        "citationCount": 0,
        "score": 0
    },
    "8da5fb56b6ade82c5eb621f858a4c8aa3f60f4ef.pdf": {
        "title": "Breaking down the silos of artificial intelligence in surgery: glossary of terms",
        "authors": [
            "A. Moglia",
            "K. Georgiou",
            "L. Morelli",
            "K. Toutouzas",
            "R. Satava",
            "A. Cuschieri"
        ],
        "published_date": "2022",
        "abstract": "The literature on artificial intelligence (AI) in surgery has advanced rapidly during the past few years. However, the published studies on AI are mostly reported by computer scientists using their own jargon which is unfamiliar to surgeons. A literature search was conducted in using PubMed following the preferred reporting items for systematic reviews and meta-analyses (PRISMA) statement. The primary outcome of this review is to provide a glossary with definitions of the commonly used AI terms in surgery to improve their understanding by surgeons. One hundred ninety-five studies were included in this review, and 38 AI terms related to surgery were retrieved. Convolutional neural networks were the most frequently culled term by the search, accounting for 74 studies on AI in surgery, followed by classification task (n\u2009=\u200962), artificial neural networks (n\u2009=\u200953), and regression (n\u2009=\u200949). Then, the most frequent expressions were supervised learning (reported in 24 articles), support vector machine (SVM) in 21, and logistic regression in 16. The rest of the 38 terms was seldom mentioned. The proposed glossary can be used by several stakeholders. First and foremost, by residents and attending consultant surgeons, both having to understand the fundamentals of AI when reading such articles. Secondly, junior researchers at the start of their career in Surgical Data Science and thirdly experts working in the regulatory sections of companies involved in the AI Business Software as a Medical Device (SaMD) preparing documents for submission to the Food and Drug Administration (FDA) or other agencies for approval.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/8da5fb56b6ade82c5eb621f858a4c8aa3f60f4ef.pdf",
        "venue": "Surgical Endoscopy",
        "citationCount": 0,
        "score": 0
    },
    "8916ed77f946a4592d00abf5d1ed5b46777e0803.pdf": {
        "title": "Artificial Intelligence Research During COVID-19 Pandemic: Contributed to Future Education",
        "authors": [
            "Nurhasan Nurhasan",
            "B. Prahani*",
            "Nadi Suprapto",
            "Muchamad Arif Al Ardha"
        ],
        "published_date": "2022",
        "abstract": "Besides being able to cause death, it turns out that the COVID-19 pandemic has caused problems in various sectors, including education, health, and Social Life. In addition, the COVID-19 pandemic also has an impact on the field of research, including the field of Artificial Intelligence (AI) which has become an interesting issue in the era of the Industrial Revolution 4.0. Based on Scopus data (search by article title, , and keywords), it shows that there are 381,691 documents. Results of Bibliometric through VOSViewer found some parameters or interrelationships among variables to capture the trend and novelty of researching on AI During COVID-19 Pandemic, such as researching on AI During COVID-19 Pandemic and technology, detection, patient, diagnosis, performance, radiologist, feature, education, and image. Implication research in general evidence, (1) AI researchers have bright career opportunities in the present and the future. This is evident from the condition of the central role of AI in all lines of human life, (2) The trend of AI research is also classified as having a very large contribution to have entered various fields during the COVID-19 pandemic. (3) Including the prevention of COVID-19 transmission with AI, various tools and media have emerged in the medical world that provides many benefits. (4) AI needs more exploration in education field research. In the last five years, AI has made a major contribution advancing the field of education. \u00a9 2022 Eskisehir Osmangazi University. All rights reserved.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/8916ed77f946a4592d00abf5d1ed5b46777e0803.pdf",
        "venue": "International Journal of Instruction",
        "citationCount": 0,
        "score": 0
    },
    "96579c44f66812d47e835e1264cde4211c9f0bd4.pdf": {
        "title": "Common strategic research agenda for radiation protection in medicine",
        "authors": [
            "European Association of Nuclear Medicine",
            "European Federation of Organizations for Medical Physics",
            "European Federation of Radiographer Societies",
            "European Society of Radiology",
            "European Society for Radiotherapy and Oncology"
        ],
        "published_date": "2017",
        "abstract": "AbstractReflecting the change in funding strategies for European research projects, and the goal to jointly improve medical radiation protection through sustainable research efforts, five medical societies involved in the application of ionising radiation (European Association of Nuclear Medicine, EANM; European Federation of Organizations for Medical Physics. EFOMP; European Federation of Radiographer Societies, EFRS; European Society of Radiology, ESR; European Society for Radiotherapy and Oncology, ESTRO) have identified research areas of common interest and developed this first edition of the Common Strategic Research Agenda (SRA) for medical radiation protection.The research topics considered necessary and most urgent for effective medical care and efficient in terms of radiation protection are summarised in five main themes:1.Measurement and quantification in the field of medical applications of ionising radiation2.Normal tissue reactions, radiation-induced morbidity and long-term health problems3.Optimisation of radiation exposure and harmonisation of practices4.Justification of the use of ionising radiation in medical practice5.Infrastructures for quality assurance\n The SRA is a living document; thus comments and suggestions by all stakeholders in medical radiation protection are welcome and will be dealt with by the European Alliance for Medical Radiation Protection Research (EURAMED) established by the above-mentioned societies.Main messages\u2022 Overcome the fragmentation of medical radiation protection research in Europe\n \u2022 Identify research areas of joint interest in the field of medical radiation protection\n \u2022 Improve the use of ionising radiation in medicine\n \u2022 Collect stakeholder feedback and seek consensus\n \u2022 Emphasise importance of clinical translation and evaluation of research results",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/96579c44f66812d47e835e1264cde4211c9f0bd4.pdf",
        "venue": "Insights into Imaging",
        "citationCount": 0,
        "score": 0
    },
    "b2deb192850ed9cc8d58aade49e0eda7ffa256fd.pdf": {
        "title": "Bibliometric Analysis of Articles on Accounting and Covid-19 during the Pandemic",
        "authors": [
            "I. Firmansyah",
            "Aam Slamet Rusydiana"
        ],
        "published_date": "2021",
        "abstract": "",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/b2deb192850ed9cc8d58aade49e0eda7ffa256fd.pdf",
        "venue": "",
        "citationCount": 0,
        "score": 0
    },
    "227eb63a63d588f56d6f4d3d5e410a61381a804b.pdf": {
        "title": "BeCaked: An Explainable Artificial Intelligence Model for COVID-19 Forecasting",
        "authors": [
            "Duc Quang Nguyen",
            "N. Q. Vo",
            "T. Nguyen",
            "Khuong Nguyen-An",
            "Q. N. Nguyen",
            "D. N. Tran",
            "T. Quan"
        ],
        "published_date": "2021",
        "abstract": "From the end of 2019, one of the most serious and largest spread pandemics occurred in Wuhan (China) named Coronavirus (COVID-19). As reported by the World Health Organization, there are currently more than 100 million infectious cases with an average mortality rate of about five percent all over the world. To avoid serious consequences on people\u2019s lives and the economy, policies and actions need to be suitably made in time. To do that, the authorities need to know the future trend in the development process of this pandemic. This is the reason why forecasting models play an important role in controlling the pandemic situation. However, the behavior of this pandemic is extremely complicated and difficult to be analyzed, so that an effective model is not only considered on accurate forecasting results but also the explainable capability for human experts to take action pro-actively. With the recent advancement of Artificial Intelligence (AI) techniques, the emerging Deep Learning (DL) models have been proving highly effective when forecasting this pandemic future from the huge historical data. However, the main weakness of DL models is lacking the explanation capabilities. To overcome this limitation, we introduce a novel combination of the Susceptible-Infectious-Recovered-Deceased (SIRD) compartmental model and Variational Autoencoder (VAE) neural network known as BeCaked. With pandemic data provided by the Johns Hopkins University Center for Systems Science and Engineering, our model achieves 0.98 R2\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$R^2$$\\end{document} and 0.012 MAPE at world level with 31-step forecast and up to 0.99 R2\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$R^2$$\\end{document} and 0.0026 MAPE at country level with 15-step forecast on predicting daily infectious cases. Not only enjoying high accuracy, but BeCaked also offers useful justifications for its results based on the parameters of the SIRD model. Therefore, BeCaked can be used as a reference for authorities or medical experts to make on time right decisions.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/227eb63a63d588f56d6f4d3d5e410a61381a804b.pdf",
        "venue": "Scientific Reports",
        "citationCount": 0,
        "score": 0
    },
    "7dee85dea47eb0521522f4bb14ece1b0da6d8914.pdf": {
        "title": "Evaluation of the clinical characteristics of suspected or confirmed cases of COVID-19 during home care with isolation: A new retrospective analysis based on O2O",
        "authors": [
            "Hui Xu",
            "Sufang Huang",
            "Shangkun Liu",
            "J. Deng",
            "B. Jiao",
            "L. Ai",
            "Yaru Xiao",
            "Li Yan",
            "Shusheng Li"
        ],
        "published_date": "2020",
        "abstract": "Summary Background The recent outbreak of the novel coronavirus in December 2019 (COVID-19) has activated top-level response nationwide. We developed a new treatment model based on the online-to-offline (O2O) model for the home isolated patients, because in the early stages the medical staff were insufficient to cope with so many patients. Methods In this single-centered, retrospective study, we enrolled 48 confirmed/suspected COVID-19 patients who underwent home isolation in Wuhan between January 6 and January 31, 2020. By WeChat and online document editing all patients were treated with medical observation scale. The clinical indications such as Fever, Muscle soreness, Dyspnea and Lack of strength were collected with this system led by medical staff in management, medicine, nursing, rehabilitation and psychology. Findings The mean(SD) age of 48 patients was 39.08(13.88) years, 35(72.9%) were women. Compared with non-hospitalized patients, inpatients were older(\u22658805;70years, 2.4% vs 33.3%, P<0.04). All inpatients had fever, 50% inpatients had coughs and showed infiltration in both lungs at the time of diagnosis. 33.3% inpatients exhibited negative changes in their CT results at initial diagnosis. The body temperature of non-hospitalized patients with mild symptoms returned to normal by day 4-5. While dyspnea peaked on day 6 for non-hospitalized patients with mild symptoms, it persisted in hospitalized patients and exacerbated over time. The lack of strength and muscle soreness were both back to normal by day 4 for non-hospitalized patients. Interpretation Monitoring the trends of symptoms is more important for identifying severe cases. Excessive laboratory data and physical examination are not necessary for the evaluation of patients with mild symptoms. The system we developed is the first to convert the subjective symptoms of patients into objective scores. This type of O2O, subjective-to-objective strategy may be used in regions with similar highly infectious diseases to minimize the possibility of infection among medical staff.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/7dee85dea47eb0521522f4bb14ece1b0da6d8914.pdf",
        "venue": "medRxiv",
        "citationCount": 0,
        "score": 0
    },
    "4c400a0ff72487fc8dbc3abc858db14ad67789d4.pdf": {
        "title": "Stress Exposure and Physical, Mental, and Behavioral Health among American Indian Adults with Type 2 Diabetes",
        "authors": [
            "Melissa L. Walls",
            "Kelley J. Sittner",
            "B. Aronson",
            "Angie K. Forsberg",
            "L. Whitbeck",
            "M. al\u2019Absi"
        ],
        "published_date": "2017",
        "abstract": "American Indian (AI) communities experience disproportionate exposure to stressors and health inequities including type 2 diabetes. Yet, we know little about the role of psychosocial stressors for AI diabetes-related health outcomes. We investigated associations between a range of stressors and psychological, behavioral, and physical health for AIs with diabetes. This community-based participatory research with 5 AI tribes includes 192 AI adult type 2 diabetes patients recruited from clinical records at tribal clinics. Data are from computer-assisted interviews and medical charts. We found consistent bivariate relationships between chronic to discrete stressors and mental and behavioral health outcomes; several remained even after accounting for participant age, gender, and income. Fewer stressors were linked to physical health. We also document a dose\u2013response relationship between stress accumulation and worse health. Findings underscore the importance of considering a broad range of stressors for comprehensive assessment of stress burden and diabetes. Policies and practices aimed at reducing stress exposure and promoting tools for stress management may be mechanisms for optimal health for AI diabetes patients.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/4c400a0ff72487fc8dbc3abc858db14ad67789d4.pdf",
        "venue": "International Journal of Environmental Research and Public Health",
        "citationCount": 0,
        "score": 0
    },
    "063e16c467465a5399c5a30f4ca55a337f0dd502.pdf": {
        "title": "Integrating artificial intelligence and natural language processing for computer-assisted reporting and report understanding in nuclear cardiology",
        "authors": [
            "Ernest V. Garcia"
        ],
        "published_date": "2022",
        "abstract": "",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/063e16c467465a5399c5a30f4ca55a337f0dd502.pdf",
        "venue": "Journal of Nuclear Cardiology",
        "citationCount": 0,
        "score": 0
    },
    "ba160e3734af4b7aa7dc950192ffd5a50e9168b8.pdf": {
        "title": "Amelioration of diabetic nephropathy in db/db mice treated with tibetan medicine formula Siwei Jianghuang Decoction Powder extract",
        "authors": [
            "Xianrong Lai",
            "D. Tong",
            "Xiaopeng Ai",
            "Jiasi Wu",
            "Yu Luo",
            "F. Zuo",
            "Zhicheng Wei",
            "Yanqiao Li",
            "Wanyi Huang",
            "Wenqian Wang",
            "Qing Jiang",
            "Xianli Meng",
            "Yong Zeng",
            "Ping Wang"
        ],
        "published_date": "2018",
        "abstract": "Siwei Jianghuang Decoction Powder (SWJH) documented originally in the Four Medical Tantras-Blue Glaze exhibited beneficial effects on diabetic nephropathy (DN) via combined synergistically action of multiple formula components including Curcumae longae Rhizoma, Berberidis dictyophyllae Cortex, Phyllanthi Fructus and Tribuli Fructus. This study investigated the effects of SWJH on DN in db/db mice and possible underlying mechanisms. The ten weeks old db/db mice treated with SWJH by intra-gastric administration once a day for 8 weeks. After 8 weeks, body weight, water and food intake of mice were recorded. The level of fasting blood glucose (FBG) was measured. Serum creatinine (Scr), blood urea nitrogen (BUN), urine microalbumin (UMAlb), serum uric acid (UA) and urinary albumin excretion (UAE) were detected. An enzyme-linked immunosorbent assay was performed to test serum vascular endothelial growth factor (VEGF) and transforming growth factor-\u03b21 (TGF-\u03b21). Real-time PCR and Western blot analysis were used to test mRNA and protein expression of hypoxia inducible factor-1\u03b1 (HIF-1\u03b1), VEGF and TGF-\u03b21 in kidney tissue. SWJH treatment significantly reduced the levels of FBG, Scr, BUN, UMAlb, UA and UAE and retarded renal fibrosis. SWJH treatment further significantly reduced serum TGF-\u03b21 level and downregulated the expression of HIF-1\u03b1, VEGF and TGF-\u03b21 at both mRNA and protein levels. Principal component analysis and partial least squares regression and hierarchical cluster analysis demonstrated that SWJH treatment significantly ameliorated renal damage in DN mice. These consequences suggested that SWJH formulations were effective in the treatment of DN through regulating the HIF-1\u03b1, VEGF and TGF-\u03b21 overexpression.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/ba160e3734af4b7aa7dc950192ffd5a50e9168b8.pdf",
        "venue": "Scientific Reports",
        "citationCount": 0,
        "score": 0
    },
    "a830cda28038c474c0477e1991eb54d1c9c124d3.pdf": {
        "title": "Software as a Medical Device: Regulating AI in Healthcare via Responsible AI",
        "authors": [
            "M. Ahmad",
            "Steve Overman",
            "Christine Allen",
            "Vikas Kumar",
            "Ankur Teredesai",
            "C. Eckert"
        ],
        "published_date": "2021",
        "abstract": "With the increased adoption of AI in healthcare, there is a growing recognition and demand to regulate AI in healthcare to avoid potential harm and unfair bias against vulnerable populations. Around a hundred governmental bodies and commissions as well as leaders in the tech sector have proposed principles to create responsible AI systems. However, most of these proposals are short on specifics which has led to charges of ethics washing. In this tutorial we offer a guide to help navigate through complex governmental regulations and explain the various constituent practical elements of a responsible AI system in healthcare in the light of proposed regulations. Additionally, we breakdown and emphasize that the recommendations from regulatory bodies like FDA or the EU are necessary but not sufficient elements of creating a responsible AI system. We elucidate how regulations and guidelines often focus on epistemic concerns to the detriment of practical concerns e.g., requirement for fairness without explicating what fairness constitutes for a use case. FDA's Software as a medical device document and EU's GDPR among other AI governance documents talk about the need for implementing sufficiently good machine learning practices. In this tutorial we elucidate what that would mean from a practical perspective for real world use cases in healthcare throughout the machine learning cycle i.e., Data Management, Data Specification, Feature Engineering, Model Evaluation, Model Specification, Model Explainability, Model Fairness, Reproducibility, checks for data leakage and model leakage. We note that conceptualizing responsible AI as a process rather than an end goal accords well with how AI systems are used in practice. We also discuss how a domain centric stakeholder perspective translates into balancing requirements for multiple competing optimization criteria.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/a830cda28038c474c0477e1991eb54d1c9c124d3.pdf",
        "venue": "Knowledge Discovery and Data Mining",
        "citationCount": 0,
        "score": 0
    },
    "b86bae2d2a30fbe8a338021c98118967c3719c98.pdf": {
        "title": "Education and Communication in an Interprofessional Antimicrobial Stewardship Program",
        "authors": [
            "P. Foral",
            "Jennifer Anthone",
            "C. Destache",
            "R. Vivekanandan",
            "L. Preheim",
            "G. Gorby",
            "J. Horne",
            "Leo A. Dobronski",
            "J. Syed",
            "C. Mindru",
            "Mir A Ali",
            "Karim F. Ali",
            "Kari A Neemann",
            "M. Bittner"
        ],
        "published_date": "2016",
        "abstract": "",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/b86bae2d2a30fbe8a338021c98118967c3719c98.pdf",
        "venue": "The Journal of the American Osteopathic Association",
        "citationCount": 0,
        "score": 0
    },
    "0c79de253b4f7cac489665d5ecafe70375af57b4.pdf": {
        "title": "Assessing Vitamins, Minerals and Supplements Marketed to Children in Canada",
        "authors": [
            "Charlene Elliott"
        ],
        "published_date": "2019",
        "abstract": "Given the growth of supplements specifically designed for children in Canada, this study examines the nutrient levels of these products, and evaluates them in light of the US Health and Medical Division (HMD)\u2014formerly the Institute of Medicine\u2014and Health Canada\u2019s recommendations. Content analysis was used to document the nutrient levels of child-targeted vitamins, minerals and fish oils/omega-3s (n = 80) in Calgary, Alberta, Canada. Products were assessed according to HMD and Health Canada dosage recommendations for children, and the percentage of Estimate Average Requirements (EAR), Adequate Intakes (AI), and Tolerable Upper Intakes Level (UL) calculated. Median EAR/AI/UL percentages and quartiles were calculated for each nutrient, and estimates for the adequate intake recommendations plotted with box plots. Sixty five percent of the products assessed were multivitamins; the median dose was higher than AI recommendations for vitamins A, B6, B12, and C, as well as thiamin, riboflavin, pantothenic acid, and biotin. Substantial variation in vitamin, mineral, or fish oil dosage was found between similar supplements\u2014with nutrients such as vitamin B12 ranging from 83% to 5557% of AI. Such findings matter because the very existence of these products suggests that children should be taking them, yet more research is needed on their potential (adverse) effects over both the short and long term. The substantial variation in dosages between products also raises questions about the (perhaps unnecessary) fortification of our children, as well as the expectations that parents know\u2014or are even aware of\u2014appropriate nutrient levels for their kids.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/0c79de253b4f7cac489665d5ecafe70375af57b4.pdf",
        "venue": "International Journal of Environmental Research and Public Health",
        "citationCount": 0,
        "score": 0
    },
    "9f1804fb51570686108d2d94badb3baf84f8052d.pdf": {
        "title": "Promise and Perils of Big Data and Artificial Intelligence in Clinical Medicine and Biomedical Research.",
        "authors": [
            "F. Rodriguez",
            "David Scheinker",
            "R. Harrington"
        ],
        "published_date": "2018",
        "abstract": "The use of big data and AI to help guide clinical decisions is a central aspect of precision medicine initiatives. Yet, buzz words like big data and AI mystify many clinicians and biomedical researchers. Their widespread use in other industries and initial clinical applications can serve as a guide to a clearer understanding of what they are and are not, their promise, and their potential peril. Many common terms mean different things in different contexts. AI typically refers to a machine with human capabilities; machine learning (ML) may refer either to a set of computational and statistical tools for identifying relationships in data or to the use of such tools to make predictions based on data; deep neural networks are a particular type of ML whose success at tasks, such as image recognition, has led to them being referred to as AI or deep learning. Developing most AI, ML, and deep neural network tools requires access to big data\u2014another concept with multiple meanings. For data scientists, it implies using more data than one computer can handle with significant attendant analytical and computational challenges and opportunities; for clinicians and biomedical researchers, it refers to complex datasets with numerous structured and unstructured data fields, such as those typically found in electronic health records. Figure 1 illustrates the relationship between AI, ML, deep neural networks, and big data. Reinforcement learning is a notable exception to the use of big data to train AI. It is an approach to building AI tools based only on feedback. For example, DeepMind program AlphaGo Zero became the most powerful Go program in the world solely by playing against itself. Thus far, reinforcement learning in health care has been developed using historical data representing decisions and feedback. If (when) AI starts to make and test clinical decisions, algorithms will have the capacity to learn on their own. The widespread use of AI by companies such as Amazon and Google offers lessons for health care. Such industries have applied AI to enable smart electronic assistants, facial recognition software, and self-driving cars; the use and misuse of such applications have raised concerns about safety, fairness, and privacy. For example, data are increasingly being used to predict consumer behavior and preferences. Do I want the computers at a department store to know that I am pregnant before my family does? Will I be charged more for plane tickets if I buy them using an iPhone? There are numerous proof-of-concept examples of ML in health care. It has been applied to clinical risk prediction and to learning from the large volume of data generated by electronic health records and other large datasets. Notable recent examples include the classification of a picture of a nevus as malignant or benign, of a retinal fundus image to predict the risk of cardiovascular disease, and of using histopathology specimens to predict prognosis in lung cancer. In everyday clinical cardiology, ML has been used for interpreting automated ECG, determine left ventricular ejection fractions from echocardiography, and scoring coronary artery calcium scans. A form of AI known as computer vision is being developed to prevent clinical errors and improve patient safety. Although relatively few of these methods have been implemented in routine clinical practice, and none on a large scale, they demonstrate the promise of AI in clinical medicine and biomedical research. AI can be used to automate and simplify tasks too onerous or time-consuming for a single person or team to perform. What if we could use voice recognition software as a medical scribe to allow more doctoring and less documenting in patient exam rooms? What if we could aggregate a personalized cohort to ask simple, clinically relevant questions with a few clicks of our mouse? Research teams at Stanford University have developed a variety of approaches to leveraging data found in the electronic health record to help clinicians make decisions based on a patient\u2019s unique characteristics. One such approach allows a physician considering a decision to call for an informatics consult. This triggers an ML algorithm that identifies patients similar to the one being considered and presents their treatments and outcomes. Similar tools could be used to quickly identify patients who meet criteria for entry into randomized clinical trials, dramatically cutting enrollment and recruitment costs. In translational research, ML can efficiently identify candidate molecules for drug development. ML can better risk stratify populations underrepresented in our available evidence base and identify patterns and relationships not captured by traditional statistical methods. The opinions expressed in this article are not necessarily those of the editors or of the American Heart Association. From the Division of Cardiovascular Medicine, Cardiovascular Institute (F.R., R.A.H.), Department of Medicine (F.R., R.A.H.), and Department of Management Science and Engineering (D.S.), Stanford University, CA. Correspondence to Fatima Rodriguez, MD, MPH, Division of Cardiovascular Medicine, Stanford University School of Medicine, 870 Quarry Rd, Falk CVRC, Stanford, CA 94305\u20135406. Email frodrigu@ stanford.edu Viewpoints",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/9f1804fb51570686108d2d94badb3baf84f8052d.pdf",
        "venue": "Circulation Research",
        "citationCount": 0,
        "score": 0
    },
    "827e91572a0e6e3dba0d0c81d0e4e74b99a39d74.pdf": {
        "title": "Rationalizing medical work",
        "authors": [
            "P. Taylor"
        ],
        "published_date": "2016",
        "abstract": "",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/827e91572a0e6e3dba0d0c81d0e4e74b99a39d74.pdf",
        "venue": "Journal of Health Services Research and Policy",
        "citationCount": 0,
        "score": 0
    },
    "69afe1e8f19e3a2c3837abff5151b2630b0de177.pdf": {
        "title": "Analyzing the Coronary Heart Disease Mortality Decline in a Mediterranean Population : Spain 1988-2005",
        "authors": [
            "G. Flores-Mateo",
            "M. Grau",
            "M. O\u2019Flaherty",
            "R. Ramos",
            "R. Elos\u00faa",
            "Concepci\u00f3n Viol\u00e1n-Fors",
            "M. Quesada",
            "J. Sala",
            "J. Marrugat",
            "Simon Capewelld"
        ],
        "published_date": "2011",
        "abstract": "",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/69afe1e8f19e3a2c3837abff5151b2630b0de177.pdf",
        "venue": "",
        "citationCount": 0,
        "score": 0
    },
    "b85d6105f79e214efde9dfd93e1330cd86580db3.pdf": {
        "title": "Relationship of Serum Soluble Klotho Levels and Echocardiographic Parameters in Patients on Maintenance Hemodialysis",
        "authors": [
            "Ai-hua Zhang",
            "Weikang Guo",
            "Ling Yu",
            "Wen-Hu Liu"
        ],
        "published_date": "2019",
        "abstract": "Background: Cardiovascular disease is the leading cause of morbidity and mortality in maintenance hemodialysis (MHD) patients. Uremic cardiomyopathy, characterized by myocardial hypertrophy and fibrosis, has a significant contribution to these adverse cardiac outcomes. The protective effect of soluble Klotho (s-Klotho) on myocardial damage was demonstrated in in vitro and animal experiments. However, data from MHD patients is limited. The present study was designed to identify potential correlations between echocardiographic parameters and serum s-Klotho levels in MHD patients. Methods: This is a cross-sectional study involving 105 MHD patients from the Dialysis Center of Capital Medical University affiliated Beijing Friendship Hospital between March and October 2014. The general information for each patient was recorded. Fasting blood samples were collected prior to hemodialysis during the mid-week session in all patients. The echocardiogram and left lateral lumbar spine radiograph were performed after the same mid-week session. The dialysis records for each session within 3 months before the blood tests were documented. According to the quartiles of s-Klotho levels, patients were divided into four groups (Group 1\u20134). The demographic and clinical characteristics, echocardiographic parameters, and abdominal aortic calcification scores among the groups were compared. Results: The enrolled 105 patients were predominantly male (54.3%) with an average age of 59.9 \u00b1 11.2 years. Previous hemodialysis durations were 76 (42\u2013133) months. Sixteen (15.2%) patients had diabetes mellitus. Mean serum s-Klotho level was 411.83 \u00b1 152.95 pg/mL, and the 25th percentile, 50th percentile, and 75th percentile values of serum s-Klotho levels were 298.9, 412, and 498.2 pg/mL, respectively. Individuals in the bottom quartile of s-Klotho levels (Group 1) had significantly increased interventricular septal thickness (IVST) compared to those in the other three quartiles of s-Klotho levels (Group 1: 1.12 \u00b1 0.16 cm; vs. Group 2: 1.12 \u00b1 0.16 cm, p = 0.008; vs. Group 3: 0.94 \u00b1 0.13 cm, p < 0.001; vs. Group 4: 1.03 \u00b1 0.1 5 cm, p = 0.022). There were significant differences in the ratios of IVST and posterior wall thickness (PWT) between patients of Group 1 and Group 3 (1.12 \u00b1 0.1 2 vs. 1.00 \u00b1 0.1 4, p = 0.004). No significant differences were found for other parameters among the groups. The univariate correlation analyses showed that gender (r = \u20130.211, p = 0.030), Kt/V urea (r = \u20130.240, p = 0.014), hypersensitive C reactive protein (hs-CRP) (r = 0.196, p = 0.045), and serum s-Klotho levels (r = \u20130.260, p = 0.007) significantly correlated with IVST. Ultimately, only hs-CRP and serum s-Klotho levels were entered into a multiple regression model. Conclusions: The present study showed that patients with lower circulating s-Klotho levels were more often associated with larger IVST and greater ratios of IVST and PWT. There was an independent association between s-Klotho and IVST, and lower s-Klotho levels seem to be a potential risk factor of uremic cardiomyopathy in MHD patients.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/b85d6105f79e214efde9dfd93e1330cd86580db3.pdf",
        "venue": "Kidney & Blood Pressure Research",
        "citationCount": 0,
        "score": 0
    },
    "b3c553eda3f8684847f30ab44f34a741ad38b4ce.pdf": {
        "title": "Incidence and management of arthralgias in breast cancer patients treated with aromatase inhibitors in an outpatient oncology clinic",
        "authors": [
            "P. Menas",
            "D. Merkel",
            "W. Hui",
            "J. Lawton",
            "A. Harper",
            "G. Carro"
        ],
        "published_date": "2012",
        "abstract": "",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/b3c553eda3f8684847f30ab44f34a741ad38b4ce.pdf",
        "venue": "Journal of Oncology Pharmacy Practice",
        "citationCount": 0,
        "score": 0
    },
    "45b70dbd9fd89d0e00252d41469429569ee053ab.pdf": {
        "title": "Technical Design Report for the: PANDA Micro Vertex Detector",
        "authors": [
            "P. C. W. Erni",
            "I. Keshelashvili",
            "B. Krusche",
            "M. Steinacher",
            "Y. Heng",
            "Z. Liu",
            "H. Liu",
            "X. Shen",
            "Q. Wang",
            "H. Xu",
            "M. Albrecht",
            "J. Becker",
            "K. Eickel",
            "F. Feldbauer",
            "M. Fink",
            "P. Friedel",
            "F. Heinsius",
            "T. Held",
            "H. Koch",
            "B. Kopf",
            "M. Leyhe",
            "C. Motzko",
            "M. Pelizaus",
            "J. Pychy",
            "B. Roth",
            "T. Schroder",
            "J. Schulze",
            "M. Steinke",
            "T. Trifterer",
            "U. Wiedner",
            "J. Zhong",
            "R. Beck",
            "M. Becker",
            "S. Bianco",
            "K. Brinkmann",
            "C. Hammann",
            "F. Hinterberger",
            "R. Jakel",
            "D. Kaiser",
            "R. Kliemt",
            "K. Koop",
            "C. Schmidt",
            "R. Schnell",
            "U. Thoma",
            "P. Vlasov",
            "C. Wendel",
            "A. Winnebeck",
            "T. Wurschig",
            "H. Zaunick",
            "A. Bianconi",
            "M. Bragadireanu",
            "M. Caprini",
            "M. Ciubancan",
            "D. Pantea",
            "P. Tarta",
            "M. Napoli",
            "F. Giacoppo",
            "E. Rapisarda",
            "C. Sfienti",
            "T. Fiutowski",
            "N. Idzik",
            "B. Mindur",
            "D. Przyborowski",
            "K. \u015awientek",
            "E. Bialkowski",
            "A. Budzanowski",
            "B. Czech",
            "S. Kliczewski",
            "A. Kozela",
            "P. Kulessa",
            "P. Lebiedowicz",
            "K. Malgorzata",
            "K. Pysz",
            "W. Schafer",
            "R. Siudak",
            "A. Szczurek",
            "P. Brandys",
            "T. Czy\u017cewski",
            "W. Czy\u017cycki",
            "M. Domagala",
            "M. Hawryluk",
            "G. Filo",
            "D. Kwiatkowski",
            "E. Lisowski",
            "F. Lisowski",
            "W. Bardan",
            "D. Gil",
            "B. Kamys",
            "S. Kistryn",
            "K. Korcyl",
            "W. Krzemie\u0144",
            "A. Magiera",
            "P. Moskal",
            "Z. Rudy",
            "P. Salabura",
            "J. Smyrski",
            "A. Wro\u0144ska",
            "M. Al-Turany",
            "R. Arora",
            "I. Augustin",
            "H. Deppe",
            "D. Dutta",
            "H. Flemming",
            "K. Gotzen",
            "G. Hohler",
            "R. Karabowicz",
            "D. Lehmann",
            "B. Lewandowski",
            "J. Luhning",
            "F. Maas",
            "H. Orth",
            "K. Peters",
            "T. Saito",
            "G. Schepers",
            "C. Schmidt",
            "L. Schmitt",
            "C. Schwarz",
            "J. Schwiening",
            "B. Voss",
            "P. Wieczorek",
            "A. Wilms",
            "V. Abazov",
            "G. Alexeev",
            "V. Arefiev",
            "V. Astakhov",
            "M. Barabanov",
            "B. Batyunya",
            "Y. Davydov",
            "V. Dodokhov",
            "A. Efremov",
            "A. Fedunov",
            "A. Feshchenko",
            "A. Galoyan",
            "S. Grigoryan",
            "A. Karmokov",
            "E. Koshurnikov",
            "V. Lobanov",
            "Y. Lobanov",
            "A. Makarov",
            "L. Malinina",
            "V. Malyshev",
            "G. A. Mustafaev",
            "A. Olshevski",
            "M. Pasyuk",
            "E. Perevalova",
            "A. A. Piskun",
            "T. Pocheptsov",
            "G. Pontecorvo",
            "V. Rodionov",
            "Y. Rogov",
            "R. Salmin",
            "A. Samartsev",
            "M. Sapozhnikov",
            "G. Shabratova",
            "A. Skachkova",
            "N. B. Skachkov",
            "E. Strokovsky",
            "M. Suleimanov",
            "R. Teshev",
            "V. Tokmenin",
            "V. Uzhinsky",
            "A. Vodopyanov",
            "S. Zaporozhets",
            "N. Zhuravlev",
            "A. Zorin",
            "D. Branford",
            "D. Glazier",
            "D. Watts",
            "P. Woods",
            "A. Britting",
            "W. Eyrich",
            "A. Lehmann",
            "F. Uhlig",
            "S. Dobbs",
            "Z. Metreveli",
            "K. Seth",
            "B. Tann",
            "A. Tomaradze",
            "D. Bettoni",
            "V. Carassiti",
            "P. Dalpiaz",
            "A. Drago",
            "E. Fioravanti",
            "I. Garzia",
            "M. Negrini",
            "M. Savri\u00e9",
            "G. Stancari",
            "B. Dulach",
            "P. Gianotti",
            "C. Guaraldo",
            "V. Lucherini",
            "E. Pace",
            "A. Bersani",
            "M. Macri",
            "M. Marinelli",
            "R. Parodi",
            "V. Dormenev",
            "P. Drexler",
            "M. Duren",
            "T. Eisner",
            "K. Foehl",
            "A. Hayrapetyan",
            "P. Koch",
            "B. Krioch",
            "W. Kuhn",
            "S. Lange",
            "Y. Liang",
            "M. Liu",
            "O. Merle",
            "V. Metag",
            "M. Moritz",
            "M. Nanova",
            "R. Novotn\u00fd",
            "B. Spruck",
            "H. Stenzel",
            "C. Strackbein",
            "M. Thiel",
            "T. Clarkson",
            "C. Euan",
            "G. Hill",
            "M. Hoek",
            "D. Ireland",
            "R. Kaiser",
            "T. Keri",
            "I. Lehmann",
            "K. Livingston",
            "P. Lumsden",
            "D. MacGregor",
            "B. McKinnon",
            "R. Montgomery",
            "M. Murray",
            "D. Protopopescu",
            "G. Rosner",
            "B. Seitz",
            "G. Yang",
            "M. Babai",
            "A. Biegun",
            "A. Glazenborg-Kluttig",
            "E. Guliyev",
            "V. Jothi",
            "M. Kavatsyuk",
            "P. Lemmens",
            "H. Lohner",
            "J. Messchendorp",
            "T. Poelman",
            "H. Smit",
            "J. C. Weele",
            "H. Sohlbach",
            "M. Buscher",
            "R. Dosdall",
            "R. Dzhygadlo",
            "S. Esch",
            "A. Gillitzer",
            "F. Goldenbaum",
            "D. Grunwald",
            "V. Jha",
            "G. Kemmerling",
            "H. Kleines",
            "A. Lehrach",
            "R. Maier",
            "M. Mertens",
            "H. Ohm",
            "D. Pohl",
            "D. Prasuhn",
            "T. Randriamalala",
            "J. Ritman",
            "M. Roeder",
            "G. Sterzenbach",
            "T. Stockmanns",
            "P. Wintz",
            "P. Wustner",
            "J. Kisiel",
            "S. Li",
            "Z. Li",
            "Z. Sun",
            "K. Fissum",
            "K. Hansen",
            "L. Isaksson",
            "M. Lundin",
            "B. Schroder",
            "P. Achenbach",
            "A. Denig",
            "M. Distler",
            "M. Fritsch",
            "D. Kangh",
            "A. Karavdina",
            "W. Lauth",
            "M. Michel",
            "M. C. M. Espi",
            "J. Pochodzalla",
            "S. S\u00e1nchez",
            "A. Sanchez-Lorente",
            "T. Weber",
            "V. Dormenev",
            "A. Fedorov",
            "M. Korzhik",
            "O. Missevitch",
            "V. Balanutsa",
            "V. Chernetsky",
            "A. Demekhin",
            "A. Dolgolenko",
            "P. Fedorets",
            "A. Gerasimov",
            "V. Goryachev",
            "A. Boukharov",
            "O. Malyshev",
            "I. Marishev",
            "A. Semenov",
            "R. Varma",
            "B. Ketzer",
            "I. Konorov",
            "A. Mann",
            "S. Neubert",
            "S. Paul",
            "M. Vandenbroucke",
            "Q. Zhang",
            "A. Khoukaz",
            "T. Rausmann",
            "A. Taschner",
            "J. Wessels",
            "E. Baldin",
            "K. Kotov",
            "S. Peleganchuk",
            "Y. Tikhonov",
            "T. Hennino",
            "M. Imre",
            "R. Kunne",
            "C. L. Galliard",
            "J. L. Normand",
            "D. Marchand",
            "A. Maroni",
            "S. Ong",
            "J. Pouthas",
            "B. Ramstein",
            "P. Rosier",
            "M. Sudol",
            "C. Th\u00e9neau",
            "E. Tomasi-Gustafsson",
            "J. Wiele",
            "T. Zerguerras",
            "G. Boca",
            "A. Braghieri",
            "S. Costanza",
            "A. Fontana",
            "P. Genova",
            "L. Lavezzi",
            "P. Montagna",
            "A. Rotondi",
            "V. Buda",
            "V. Abramov",
            "A. Davidenko",
            "A. Derevschikov",
            "Y. Goncharenko",
            "V. Grishin",
            "V. Kachanov",
            "D. Konstantinov",
            "V. Kormilitsin",
            "Y. Matulenko",
            "Y. Melnik",
            "A. Meschanin",
            "N. Minaev",
            "V. Mochalov",
            "D. Morozov",
            "L. Nogach",
            "S. Nurushev",
            "A. Ryazantsev",
            "P. Semenov",
            "L. Soloviev",
            "A. Uzunian",
            "A. Vasiliev",
            "A. Yakutin",
            "S. Belostotski",
            "G. Gavrilov",
            "A. Itzotov",
            "A. Kisselev",
            "P. Kravchenko",
            "S. Manaenkov",
            "O. Miklukho",
            "Y. Naryshkin",
            "D. Veretennikov",
            "V. Vikhrov",
            "A. Zhadanov",
            "T. Back",
            "B. Cederwall",
            "C. Bargholtz",
            "L. Ger'en",
            "P. Tegn'er",
            "P. Thorngren",
            "K. M. V. Wurtemberg",
            "L. Fava",
            "D. Alberto",
            "A. Amoroso",
            "M. Bussa",
            "L. Busso",
            "F. Mori",
            "M. Destefanis",
            "L. Ferrero",
            "M. Greco",
            "T. Kugathasan",
            "M. Maggiora",
            "S. Marcello",
            "S. Sosio",
            "S. Spataro",
            "D. Calvo",
            "S. Coli",
            "P. Remigis",
            "A. Filippi",
            "G. Giraudo",
            "S. Lusso",
            "G. Mazza",
            "M. Mignone",
            "A. Rivetti",
            "R. Wheadon",
            "L. Zotti",
            "O. Morra",
            "F. Iazzi",
            "A. Lavagno",
            "P. Quarati",
            "K. Szymanska",
            "R. Birsa",
            "F. Bradamante",
            "A. Bressan",
            "A. Martin",
            "H. Clement",
            "B. G\u00e5lnander",
            "H. Cal'en",
            "K. Fransson",
            "T. Johansson",
            "A. Kupsc",
            "P. Marciniewski",
            "E. Thom'e",
            "M. Wolke",
            "J. Zlomanczuk",
            "J. D'iaz",
            "A. Ortiz",
            "P. Buda",
            "K. Dmowski",
            "R. Korzeniewski",
            "D. Przemyslaw",
            "B. Slowinski",
            "S. Borsuk",
            "A. Chlopik",
            "Z. Guzik",
            "J. Kopec",
            "T. Koz\u0142owski",
            "D. Melnychuk",
            "M. P\u0142omi\u0144ski",
            "J. Szewinski",
            "K. Traczyk",
            "B. Zwi\u0229gli\u0144ski",
            "P. Buhler",
            "A. Gruber",
            "P. Kienle",
            "J. Marton",
            "E. Widmann",
            "J. Z. U. B. Switzerland",
            "Institute for High Energy Physics",
            "Chinese Academy of Sciences",
            "Beijing China",
            "Universitat Bochum I. Institut fur Experimentalphysik",
            "Germany",
            "R. Germany",
            "Universita di Brescia Italy",
            "Institutul National de CD pentru Fizica si Inginerie Nucleara Hulubei",
            "Bukarest-Magurele Romania",
            "D. D. F. E. A. U. D. Catania",
            "Infn",
            "Sezione di Catania Italy",
            "A. U. O. Science",
            "Technology Cracow Poland",
            "Ifj",
            "Institute of Nuclear Physics Pan",
            "Cracow Poland",
            "I. Informatics",
            "University of Technology",
            "Instytut Fizyki",
            "Uniwersytet Jagiello\u0144ski",
            "Gesellschaft f\u00fcr Schwerionenforschung Mbh",
            "D. Germany",
            "Veksler-Baldin Laboratory of High Energies",
            "University of Edinburgh United Kingdom",
            "Friedrich Alexander Universitat Erlangen-Nurnberg Germany",
            "N. University",
            "A. EvanstonU.S.",
            "U. Ferrara",
            "Sezione di Ferrara",
            "Italy",
            "INFN-Laboratori Nazionali di Frascati Italy",
            "Sezione di Genova Italy",
            "J. N. I. P. Institut",
            "University of Edinburgh United Kingdom",
            "Kernfysisch Versneller Instituut",
            "University of Groningen Netherlands",
            "Fachhochschule Sudwestfalen",
            "Iserlohn Germany",
            "Forschungszentrum Julich",
            "I. F. Kernphysik",
            "J. Germany",
            "U. Silesia",
            "Katowice Poland"
        ],
        "published_date": "2012",
        "abstract": "This document illustrates the technical layout and the expected performance of the Micro Vertex Detector (MVD) of the PANDA experiment. The MVD will detect charged particles as close as possible to the interaction zone. Design criteria and the optimisation process as well as the technical solutions chosen are discussed and the results of this process are subjected to extensive Monte Carlo physics studies. The route towards realisation of the detector is outlined.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/45b70dbd9fd89d0e00252d41469429569ee053ab.pdf",
        "venue": "",
        "citationCount": 0,
        "score": 0
    },
    "0b0e093a33e9538cbf04075220fc0f15e03c2807.pdf": {
        "title": "Abemaciclib with or without fulvestrant for the treatment of hormone receptor-positive and HER2-negative metastatic breast cancer with disease progression following prior treatment with palbociclib.",
        "authors": [
            "Keerthi Tamragouri",
            "M. Cobleigh",
            "R. Rao"
        ],
        "published_date": "2019",
        "abstract": "e12533 Background: Abemaciclib is a selective inhibitor of CDK4 and CDK6 kinase activity. It is approved for patients with hormone receptor (HR) positive, human epidermal growth factor receptor 2 (HER2) negative, advanced or metastatic breast cancer (MBC) previously treated: in combination with fulvestrant for patients with disease progression following endocrine therapy (MONARCH 2) and as monotherapy for patients with disease progression after endocrine therapy and chemotherapy for MBC (MONARCH 1). The patients in these trials were CDK 4/6 inhibitor-na\u00efve. It has not yet been studied in patients who previously received a CDK 4/6 inhibitor. Methods: We performed a chart review of patients with HR positive, HER2-negative MBC treated at Rush University Medical Center who progressed on palbociclib, either with an aromatase inhibitor (AI) or fulvestrant, and were subsequently treated with abemaciclib with or without fulvestrant. We documented patient demographics, prior treatment, and response to abemaciclib therapy. Results: 21 female patients, mean age 57.8 (+/- 13.2y), were included. Patients had received 1-5 prior lines of endocrine therapy and 0 \u2013 4 prior lines of chemotherapy for MBC. All patients received prior palbociclib: 14 patients with an AI, 6 patients with fulvestrant, and 1 patient received palbociclib with an AI and then with fulvestrant. Of the 21 patients, 17 were treated with abemaciclib monotherapy and 4 received abemaciclib with fulvestrant. SD was seen in 19% of patients (4/21) and 62% had PD (13/21). The CBR was 29% (6/21) and all of these patients received abemaciclib monotherapy. Due to expected toxicities of the drug (diarrhea, neutropenia, and thrombocytopenia), 19% (4/21) of patients discontinued treatment. 4 patients continued abemaciclib monotherapy for greater than 8.3M. 3 patients were on treatment for less than 35 days; 2 stopped due to expected toxicities and one had progression of disease on physical exam. Median treatment duration was 3.1M. Conclusions: This retrospective chart review of 21 patients demonstrates that abemaciclib has limited activity as a single agent in patients previously treated with palbociclib.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/0b0e093a33e9538cbf04075220fc0f15e03c2807.pdf",
        "venue": "Journal of Clinical Oncology",
        "citationCount": 0,
        "score": 0
    },
    "5541f38af192fb2df8f985b4f3dd0f3571aae20c.pdf": {
        "title": "Enhancing cardiovascular artificial intelligence (AI) research in the Netherlands: CVON-AI consortium",
        "authors": [
            "J. Benjamins",
            "K. V. Leeuwen",
            "L. Hofstra",
            "M. Rienstra",
            "Y. Appelman",
            "W. Nijhof",
            "B. Verlaat",
            "I. Everts",
            "H. D. Ruijter",
            "Ivana I\u0161gum",
            "T. Leiner",
            "R. Vliegenthart",
            "F. Asselbergs",
            "L. Ju\u00e1rez-Orozco",
            "P. Harst"
        ],
        "published_date": "2019",
        "abstract": "BackgroundMachine learning (ML) allows the exploration and progressive improvement of very complex high-dimensional data patterns that can be utilised to optimise specific classification and prediction tasks, outperforming traditional statistical approaches. An enormous acceleration of ready-to-use tools and artificial intelligence (AI) applications, shaped by the emergence, refinement, and application of powerful ML algorithms in several areas of knowledge, is ongoing. Although such progress has begun to permeate the medical sciences and clinical medicine, implementation in cardiovascular medicine and research is still in its infancy.ObjectivesTo lay out the theoretical framework, purpose, and structure of a\u00a0novel AI consortium.MethodsWe have established a\u00a0new Dutch research consortium, the CVON-AI, supported by the Netherlands Heart Foundation, to catalyse and facilitate the development and utilisation of AI solutions for existing and emerging cardiovascular research initiatives and to raise AI awareness in the cardiovascular research community. CVON-AI will connect to previously established CVON consortia and apply a\u00a0cloud-based AI platform to supplement their planned traditional data-analysis approach.ResultsA\u00a0pilot experiment on the CVON-AI cloud was conducted using cardiac magnetic resonance data. It demonstrated the feasibility of the platform and documented excellent correlation between AI-generated ventricular function estimates as compared to expert manual annotations. The resulting AI solution was then integrated in a\u00a0web application.ConclusionCVON-AI is a\u00a0new consortium meant to facilitate the implementation and raise awareness of AI in cardiovascular research in the Netherlands. CVON-AI will create an accessible cloud-based platform for cardiovascular researchers, demonstrate the clinical applicability of AI, optimise the analytical methodology of other ongoing CVON consortia, and promote AI awareness through education and training.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/5541f38af192fb2df8f985b4f3dd0f3571aae20c.pdf",
        "venue": "Netherlands Heart Journal",
        "citationCount": 0,
        "score": 0
    },
    "fb627fa84455c92cc3b4c4dcf9ce69f732196d24.pdf": {
        "title": "Epidemiological survey and analysis on an outbreak of gastroenteritis due to water contamination.",
        "authors": [
            "Zhicong Yang",
            "Xinwei Wu",
            "Tiegang Li",
            "Mei-xia Li",
            "Yi Zhong",
            "Yu-fei Liu",
            "Z. Deng",
            "B. Di",
            "Cong Huang",
            "Hui-ying Liang",
            "Ming Wang"
        ],
        "published_date": "2011",
        "abstract": "",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/fb627fa84455c92cc3b4c4dcf9ce69f732196d24.pdf",
        "venue": "Biomedical and environmental sciences : BES",
        "citationCount": 0,
        "score": 0
    },
    "84c7c05ac44ecc4fce04d62b49d9ada2cdcc7e32.pdf": {
        "title": "Changes in Food Choices of Participants in the Special Diabetes Program for Indians\u2013Diabetes Prevention Demonstration Project, 2006\u20132010",
        "authors": [
            "N. Teufel-Shone",
            "Luohua Jiang",
            "J. Beals",
            "W. Henderson",
            "K. Acton",
            "Y. Roubideaux",
            "S. Manson"
        ],
        "published_date": "2015",
        "abstract": "Introduction American Indians/Alaska Natives (AI/ANs) have a disproportionately high rate of type 2 diabetes. Changing food choices plays a key role in preventing diabetes. This study documented changes in the food choices of AI/ANs with diagnosed prediabetes who participated in a diabetes prevention program. Methods The Special Diabetes Program for Indians\u2013Diabetes Prevention Demonstration Project implemented the evidence-based Diabetes Prevention Program (DPP) lifestyle intervention in 36 health care programs nationwide, engaging 80 AI/AN communities. At baseline, at 30 days post-curriculum, and at the first annual assessment, participants completed a sociodemographic survey and 27-item food frequency questionnaire and underwent a medical examination assessing fasting blood glucose (FBG), blood pressure, body mass index (BMI), low-density lipoprotein [LDL], high-density lipoprotein [HDL], and triglycerides. Multiple linear regressions were used to assess the relationship between temporal changes in food choice and other diabetes risk factors. Results From January 2006 to July 2010, baseline, post-curriculum, and first annual assessments were completed by 3,135 (100%), 2,046 (65%), and 1,480 (47%) participants, respectively. An increase in healthy food choices was associated initially with reduced bodyweight, BMI, FBG, and LDL and increased physical activity. At first annual assessment, the associations persisted between healthy food choices and bodyweight, BMI, and physical activity. Conclusion AI/AN adults from various tribal and urban communities participating in this preventive intervention made sustained changes in food choices and had reductions in diabetes risk factors. The outcomes demonstrate the feasibility and effectiveness of translating the DPP lifestyle intervention to community-based settings.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/84c7c05ac44ecc4fce04d62b49d9ada2cdcc7e32.pdf",
        "venue": "Preventing Chronic Disease",
        "citationCount": 0,
        "score": 0
    },
    "858f5cd62d8ee1fdcd13461989797a4f784fef37.pdf": {
        "title": "A Picture is Worth 1,000 Words",
        "authors": [
            "Angela Ai",
            "F. Maloney",
            "Thu-Trang T. Hickman",
            "A. Wilcox",
            "H. Ramelson",
            "A. Wright"
        ],
        "published_date": "2017",
        "abstract": "",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/858f5cd62d8ee1fdcd13461989797a4f784fef37.pdf",
        "venue": "Applied Clinical Informatics",
        "citationCount": 0,
        "score": 0
    },
    "7c38bdd888c1ff4e84125ccd54a0b515c02d585b.pdf": {
        "title": "Application of Minimum Effective Cuff Inflating Volume for Laryngeal Mask Airway and its Impact on Postoperative Pharyngeal Complications",
        "authors": [
            "Bing-bing Li",
            "Jie Yan",
            "Hong-Gang Zhou",
            "Jing Hao",
            "Ai-Jia Liu",
            "Zheng-liang Ma"
        ],
        "published_date": "2015",
        "abstract": "Background:High intracuff pressure can cause severe pharyngeal complications including sore throat or hoarseness after laryngeal mask airway (LMA) removal postoperatively. Though the application of minimum effective cuff inflating volume is suggested to maintain airway sealing and adequacy of ventilation for patients receiving general anesthesia with LMA at lower level of the intracuff pressure, it is currently not a standard care in most of the anesthetic departments. In this study, the minimum effective cuff inflating volume was determined for classic LMA Well Lead\u2122 (Well Lead Medical Co., Ltd., China) and its impact on postoperative pharyngeal complications was also explored. Methods:Patients with American Society of Anesthesiologists physical status (I\u2013III) undergoing the short-duration urological surgery were recruited in this trial. First, the minimum effective cuff inflating volume was determined for size 4 or 5 LMA Well LeadTM in the study 1. Immediately following placement and confirmation of ideal LMA position, the cuff was inflated with 5, 7, 10 ml of air and up to 30 ml at 5 ml increment. The intracuff pressure, oropharyngeal leak pressure (OLP), and inspiratory peak airway pressure under positive pressure ventilation at the corresponding cuff volume as indicated above were recorded. Second, the enrolled patients were randomly allocated into minimum effective cuff inflating volume group (MC) and routine care (RC) group in the study 2. The minimum effective cuff inflating volume was applied and maintained in MC group, whereas the cuff volume was inflated with half of the maximum cuff inflating volume recommended by manufacturer in RC group throughout the surgical procedure and stay in postanesthesia care unit prior to LMA removal. The incidence of pharyngeal complications at 0, 2, 24, and 48 h after removal of LMA and other intra-operative adverse events were also documented. Results:The intracuff pressure varied with the cuff inflating volume in a positive linear correlation manner (Y = 11.68X \u2212 42.1, r2 = 0.9191) under the range of 5\u201330 ml for size 4 LMA. In similar with size 4 LMA, the data were also showed the linear relationship between the intracuff pressure and the cuff inflating volume (Y = 7.39X \u2212 10.9, r2 = 0.8855) for size 5 LMA. The minimal effective cuff inflating volume for size 4 or 5 LMA was 7\u20139 ml in combination of considering OLP needed to maintain airway sealing during intermittently positive pressure ventilation. The intracuff pressure in MC group was lower compared with RC group (63.0 \u00b1 3.7 vs. 126.4 \u00b1 24.0 cmH2O for size 4 LMA; 55.6 \u00b1 2.4 vs. 138.5\u00b1 26.8 cmH2O for size 5 LMA; P < 0.0001). The incidence of pharyngeal adverse events was lower in MC group versus the RC group at 2, 24 h after LMA removal. Conclusions:The relationship between the cuff inflating volume and the intracuff pressure for size 4 or 5 LMA Well Lead\u2122 is in a linear correlation manner at the range of 5\u201330 ml. The minimal cuff inflating volume is adequate for satisfactory airway sealing and consequently associated with lower incidence of postoperative pharyngeal complications for LMA Well Lead.\u2122",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/7c38bdd888c1ff4e84125ccd54a0b515c02d585b.pdf",
        "venue": "Chinese Medical Journal",
        "citationCount": 0,
        "score": 0
    },
    "7df3f31e4f57679346121df58c9c6d7bdc1609fd.pdf": {
        "title": "The vegetative state: A syndrome seeking revision?",
        "authors": [
            "G. Dolce",
            "W. Sannita",
            "for the European Task Force on the Vegetative Stat"
        ],
        "published_date": "2010",
        "abstract": "",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/7df3f31e4f57679346121df58c9c6d7bdc1609fd.pdf",
        "venue": "Brain Injury",
        "citationCount": 0,
        "score": 0
    },
    "489fe30cd7221507126579f37694f5d99277bd91.pdf": {
        "title": "An early history of human breast cancer: West meets East",
        "authors": [
            "S. Yan"
        ],
        "published_date": "2013",
        "abstract": "Cancer has been increasingly recognized as a global issue. This is especially true in countries like China, where cancer incidence has increased likely because of changes in environment and lifestyle. However, cancer is not a modern disease; early cases have been recorded in ancient medical books in the West and in China. Here, we provide a brief history of cancer, focusing on cancer of the breast, and review the etymology of ai, the Chinese character for cancer. Notable findings from both Western and Chinese traditional medicine are presented to give an overview of the most important, early contributors to our evolving understanding of human breast cancer. We also discuss the earliest historical documents to record patients with breast cancer.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/489fe30cd7221507126579f37694f5d99277bd91.pdf",
        "venue": "Chinese journal of cancer",
        "citationCount": 0,
        "score": 0
    },
    "1c2a38413583c6836f11b88edebf65577e1450bd.pdf": {
        "title": "Exploring the role of ChatGPT in patient care (diagnosis and treatment) and medical research: A systematic review",
        "authors": [
            "R. Garg",
            "V. L. Urs",
            "Akshya Anand Agrawal",
            "S. Chaudhary",
            "V. Paliwal",
            "Sujita Kumar Kar"
        ],
        "published_date": "2023",
        "abstract": "Background ChatGPT(Chat Generative Pre-trained Transformer) is an artificial intelligence (AI) based on a natural language processing tool developed by OpenAI (California, USA). This systematic review examines the potential of Chat GPT in diagnosing and treating patients and its contributions to medical research. Methods In order to locate articles on ChatGPT's use in clinical practise and medical research, this systematic review used PRISMA standards and conducted database searches across several sources. Selected records were analysed using ChatGPT, which also produced a summary for each article. The resultant word document was transformed to a PDF and handled using ChatPDF. The review looked at topics pertaining to scholarly publishing, clinical practise, and medical research. Results We reviewed 118 publications. There are difficulties and moral conundrums associated with using ChatGPT in therapeutic settings and medical research. Patient inquiries, note writing, decision-making, trial enrolment, data management, decision support, research support, and patient education are all things that ChatGPT can help with. However, the solutions it provides are frequently inadequate and inconsistent, presenting issues with its originality, privacy, accuracy, bias, and legality. When utilising ChatGPT for academic writings, there are issues with prejudice and plagiarism, and because it lacks human-like characteristics, its authority as an author is called into question. Conclusions ChatGPT has limitations when used in research and healthcare. Even while it aids in patient treatment, concerns regarding accuracy, authorship, and bias arise. Currently, ChatGPT can serve as a \"clinical assistant\" and be a huge assistance with research and scholarly writing.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/1c2a38413583c6836f11b88edebf65577e1450bd.pdf",
        "venue": "medRxiv",
        "citationCount": 0,
        "score": 0
    },
    "56df62407ba0878d34493f12a6ece8634ee0db9e.pdf": {
        "title": "A trustworthy AI reality-check: the lack of transparency of artificial intelligence products in healthcare",
        "authors": [
            "Jana Fehr",
            "Brian Citro",
            "Rohit Malpani",
            "Christoph Lippert",
            "V. Madai"
        ],
        "published_date": "2024",
        "abstract": "Trustworthy medical AI requires transparency about the development and testing of underlying algorithms to identify biases and communicate potential risks of harm. Abundant guidance exists on how to achieve transparency for medical AI products, but it is unclear whether publicly available information adequately informs about their risks. To assess this, we retrieved public documentation on the 14 available CE-certified AI-based radiology products of the II b risk category in the EU from vendor websites, scientific publications, and the European EUDAMED database. Using a self-designed survey, we reported on their development, validation, ethical considerations, and deployment caveats, according to trustworthy AI guidelines. We scored each question with either 0, 0.5, or 1, to rate if the required information was \u201cunavailable\u201d, \u201cpartially available,\u201d or \u201cfully available.\u201d The transparency of each product was calculated relative to all 55 questions. Transparency scores ranged from 6.4% to 60.9%, with a median of 29.1%. Major transparency gaps included missing documentation on training data, ethical considerations, and limitations for deployment. Ethical aspects like consent, safety monitoring, and GDPR-compliance were rarely documented. Furthermore, deployment caveats for different demographics and medical settings were scarce. In conclusion, public documentation of authorized medical AI products in Europe lacks sufficient public transparency to inform about safety and risks. We call on lawmakers and regulators to establish legally mandated requirements for public and substantive transparency to fulfill the promise of trustworthy AI for health.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/56df62407ba0878d34493f12a6ece8634ee0db9e.pdf",
        "venue": "Frontiers Digit. Health",
        "citationCount": 0,
        "score": 0
    },
    "561df8e070393a981b7c4196e1c94b92876d4e5b.pdf": {
        "title": "A Declarative System for Optimizing AI Workloads",
        "authors": [
            "Chunwei Liu",
            "Matthew Russo",
            "Michael J. Cafarella",
            "Lei Cao",
            "Peter Baille Chen",
            "Zui Chen",
            "Michael J. Franklin",
            "T. Kraska",
            "Samuel Madden",
            "Gerardo Vitagliano"
        ],
        "published_date": "2024",
        "abstract": "A long-standing goal of data management systems has been to build systems which can compute quantitative insights over large corpora of unstructured data in a cost-effective manner. Until recently, it was difficult and expensive to extract facts from company documents, data from scientific papers, or metrics from image and video corpora. Today's models can accomplish these tasks with high accuracy. However, a programmer who wants to answer a substantive AI-powered query must orchestrate large numbers of models, prompts, and data operations. For even a single query, the programmer has to make a vast number of decisions such as the choice of model, the right inference method, the most cost-effective inference hardware, the ideal prompt design, and so on. The optimal set of decisions can change as the query changes and as the rapidly-evolving technical landscape shifts. In this paper we present Palimpzest, a system that enables anyone to process AI-powered analytical queries simply by defining them in a declarative language. The system uses its cost optimization framework to implement the query plan with the best trade-offs between runtime, financial cost, and output data quality. We describe the workload of AI-powered analytics tasks, the optimization methods that Palimpzest uses, and the prototype system itself. We evaluate Palimpzest on tasks in Legal Discovery, Real Estate Search, and Medical Schema Matching. We show that even our simple prototype offers a range of appealing plans, including one that is 3.3x faster and 2.9x cheaper than the baseline method, while also offering better data quality. With parallelism enabled, Palimpzest can produce plans with up to a 90.3x speedup at 9.1x lower cost relative to a single-threaded GPT-4 baseline, while obtaining an F1-score within 83.5% of the baseline. These require no additional work by the user.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/561df8e070393a981b7c4196e1c94b92876d4e5b.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "c4034bb6f3e29ab0adcb3423d5acfbbf28623f94.pdf": {
        "title": "Exploring AI-driven approaches for unstructured document analysis and future horizons",
        "authors": [
            "Supriya V. Mahadevkar",
            "S. Patil",
            "K. Kotecha",
            "Lim Way Soong",
            "Tanupriya Choudhury"
        ],
        "published_date": "2024",
        "abstract": "",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/c4034bb6f3e29ab0adcb3423d5acfbbf28623f94.pdf",
        "venue": "Journal of Big Data",
        "citationCount": 0,
        "score": 0
    },
    "bdba9bd3e75b1899824dcddcaa5a707fe3ad40ee.pdf": {
        "title": "Explainable AI improves task performance in human\u2013AI collaboration",
        "authors": [
            "J. Senoner",
            "Simon Schallmoser",
            "Bernhard Kratzwald",
            "Stefan Feuerriegel",
            "Torbj\u00f8rn Netland"
        ],
        "published_date": "2024",
        "abstract": "Artificial intelligence (AI) provides considerable opportunities to assist human work. However, one crucial challenge of human\u2013AI collaboration is that many AI algorithms operate in a black-box manner where the way how the AI makes predictions remains opaque. This makes it difficult for humans to validate a prediction made by AI against their own domain knowledge. For this reason, we hypothesize that augmenting humans with explainable AI improves task performance in human\u2013AI collaboration. To test this hypothesis, we implement explainable AI in the form of visual heatmaps in inspection tasks conducted by domain experts. Visual heatmaps have the advantage that they are easy to understand and help to localize relevant parts of an image. We then compare participants that were either supported by (a) black-box AI or (b) explainable AI, where the latter supports them to follow AI predictions when the AI is accurate or overrule the AI when the AI predictions are wrong. We conducted two preregistered experiments with representative, real-world visual inspection tasks from manufacturing and medicine. The first experiment was conducted with factory workers from an electronics factory, who performed \\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$N=9,600$$\\end{document} assessments of whether electronic products have defects. The second experiment was conducted with radiologists, who performed \\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$N=5,650$$\\end{document} assessments of chest X-ray images to identify lung lesions. The results of our experiments with domain experts performing real-world tasks show that task performance improves when participants are supported by explainable AI with heatmaps instead of black-box AI. We find that explainable AI as a decision aid improved the task performance by 7.7 percentage points (95% confidence interval [CI]: 3.3% to 12.0%, \\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$P=0.001$$\\end{document}) in the manufacturing experiment and by 4.7 percentage points (95% CI: 1.1% to 8.3%, \\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$P=0.010$$\\end{document}) in the medical experiment compared to black-box AI. These gains represent a significant improvement in task performance.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/bdba9bd3e75b1899824dcddcaa5a707fe3ad40ee.pdf",
        "venue": "Scientific Reports",
        "citationCount": 0,
        "score": 0
    },
    "d3abdfe5f5f260e28c7d989dbf5fee9c232a0584.pdf": {
        "title": "AI-generated text may have a role in evidence-based medicine",
        "authors": [
            "Yifan Peng",
            "Justin F. Rousseau",
            "E. Shortliffe",
            "C. Weng"
        ],
        "published_date": "2023",
        "abstract": "",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/d3abdfe5f5f260e28c7d989dbf5fee9c232a0584.pdf",
        "venue": "Nature Network Boston",
        "citationCount": 0,
        "score": 0
    },
    "a2f5c019c8017e10850fc32fc08e2457c81f8df5.pdf": {
        "title": "Utilizing Large Language Models for Enhanced Clinical Trial Matching: A Study on Automation in Patient Screening",
        "authors": [
            "J. Beattie",
            "Sarah Neufeld",
            "Daniel Yang",
            "C. Chukwuma",
            "A. Gul",
            "Neil Desai",
            "Steve Jiang",
            "M. Dohopolski"
        ],
        "published_date": "2024",
        "abstract": "Background: Clinical trial matching, essential for advancing medical research, involves detailed screening of potential participants to ensure alignment with specific trial requirements. Research staff face challenges due to the high volume of eligible patients and the complexity of varying eligibility criteria. The traditional manual process, both time-consuming and error-prone, often leads to missed opportunities. Utilizing Artificial Intelligence (AI) and Natural Language Processing (NLP) can significantly enhance the accuracy and efficiency of this process through automated patient screening against established criteria. Methods: Utilizing data from the National NLP Clinical Challenges (n2c2) 2018 Challenge, we utilized 202 longitudinal patient records. These records were annotated by medical professionals and evaluated against 13 selection criteria encompassing various health assessments. Our approach involved embedding medical documents into a vector database to determine relevant document sections, then using a large language model (GPT-3.5 Turbo and GPT-4 OpenAI API) in tandem with structured and chain-of-thought prompting techniques for systematic document assessment against the criteria. Misclassified criteria were also examined to identify classification challenges. Results: This study achieved an accuracy of 0.81, sensitivity of 0.80, specificity of 0.82, and a micro F1 score of 0.79 using GPT-3.5 Turbo, and an accuracy of 0.87, sensitivity of 0.85, specificity of 0.89, and micro F1 score of 0.86 using GPT-4 Turbo. Notably, some criteria in the ground truth appeared mislabeled, an issue we could not explore further due to insufficient label generation guidelines. Conclusion: Our findings underscore the significant potential of AI and NLP technologies, including large language models, in the clinical trial matching process. The study demonstrated strong capabilities in identifying eligible patients and minimizing false inclusions. Such automated systems promise to greatly alleviate the workload of research staff and improve clinical trial enrollment, thus accelerating the process and enhancing the overall feasibility of clinical research.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/a2f5c019c8017e10850fc32fc08e2457c81f8df5.pdf",
        "venue": "medRxiv",
        "citationCount": 0,
        "score": 0
    },
    "e3ee318d593729352f991142e6e3bef62640c5a5.pdf": {
        "title": "AI in imaging: the regulatory landscape",
        "authors": [
            "Derek L G Hill"
        ],
        "published_date": "2024",
        "abstract": "Abstract Artificial intelligence (AI) methods have been applied to medical imaging for several decades, but in the last few years, the number of publications and the number of AI-enabled medical devices coming on the market have significantly increased. While some AI-enabled approaches are proving very valuable, systematic reviews of the AI imaging field identify significant weaknesses in a significant proportion of the literature. Medical device regulators have recently become more proactive in publishing guidance documents and recognizing standards that will require that the development and validation of AI-enabled medical devices need to be more rigorous than required for tradition \u201crule-based\u201d software. In particular, developers are required to better identify and mitigate risks (such as bias) that arise in AI-enabled devices, and to ensure that the devices are validated in a realistic clinical setting to ensure their output is clinically meaningful. While this evolving regulatory landscape will mean that device developers will take longer to bring novel AI-based medical imaging devices to market, such additional rigour is necessary to address existing weaknesses in the field and ensure that patients and healthcare professionals can trust AI-enabled devices. There would also be benefits in the academic community taking into account this regulatory framework, to improve the quality of the literature and make it easier for academically developed AI tools to make the transition to medical devices that impact healthcare.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/e3ee318d593729352f991142e6e3bef62640c5a5.pdf",
        "venue": "British Journal of Radiology",
        "citationCount": 0,
        "score": 0
    },
    "3bf118f2f918ad121aa3983479241d8b09f9c071.pdf": {
        "title": "Autonomous Artificial Intelligence Agents for Clinical Decision Making in Oncology",
        "authors": [
            "Dyke Ferber",
            "O. E. Nahhas",
            "Georg W\u00f6lflein",
            "I. Wiest",
            "J. Clusmann",
            "Marie-Elisabeth Lessman",
            "S. Foersch",
            "Jacqueline Lammert",
            "Maximilian Tschochohei",
            "Dirk J\u00e4ger",
            "M. Salto-Tellez",
            "N. Schultz",
            "Daniel Truhn",
            "J. Kather"
        ],
        "published_date": "2024",
        "abstract": "Multimodal artificial intelligence (AI) systems have the potential to enhance clinical decision-making by interpreting various types of medical data. However, the effectiveness of these models across all medical fields is uncertain. Each discipline presents unique challenges that need to be addressed for optimal performance. This complexity is further increased when attempting to integrate different fields into a single model. Here, we introduce an alternative approach to multimodal medical AI that utilizes the generalist capabilities of a large language model (LLM) as a central reasoning engine. This engine autonomously coordinates and deploys a set of specialized medical AI tools. These tools include text, radiology and histopathology image interpretation, genomic data processing, web searches, and document retrieval from medical guidelines. We validate our system across a series of clinical oncology scenarios that closely resemble typical patient care workflows. We show that the system has a high capability in employing appropriate tools (97%), drawing correct conclusions (93.6%), and providing complete (94%), and helpful (89.2%) recommendations for individual patient cases while consistently referencing relevant literature (82.5%) upon instruction. This work provides evidence that LLMs can effectively plan and execute domain-specific models to retrieve or synthesize new information when used as autonomous agents. This enables them to function as specialist, patient-tailored clinical assistants. It also simplifies regulatory compliance by allowing each component tool to be individually validated and approved. We believe, that our work can serve as a proof-of-concept for more advanced LLM-agents in the medical domain.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/3bf118f2f918ad121aa3983479241d8b09f9c071.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "139728e2c178cbb2c6efd13dac8c9c622242b448.pdf": {
        "title": "Advancements in AI for Oncology: Developing an Enhanced YOLOv5-based Cancer Cell Detection System",
        "authors": [
            "Xin Chen",
            "Yuxiang Hu",
            "Ting Xu",
            "Haowei Yang",
            "Tong Wu"
        ],
        "published_date": "2024",
        "abstract": "As artificial intelligence (AI) theory becomes more sophisticated and its utilization spreads across daily life, education, and professional settings, the adoption of AI for medical diagnostic and service purposes stands as a logical progression in the evolution of medical technologies. This document outlines a novel approach to detecting cancer cell targets using a deep learning-based system, marking a critical step towards integrating AI into cancer diagnostics. The process of detecting cancer cell targets entails the localization of cell types within images of cells. By capitalizing on the strengths of the YOLOv5 model\u2014a deep learning-driven, end-to-end, real-time object detection framework known for its efficiency, superior performance, adaptability, and user-friendly PyTorch integration\u2014this research presents an enhanced YOLOv5 model incorporating both a feature pyramid network and the original YOLOv5 architecture. The ultimate aim is to facilitate precise detection of targets in cancer cell images. The experimental data demonstrate the system's negligible error rate in detection, swift processing capabilities, and exceptional reliability.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/139728e2c178cbb2c6efd13dac8c9c622242b448.pdf",
        "venue": "International Journal of Innovative Research in Computer Science & Technology",
        "citationCount": 0,
        "score": 0
    },
    "470b6f476c26b140461119130a7ee3da59b97504.pdf": {
        "title": "High-reward, high-risk technologies? An ethical and legal account of AI development in healthcare",
        "authors": [
            "Maelenn Corfmat",
            "Jo\u00e9 T. Martineau",
            "Catherine R\u00e9gis"
        ],
        "published_date": "2025",
        "abstract": "Background Considering the disruptive potential of AI technology, its current and future impact in healthcare, as well as healthcare professionals\u2019 lack of training in how to use it, the paper summarizes how to approach the challenges of AI from an ethical and legal perspective. It concludes with suggestions for improvements to help healthcare professionals better navigate the AI wave. Methods We analyzed the literature that specifically discusses ethics and law related to the development and implementation of AI in healthcare as well as relevant normative documents that pertain to both ethical and legal issues. After such analysis, we created categories regrouping the most frequently cited and discussed ethical and legal issues. We then proposed a breakdown within such categories that emphasizes the different - yet often interconnecting - ways in which ethics and law are approached for each category of issues. Finally, we identified several key ideas for healthcare professionals and organizations to better integrate ethics and law into their practices. Results We identified six categories of issues related to AI development and implementation in healthcare: (1) privacy; (2) individual autonomy; (3) bias; (4) responsibility and liability; (5) evaluation and oversight; and (6) work, professions and the job market. While each one raises different questions depending on perspective, we propose three main legal and ethical priorities: education and training of healthcare professionals, offering support and guidance throughout the use of AI systems, and integrating the necessary ethical and legal reflection at the heart of the AI tools themselves. Conclusions By highlighting the main ethical and legal issues involved in the development and implementation of AI technologies in healthcare, we illustrate their profound effects on professionals as well as their relationship with patients and other organizations in the healthcare sector. We must be able to identify AI technologies in medical practices and distinguish them by their nature so we can better react and respond to them. Healthcare professionals need to work closely with ethicists and lawyers involved in the healthcare system, or the development of reliable and trusted AI will be jeopardized.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/470b6f476c26b140461119130a7ee3da59b97504.pdf",
        "venue": "BMC Medical Ethics",
        "citationCount": 0,
        "score": 0
    },
    "17de71b58044d771beca14bcd8ef18b4f7cff213.pdf": {
        "title": "ChatGPT\u2019s performance in German OB/GYN exams \u2013 paving the way for AI-enhanced medical education and clinical practice",
        "authors": [
            "Maximilian Riedel",
            "Katharina Kaefinger",
            "Antonia Stuehrenberg",
            "Viktoria Ritter",
            "Niklas Amann",
            "Anna Graf",
            "Florian Recker",
            "Evelyn Klein",
            "M. Kiechle",
            "Fabian Riedel",
            "Bastian Meyer"
        ],
        "published_date": "2023",
        "abstract": "Background Chat Generative Pre-Trained Transformer (ChatGPT) is an artificial learning and large language model tool developed by OpenAI in 2022. It utilizes deep learning algorithms to process natural language and generate responses, which renders it suitable for conversational interfaces. ChatGPT\u2019s potential to transform medical education and clinical practice is currently being explored, but its capabilities and limitations in this domain remain incompletely investigated. The present study aimed to assess ChatGPT\u2019s performance in medical knowledge competency for problem assessment in obstetrics and gynecology (OB/GYN). Methods Two datasets were established for analysis: questions (1) from OB/GYN course exams at a German university hospital and (2) from the German medical state licensing exams. In order to assess ChatGPT\u2019s performance, questions were entered into the chat interface, and responses were documented. A quantitative analysis compared ChatGPT\u2019s accuracy with that of medical students for different levels of difficulty and types of questions. Additionally, a qualitative analysis assessed the quality of ChatGPT\u2019s responses regarding ease of understanding, conciseness, accuracy, completeness, and relevance. Non-obvious insights generated by ChatGPT were evaluated, and a density index of insights was established in order to quantify the tool\u2019s ability to provide students with relevant and concise medical knowledge. Results ChatGPT demonstrated consistent and comparable performance across both datasets. It provided correct responses at a rate comparable with that of medical students, thereby indicating its ability to handle a diverse spectrum of questions ranging from general knowledge to complex clinical case presentations. The tool\u2019s accuracy was partly affected by question difficulty in the medical state exam dataset. Our qualitative assessment revealed that ChatGPT provided mostly accurate, complete, and relevant answers. ChatGPT additionally provided many non-obvious insights, especially in correctly answered questions, which indicates its potential for enhancing autonomous medical learning. Conclusion ChatGPT has promise as a supplementary tool in medical education and clinical practice. Its ability to provide accurate and insightful responses showcases its adaptability to complex clinical scenarios. As AI technologies continue to evolve, ChatGPT and similar tools may contribute to more efficient and personalized learning experiences and assistance for health care providers.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/17de71b58044d771beca14bcd8ef18b4f7cff213.pdf",
        "venue": "Frontiers in Medicine",
        "citationCount": 0,
        "score": 0
    },
    "3015956a254139547cb350f5dbdd8edde298ac0d.pdf": {
        "title": "Accelerating clinical evidence synthesis with large language models",
        "authors": [
            "Zifeng Wang",
            "Lang Cao",
            "Benjamin P. Danek",
            "Yichi Zhang",
            "Qiao Jin",
            "Zhiyong Lu",
            "Jimeng Sun"
        ],
        "published_date": "2024",
        "abstract": "Clinical evidence synthesis largely relies on systematic reviews (SR) of clinical studies from medical literature. Here, we propose a generative artificial intelligence (AI) pipeline named TrialMind to streamline study search, study screening, and data extraction tasks in SR. We chose published SRs to build TrialReviewBench, which contains 100 SRs and 2,220 clinical studies. For study search, it achieves high recall rates (Ours 0.711\u20130.834 v.s. Human baseline 0.138\u20130.232). For study screening, TrialMind beats previous document ranking methods in a 1.5\u20132.6 fold change. For data extraction, it outperforms a GPT-4\u2019s accuracy by 16\u201332%. In a pilot study, human-AI collaboration with TrialMind improved recall by 71.4% and reduced screening time by 44.2%, while in data extraction, accuracy increased by 23.5% with a 63.4% time reduction. Medical experts preferred TrialMind\u2019s synthesized evidence over GPT-4\u2019s in 62.5%-100% of cases. These findings show the promise of accelerating clinical evidence synthesis driven by human-AI collaboration.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/3015956a254139547cb350f5dbdd8edde298ac0d.pdf",
        "venue": "npj Digit. Medicine",
        "citationCount": 0,
        "score": 0
    },
    "8135f7dd37df7cf4ad61756fc1152c792be3d821.pdf": {
        "title": "The ethical requirement of explainability for AI-DSS in healthcare: a systematic review of reasons",
        "authors": [
            "Nils Freyer",
            "Dominik Gro\u00df",
            "Myriam Lipprandt"
        ],
        "published_date": "2024",
        "abstract": "Background Despite continuous performance improvements, especially in clinical contexts, a major challenge of Artificial Intelligence based Decision Support Systems (AI-DSS) remains their degree of epistemic opacity. The conditions of and the solutions for the justified use of the occasionally unexplainable technology in healthcare are an active field of research. In March 2024, the European Union agreed upon the Artificial Intelligence Act (AIA), requiring medical AI-DSS to be ad-hoc explainable or to use post-hoc explainability methods. The ethical debate does not seem to settle on this requirement yet. This systematic review aims to outline and categorize the positions and arguments in the ethical debate. Methods We conducted a literature search on PubMed, BASE, and Scopus for English-speaking scientific peer-reviewed publications from 2016 to 2024. The inclusion criterion was to give explicit requirements of explainability for AI-DSS in healthcare and reason for it. Non-domain-specific documents, as well as surveys, reviews, and meta-analyses were excluded. The ethical requirements for explainability outlined in the documents were qualitatively analyzed with respect to arguments for the requirement of explainability and the required level of explainability. Results The literature search resulted in 1662 documents; 44 documents were included in the review after eligibility screening of the remaining full texts. Our analysis showed that 17 records argue in favor of the requirement of explainable AI methods (xAI) or ad-hoc explainable models, providing 9 categories of arguments. The other 27 records argued against a general requirement, providing 11 categories of arguments. Also, we found that 14 works advocate the need for context-dependent levels of explainability, as opposed to 30 documents, arguing for context-independent, absolute standards. Conclusions The systematic review of reasons shows no clear agreement on the requirement of post-hoc explainability methods or ad-hoc explainable models for AI-DSS in healthcare. The arguments found in the debate were referenced and responded to from different perspectives, demonstrating an interactive discourse. Policymakers and researchers should watch the development of the debate closely. Conversely, ethicists should be well informed by empirical and technical research, given the frequency of advancements in the field. Supplementary Information The online version contains supplementary material available at 10.1186/s12910-024-01103-2.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/8135f7dd37df7cf4ad61756fc1152c792be3d821.pdf",
        "venue": "BMC Medical Ethics",
        "citationCount": 0,
        "score": 0
    },
    "b2515168dd17240480a0462360d8e48ab2fc2639.pdf": {
        "title": "Large Language Models in the Clinic: A Comprehensive Benchmark",
        "authors": [
            "Andrew Liu",
            "Hongjian Zhou",
            "Yining Hua",
            "Omid Rohanian",
            "Anshul Thakur",
            "Lei A. Clifton",
            "David A. Clifton"
        ],
        "published_date": "2024",
        "abstract": "The adoption of large language models (LLMs) to assist clinicians has attracted remarkable attention. Existing works mainly adopt the close-ended question-answering (QA) task with answer options for evaluation. However, many clinical decisions involve answering open-ended questions without pre-set options. To better understand LLMs in the clinic, we construct a benchmark ClinicBench. We first collect eleven existing datasets covering diverse clinical language generation, understanding, and reasoning tasks. Furthermore, we construct six novel datasets and clinical tasks that are complex but common in real-world practice, e.g., open-ended decision-making, long document processing, and emerging drug analysis. We conduct an extensive evaluation of twenty-two LLMs under both zero-shot and few-shot settings. Finally, we invite medical experts to evaluate the clinical usefulness of LLMs. The benchmark data is available at https://github.com/AI-in-Health/ClinicBench.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/b2515168dd17240480a0462360d8e48ab2fc2639.pdf",
        "venue": "",
        "citationCount": 0,
        "score": 0
    },
    "1e62d8b0db0731179b6513ae442fe29bc8f4eb2d.pdf": {
        "title": "Automating Evaluation of AI Text Generation in Healthcare with a Large Language Model (LLM)-as-a-Judge",
        "authors": [
            "E. Croxford",
            "Yanjun Gao",
            "Elliot First",
            "Nicholas Pellegrino",
            "Miranda Schnier",
            "J. Caskey",
            "M. Oguss",
            "Graham Wills",
            "Guanhua Chen",
            "D. Dligach",
            "Matthew M. Churpek",
            "Anoop M. Mayampurath",
            "Frank J Liao",
            "Cherodeep Goswami",
            "Karen K. Wong",
            "Brian W Patterson",
            "Majid Afshar"
        ],
        "published_date": "2025",
        "abstract": "Electronic Health Records (EHRs) store vast amounts of clinical information that are difficult for healthcare providers to summarize and synthesize relevant details to their practice. To reduce cognitive load on providers, generative AI with Large Language Models have emerged to automatically summarize patient records into clear, actionable insights and offload the cognitive burden for providers. However, LLM summaries need to be precise and free from errors, making evaluations on the quality of the summaries necessary. While human experts are the gold standard for evaluations, their involvement is time-consuming and costly. Therefore, we introduce and validate an automated method for evaluating real-world EHR multi-document summaries using an LLM as the evaluator, referred to as LLM-as-a-Judge. Benchmarking against the validated Provider Documentation Summarization Quality Instrument (PDSQI)-9 for human evaluation, our LLM-as-a-Judge framework uses the PDSQI-9 rubric and demonstrated strong inter-rater reliability with human evaluators. GPT-o3-mini achieved the highest intraclass correlation coefficient of 0.818 (95% CI 0.772, 0.854), with a median score difference of 0 from human evaluators, and completes evaluations in just 22 seconds. Overall, the reasoning models excelled in inter-rater reliability, particularly in evaluations that require advanced reasoning and domain expertise, outperforming non-reasoning models, those trained on the task, and multi-agent workflows. Cross-task validation on the Problem Summarization task similarly confirmed high reliability. By automating high-quality evaluations, medical LLM-as-a-Judge offers a scalable, efficient solution to rapidly identify accurate and safe AI-generated summaries in healthcare settings.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/1e62d8b0db0731179b6513ae442fe29bc8f4eb2d.pdf",
        "venue": "medRxiv",
        "citationCount": 0,
        "score": 0
    },
    "70d1805367e053588ad237d6e3d7aaf08b4e42b9.pdf": {
        "title": "\u201cDr. AI Will See You Now\u201d: How Do ChatGPT-4 Treatment Recommendations Align With Orthopaedic Clinical Practice Guidelines?",
        "authors": [
            "Tanios Dagher",
            "Emma Dwyer",
            "Hayden P. Baker",
            "Senthooran Kalidoss",
            "Jason A. Strelzow"
        ],
        "published_date": "2024",
        "abstract": "Background Artificial intelligence (AI) is engineered to emulate tasks that have historically required human interaction and intellect, including learning, pattern recognition, decision-making, and problem-solving. Although AI models like ChatGPT-4 have demonstrated satisfactory performance on medical licensing exams, suggesting a potential for supporting medical diagnostics and decision-making, no study of which we are aware has evaluated the ability of these tools to make treatment recommendations when given clinical vignettes and representative medical imaging of common orthopaedic conditions. As AI continues to advance, a thorough understanding of its strengths and limitations is necessary to inform safe and helpful integration into medical practice. Questions/purposes (1) What is the concordance between ChatGPT-4-generated treatment recommendations for common orthopaedic conditions with both the American Academy of Orthopaedic Surgeons (AAOS) clinical practice guidelines (CPGs) and an orthopaedic attending physician\u2019s treatment plan? (2) In what specific areas do the ChatGPT-4-generated treatment recommendations diverge from the AAOS CPGs? Methods Ten common orthopaedic conditions with associated AAOS CPGs were identified: carpal tunnel syndrome, distal radius fracture, glenohumeral joint osteoarthritis, rotator cuff injury, clavicle fracture, hip fracture, hip osteoarthritis, knee osteoarthritis, ACL injury, and acute Achilles rupture. For each condition, the medical records of 10 deidentified patients managed at our facility were used to construct clinical vignettes that each had an isolated, single diagnosis with adequate clarity. The vignettes also encompassed a range of diagnostic severity to evaluate more thoroughly adherence to the treatment guidelines outlined by the AAOS. These clinical vignettes were presented alongside representative radiographic imaging. The model was prompted to provide a single treatment plan recommendation. Each treatment plan was compared with established AAOS CPGs and to the treatment plan documented by the attending orthopaedic surgeon treating the specific patient. Vignettes where ChatGPT-4 recommendations diverged from CPGs were reviewed to identify patterns of error and summarized. Results ChatGPT-4 provided treatment recommendations in accordance with the AAOS CPGs in 90% (90 of 100) of clinical vignettes. Concordance between ChatGPT-generated plans and the plan recommended by the treating orthopaedic attending physician was 78% (78 of 100). One hundred percent (30 of 30) of ChatGPT-4 recommendations for fracture vignettes and hip and knee arthritis vignettes matched with CPG recommendations, whereas the model struggled most with recommendations for carpal tunnel syndrome (3 of 10 instances demonstrated discordance). ChatGPT-4 recommendations diverged from AAOS CPGs for three carpal tunnel syndrome vignettes; two ACL injury, rotator cuff injury, and glenohumeral joint osteoarthritis vignettes; as well as one acute Achilles rupture vignette. In these situations, ChatGPT-4 most often struggled to correctly interpret injury severity and progression, incorporate patient factors (such as lifestyle or comorbidities) into decision-making, and recognize a contraindication to surgery. Conclusion ChatGPT-4 can generate accurate treatment plans aligned with CPGs but can also make mistakes when it is required to integrate multiple patient factors into decision-making and understand disease severity and progression. Physicians must critically assess the full clinical picture when using AI tools to support their decision-making. Clinical Relevance ChatGPT-4 may be used as an on-demand diagnostic companion, but patient-centered decision-making should continue to remain in the hands of the physician.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/70d1805367e053588ad237d6e3d7aaf08b4e42b9.pdf",
        "venue": "Clinical Orthopaedics and Related Research",
        "citationCount": 0,
        "score": 0
    },
    "96fe238568d192a30dc7ddd528ea35b23ab1bf70.pdf": {
        "title": "Updating the Checklist for Artificial Intelligence in Medical Imaging (CLAIM) for reporting AI research",
        "authors": [
            "Ali S. Tejani",
            "M. Klontzas",
            "Anthony A Gatti",
            "John Mongan",
            "Linda Moy",
            "Seong Ho Park",
            "Charles E. Kahn"
        ],
        "published_date": "2023",
        "abstract": "",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/96fe238568d192a30dc7ddd528ea35b23ab1bf70.pdf",
        "venue": "Nature Machine Intelligence",
        "citationCount": 0,
        "score": 0
    },
    "98f16006f9492a77cba380f8c9e7eaf514092389.pdf": {
        "title": "Ethical dimensions of generative AI: a cross-domain analysis using machine learning structural topic modeling",
        "authors": [
            "Hassnian Ali",
            "A. Aysan"
        ],
        "published_date": "2024",
        "abstract": "\nPurpose\nThe purpose of this study is to comprehensively examine the ethical implications surrounding generative artificial intelligence (AI).\n\n\nDesign/methodology/approach\nLeveraging a novel methodological approach, the study curates a corpus of 364 documents from Scopus spanning 2022 to 2024. Using the term frequency-inverse document frequency (TF-IDF) and structural topic modeling (STM), it quantitatively dissects the thematic essence of the ethical discourse in generative AI across diverse domains, including education, healthcare, businesses and scientific research.\n\n\nFindings\nThe results reveal a diverse range of ethical concerns across various sectors impacted by generative AI. In academia, the primary focus is on issues of authenticity and intellectual property, highlighting the challenges of AI-generated content in maintaining academic integrity. In the healthcare sector, the emphasis shifts to the ethical implications of AI in medical decision-making and patient privacy, reflecting concerns about the reliability and security of AI-generated medical advice. The study also uncovers significant ethical discussions in educational and financial settings, demonstrating the broad impact of generative AI on societal and professional practices.\n\n\nResearch limitations/implications\nThis study provides a foundation for crafting targeted ethical guidelines and regulations for generative AI, informed by a systematic analysis using STM. It highlights the need for dynamic governance and continual monitoring of AI\u2019s evolving ethical landscape, offering a model for future research and policymaking in diverse fields.\n\n\nOriginality/value\nThe study introduces a unique methodological combination of TF-IDF and STM to analyze a large academic corpus, offering new insights into the ethical implications of generative AI across multiple domains.\n",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/98f16006f9492a77cba380f8c9e7eaf514092389.pdf",
        "venue": "International Journal of Ethics and Systems",
        "citationCount": 0,
        "score": 0
    },
    "4a9d3e39ecafb0487b54731d6d99c46770ce5965.pdf": {
        "title": "AI-powered topic modeling: comparing LDA and BERTopic in analyzing opioid-related cardiovascular risks in women",
        "authors": [
            "Li Ma",
            "Ru Chen",
            "W. Ge",
            "Paul Rogers",
            "Beverly Lyn-Cook",
            "H. Hong",
            "Weida Tong",
            "Ningning Wu",
            "Wen Zou"
        ],
        "published_date": "2025",
        "abstract": "Topic modeling is a crucial technique in natural language processing (NLP), enabling the extraction of latent themes from large text corpora. Traditional topic modeling, such as Latent Dirichlet Allocation (LDA), faces limitations in capturing the semantic relationships in the text document although it has been widely applied in text mining. BERTopic, created in 2022, leveraged advances in deep learning and can capture the contextual relationships between words. In this work, we integrated Artificial Intelligence (AI) modules to LDA and BERTopic and provided a comprehensive comparison on the analysis of prescription opioid-related cardiovascular risks in women. Opioid use can increase the risk of cardiovascular problems in women such as arrhythmia, hypotension etc. 1,837 abstracts were retrieved and downloaded from PubMed as of April 2024 using three Medical Subject Headings (MeSH) words: \u201copioid,\u201d \u201ccardiovascular,\u201d and \u201cwomen.\u201d Machine Learning of Language Toolkit (MALLET) was employed for the implementation of LDA. BioBERT was used for document embedding in BERTopic. Eighteen was selected as the optimal topic number for MALLET and 23 for BERTopic. ChatGPT-4-Turbo was integrated to interpret and compare the results. The short descriptions created by ChatGPT for each topic from LDA and BERTopic were highly correlated, and the performance accuracies of LDA and BERTopic were similar as determined by expert manual reviews of the abstracts grouped by their predominant topics. The results of the t-SNE (t-distributed Stochastic Neighbor Embedding) plots showed that the clusters created from BERTopic were more compact and well-separated, representing improved coherence and distinctiveness between the topics. Our findings indicated that AI algorithms could augment both traditional and contemporary topic modeling techniques. In addition, BERTopic has the connection port for ChatGPT-4-Turbo or other large language models in its algorithm for automatic interpretation, while with LDA interpretation must be manually, and needs special procedures for data pre-processing and stop words exclusion. Therefore, while LDA remains valuable for large-scale text analysis with resource constraints, AI-assisted BERTopic offers significant advantages in providing the enhanced interpretability and the improved semantic coherence for extracting valuable insights from textual data.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/4a9d3e39ecafb0487b54731d6d99c46770ce5965.pdf",
        "venue": "Experimental biology and medicine",
        "citationCount": 0,
        "score": 0
    },
    "9f69378a966de40ccb9a267df45ac1a926d8f0b4.pdf": {
        "title": "The 2024 revision of the Declaration of Helsinki: a modern ethical framework for medical research.",
        "authors": [
            "Boyuan Wen",
            "Guochao Zhang",
            "Chang Zhan",
            "Chen Chen",
            "Hang Yi"
        ],
        "published_date": "2024",
        "abstract": "The Declaration of Helsinki, established in 1964, remains a foundational document in medical research ethics. This review examines the 2024 revision, endorsed by the 75th World Medical Association (WMA) Assembly, highlighting its impact on modern clinical research. Major updates include the shift from \"subjects\" to \"participants,\" promoting autonomy and active involvement, and the introduction of dual ethical review requirements for cross-border studies to strengthen accountability. New guidelines for data privacy address AI-related ethical concerns, while enhanced community engagement fosters transparency and shared decision-making. Additionally, standards for environmental sustainability encourage research practices that minimize ecological impacts. In response to global health crises such as COVID-19, the revised Declaration sets forth ethical protections to balance participant safety with research urgency during emergencies. Despite these advances, areas for improvement remain, especially in AI ethics, emergency research protocols, and the extension the Declaration's scope to include forensic and specimen research. The 2024 revision thus strengthens the Declaration's role as an adaptive, relevant framework for safeguarding participant rights and research integrity in a changing landscape.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/9f69378a966de40ccb9a267df45ac1a926d8f0b4.pdf",
        "venue": "Postgraduate medical journal",
        "citationCount": 0,
        "score": 0
    },
    "91925f988424a5ab55c5e3cf36cb55fea0b96ea8.pdf": {
        "title": "Promoting AI Competencies for Medical Students: A Scoping Review on Frameworks, Programs, and Tools",
        "authors": [
            "Yingbo Ma",
            "Yukyeong Song",
            "Jeremy A. Balch",
            "Yuanfang Ren",
            "Divya Vellanki",
            "Zhenhong Hu",
            "Meghan Brennan",
            "Suraj Kolla",
            "Ziyuan Guan",
            "Brooke Armfield",
            "T. Ozrazgat-Baslanti",
            "Parisa Rashidi",
            "Tyler J. Loftus",
            "A. Bihorac",
            "Benjamin Shickel"
        ],
        "published_date": "2024",
        "abstract": "As more clinical workflows continue to be augmented by artificial intelligence (AI), AI literacy among physicians will become a critical requirement for ensuring safe and ethical AI-enabled patient care. Despite the evolving importance of AI in healthcare, the extent to which it has been adopted into traditional and often-overloaded medical curricula is currently unknown. In a scoping review of 1,699 articles published between January 2016 and June 2024, we identified 18 studies which propose guiding frameworks, and 11 studies documenting real-world instruction, centered around the integration of AI into medical education. We found that comprehensive guidelines will require greater clinical relevance and personalization to suit medical student interests and career trajectories. Current efforts highlight discrepancies in the teaching guidelines, emphasizing AI evaluation and ethics over technical topics such as data science and coding. Additionally, we identified several challenges associated with integrating AI training into the medical education program, including a lack of guidelines to define medical students AI literacy, a perceived lack of proven clinical value, and a scarcity of qualified instructors. With this knowledge, we propose an AI literacy framework to define competencies for medical students. To prioritize relevant and personalized AI education, we categorize literacy into four dimensions: Foundational, Practical, Experimental, and Ethical, with tailored learning objectives to the pre-clinical, clinical, and clinical research stages of medical education. This review provides a road map for developing practical and relevant education strategies for building an AI-competent healthcare workforce.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/91925f988424a5ab55c5e3cf36cb55fea0b96ea8.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "074382848cdfa466136392c9a106561972180d0f.pdf": {
        "title": "Documenting the de-identification process of clinical and imaging data for AI for health imaging projects",
        "authors": [
            "H. Kondylakis",
            "Rocio Catalan",
            "Sara Martinez Alabart",
            "Caroline Barelle",
            "Paschalis A. Bizopoulos",
            "Maciej Bobowicz",
            "Jonathan Bona",
            "Dimitrios I. Fotiadis",
            "Teresa Garcia",
            "Ignacio Gomez",
            "Ana Jim\u00e9nez-Pastor",
            "Giannis Karatzanis",
            "Karim Lekadir",
            "Magdalena Kogut-Czarkowska",
            "Antonios Lalas",
            "K. Marias",
            "Luis Mart\u00ed-Bonmat\u00ed",
            "Jose Munuera",
            "K. Nikiforaki",
            "Manon Pelissier",
            "Fred Prior",
            "Michael Rutherford",
            "Laure Saint-Aubert",
            "Zisis Sakellariou",
            "K. Seymour",
            "Thomas Trouillard",
            "Konstantinos Votis",
            "M. Tsiknakis"
        ],
        "published_date": "2024",
        "abstract": "Abstract Artificial intelligence (AI) is revolutionizing the field of medical imaging, holding the potential to shift medicine from a reactive \u201csick-care\u201d approach to a proactive focus on healthcare and prevention. The successful development of AI in this domain relies on access to large, comprehensive, and standardized real-world datasets that accurately represent diverse populations and diseases. However, images and data are sensitive, and as such, before using them in any way the data needs to be modified to protect the privacy of the patients. This paper explores the approaches in the domain of five EU projects working on the creation of ethically compliant and GDPR-regulated European medical imaging platforms, focused on cancer-related data. It presents the individual approaches to the de-identification of imaging data, and describes the problems and the solutions adopted in each case. Further, lessons learned are provided, enabling future projects to optimally handle the problem of data de-identification. Critical relevance statement This paper presents key approaches from five flagship EU projects for the de-identification of imaging and clinical data offering valuable insights and guidelines in the domain. Key Points \u0391\u0399 models for health imaging require access to large amounts of data. Access to large imaging datasets requires an appropriate de-identification process. This paper provides de-identification guidelines from the AI for health imaging (AI4HI) projects.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/074382848cdfa466136392c9a106561972180d0f.pdf",
        "venue": "Insights into Imaging",
        "citationCount": 0,
        "score": 0
    },
    "127b5fdae3d321cbf92a0ab39e97709afafe2191.pdf": {
        "title": "AI-based disease category prediction model using symptoms from low-resource Ethiopian language: Afaan Oromo text",
        "authors": [
            "Etana Fikadu Dinsa",
            "Mrinal Das",
            "Teklu Urgessa Abebe"
        ],
        "published_date": "2024",
        "abstract": "Automated disease diagnosis and prediction, powered by AI, play a crucial role in enabling medical professionals to deliver effective care to patients. While such predictive tools have been extensively explored in resource-rich languages like English, this manuscript focuses on predicting disease categories automatically from symptoms documented in the Afaan Oromo language, employing various classification algorithms. This study encompasses machine learning techniques such as support vector machines, random forests, logistic regression, and Na\u00efve Bayes, as well as deep learning approaches including LSTM, GRU, and Bi-LSTM. Due to the unavailability of a standard corpus, we prepared three data sets with different numbers of patient symptoms arranged into 10 categories. The two feature representations, TF-IDF and word embedding, were employed. The performance of the proposed methodology has been evaluated using accuracy, recall, precision, and F1 score. The experimental results show that, among machine learning models, the SVM model using TF-IDF had the highest accuracy and F1 score of 94.7%, while the LSTM model using word2vec embedding showed an accuracy rate of 95.7% and F1 score of 96.0% from deep learning models. To enhance the optimal performance of each model, several hyper-parameter tuning settings were used. This study shows that the LSTM model verifies to be the best of all the other models over the entire dataset.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/127b5fdae3d321cbf92a0ab39e97709afafe2191.pdf",
        "venue": "Scientific Reports",
        "citationCount": 0,
        "score": 0
    },
    "5fa7ec7ba9af0665da61d95b68f755eab224b834.pdf": {
        "title": "Medical practitioner perspectives on AI in emergency triage",
        "authors": [
            "B. Townsend",
            "K. Plant",
            "Victoria J. Hodge",
            "Ol'tunde Ashaolu",
            "R. Calinescu"
        ],
        "published_date": "2023",
        "abstract": "Introduction A proposed Diagnostic AI System for Robot-Assisted Triage (\u201cDAISY\u201d) is under development to support Emergency Department (\u201cED\u201d) triage following increasing reports of overcrowding and shortage of staff in ED care experienced within National Health Service, England (\u201cNHS\u201d) but also globally. DAISY aims to reduce ED patient wait times and medical practitioner overload. The objective of this study was to explore NHS health practitioners' perspectives and attitudes towards the future use of AI-supported technologies in ED triage. Methods Between July and August 2022 a qualitative-exploratory research study was conducted to collect and capture the perceptions and attitudes of nine NHS healthcare practitioners to better understand the challenges and benefits of a DAISY deployment. The study was based on a thematic analysis of semi-structured interviews. The study involved qualitative data analysis of the interviewees' responses. Audio-recordings were transcribed verbatim, and notes included into data documents. The transcripts were coded line-by-line, and data were organised into themes and sub-themes. Both inductive and deductive approaches to thematic analysis were used to analyse such data. Results Based on a qualitative analysis of coded interviews with the practitioners, responses were categorised into broad main thematic-types, namely: trust; current practice; social, legal, ethical, and cultural concerns; and empathetic practice. Sub-themes were identified for each main theme. Further quantitative analyses explored the vocabulary and sentiments of the participants when talking generally about NHS ED practices compared to discussing DAISY. Limitations include a small sample size and the requirement that research participants imagine a prototype AI-supported system still under development. The expectation is that such a system would work alongside the practitioner. Findings can be generalisable to other healthcare AI-supported systems and to other domains. Discussion This study highlights the benefits and challenges for an AI-supported triage healthcare solution. The study shows that most NHS ED practitioners interviewed were positive about such adoption. Benefits cited were a reduction in patient wait times in the ED, assistance in the streamlining of the triage process, support in calling for appropriate diagnostics and for further patient examination, and identification of those very unwell and requiring more immediate and urgent attention. Words used to describe the system were that DAISY is a \u201cgood idea\u201d, \u201chelp\u201d, helpful, \u201ceasier\u201d, \u201cvalue\u201d, and \u201caccurate\u201d. Our study demonstrates that trust in the system is a significant driver of use and a potential barrier to adoption. Participants emphasised social, legal, ethical, and cultural considerations and barriers to DAISY adoption and the importance of empathy and non-verbal cues in patient interactions. Findings demonstrate how DAISY might support and augment human medical performance in ED care, and provide an understanding of attitudinal barriers and considerations for the development and implementation of future triage AI-supported systems.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/5fa7ec7ba9af0665da61d95b68f755eab224b834.pdf",
        "venue": "Frontiers Digit. Health",
        "citationCount": 0,
        "score": 0
    },
    "26b3955c0c7caa01ec4ebe516ab06c86e1716971.pdf": {
        "title": "Artificial Intelligence in Hand Surgery - How Generative AI is Transforming the Hand Surgery Landscape.",
        "authors": [
            "Ruth En Si Tan",
            "Wendy Teo",
            "M. Puhaindran"
        ],
        "published_date": "2024",
        "abstract": "Artificial intelligence (AI) has witnessed significant advancements, reshaping various industries, including healthcare. The introduction of ChatGPT by OpenAI in November 2022 marked a pivotal moment, showcasing the potential of generative AI in revolutionising patient care, diagnosis and treatment. Generative AI, unlike traditional AI systems, possesses the ability to generate new content by understanding patterns within datasets. This article explores the evolution of AI in healthcare, tracing its roots to the term coined by John McCarthy in 1955 and the contributions of pioneers like John Von Neumann and Alan Turing. Currently, generative AI, particularly Large Language Models, holds promise across three broad categories in healthcare: patient care, education and research. In patient care, it offers solutions in clinical document management, diagnostic support and operative planning. Notable advancements include Microsoft's collaboration with Epic for integrating AI into electronic medical records (EMRs), enhancing clinical data management and patient care. Furthermore, generative AI aids in surgical decision-making, as demonstrated in plastic, orthopaedic and hepatobiliary surgeries. However, challenges such as bias, hallucination and integration with EMR systems necessitate caution and ongoing evaluation. The article also presents insights from the implementation of NUHS Russell-GPT, a generative AI chatbot, in a hand surgery department, showcasing its utility in administrative tasks but highlighting challenges in surgical planning and EMR integration. The survey showed unanimous support for incorporating AI into clinical settings, with all respondents being open to its use. In conclusion, generative AI is poised to enhance patient care and ease physician workloads, starting with automating administrative tasks and evolving to inform diagnoses, tailored treatment plans, as well as aid in surgical planning. As healthcare systems navigate the complexities of integrating AI, the potential benefits for both physicians and patients remain significant, offering a glimpse into a future where AI transforms healthcare delivery. Level of Evidence: Level V (Diagnostic).",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/26b3955c0c7caa01ec4ebe516ab06c86e1716971.pdf",
        "venue": "The Journal of Hand Surgery (Asian-Pacific Volume)",
        "citationCount": 0,
        "score": 0
    },
    "06ecc497edd61c2e548315a260edd0ca65242858.pdf": {
        "title": "Leveraging artificial intelligence to detect ethical concerns in medical research: a case study",
        "authors": [
            "K. Sridharan",
            "G. Sivaramakrishnan"
        ],
        "published_date": "2024",
        "abstract": "Background Institutional review boards (IRBs) have been criticised for delays in approvals for research proposals due to inadequate or inexperienced IRB staff. Artificial intelligence (AI), particularly large language models (LLMs), has significant potential to assist IRB members in a prompt and efficient reviewing process. Methods Four LLMs were evaluated on whether they could identify potential ethical issues in seven validated case studies. The LLMs were prompted with queries related to the proposed eligibility criteria of the study participants, vulnerability issues, information to be disclosed in the informed consent document (ICD), risk\u2013benefit assessment and justification of the use of a placebo. Another query was issued to the LLMs to generate ICDs for these case scenarios. Results All four LLMs were able to provide answers to the queries related to all seven cases. In general, the responses were homogeneous with respect to most elements. LLMs performed suboptimally in identifying the suitability of the placebo arm, risk mitigation strategies and potential risks to study participants in certain case studies with a single prompt. However, multiple prompts led to better outputs in all of these domains. Each of the LLMs included all of the fundamental elements of the ICD for all case scenarios. Use of jargon, understatement of benefits and failure to state potential risks were the key observations in the AI-generated ICD. Conclusion It is likely that LLMs can enhance the identification of potential ethical issues in clinical research, and they can be used as an adjunct tool to prescreen research proposals and enhance the efficiency of an IRB.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/06ecc497edd61c2e548315a260edd0ca65242858.pdf",
        "venue": "Journal of Medical Ethics",
        "citationCount": 0,
        "score": 0
    },
    "133b6ae7cc26f5ca8b9df8aa0fae460b76e1e4a5.pdf": {
        "title": "Regulatory considerations for medical imaging AI/ML devices in the United States: concepts and challenges",
        "authors": [
            "N. Petrick",
            "Weijie Chen",
            "J. Delfino",
            "B. Gallas",
            "Y. Kang",
            "Daniel M. Krainak",
            "B. Sahiner",
            "Ravi K. Samala"
        ],
        "published_date": "2023",
        "abstract": "Abstract. Purpose To introduce developers to medical device regulatory processes and data considerations in artificial intelligence and machine learning (AI/ML) device submissions and to discuss ongoing AI/ML-related regulatory challenges and activities. Approach AI/ML technologies are being used in an increasing number of medical imaging devices, and the fast evolution of these technologies presents novel regulatory challenges. We provide AI/ML developers with an introduction to U.S. Food and Drug Administration (FDA) regulatory concepts, processes, and fundamental assessments for a wide range of medical imaging AI/ML device types. Results The device type for an AI/ML device and appropriate premarket regulatory pathway is based on the level of risk associated with the device and informed by both its technological characteristics and intended use. AI/ML device submissions contain a wide array of information and testing to facilitate the review process with the model description, data, nonclinical testing, and multi-reader multi-case testing being critical aspects of the AI/ML device review process for many AI/ML device submissions. The agency is also involved in AI/ML-related activities that support guidance document development, good machine learning practice development, AI/ML transparency, AI/ML regulatory research, and real-world performance assessment. Conclusion FDA\u2019s AI/ML regulatory and scientific efforts support the joint goals of ensuring patients have access to safe and effective AI/ML devices over the entire device lifecycle and stimulating medical AI/ML innovation.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/133b6ae7cc26f5ca8b9df8aa0fae460b76e1e4a5.pdf",
        "venue": "Journal of Medical Imaging",
        "citationCount": 0,
        "score": 0
    },
    "083705b712d3bc7871f788416dd1e5209fc8cefb.pdf": {
        "title": "Comparative study of Claude 3.5-Sonnet and human physicians in generating discharge summaries for patients with renal insufficiency: assessment of efficiency, accuracy, and quality",
        "authors": [
            "Haijiao Jin",
            "Jinglu Guo",
            "Qisheng Lin",
            "Shaun Wu",
            "Weiguo Hu",
            "Xiaoyang Li"
        ],
        "published_date": "2024",
        "abstract": "Background The rapid development of artificial intelligence (AI) has shown great potential in medical document generation. This study aims to evaluate the performance of Claude 3.5-Sonnet, an advanced AI model, in generating discharge summaries for patients with renal insufficiency, compared to human physicians. Methods A prospective, comparative study was conducted involving 100 patients (50 with acute kidney injury and 50 with chronic kidney disease) from the nephrology department of Ningbo Hangzhou Bay Hospital between January and June 2024. Discharge summaries were independently generated by Claude 3.5-Sonnet and human physicians. The main evaluation indicators included accuracy, generation time, and overall quality. Results Claude 3.5-Sonnet demonstrated comparable accuracy to human physicians in generating discharge summaries for both AKI (90 vs. 92 points, p\u2009>\u20090.05) and CKD patients (88 vs. 90 points, p\u2009>\u20090.05). The AI model significantly outperformed human physicians in terms of efficiency, requiring only about 30\u2005s to generate a summary compared to over 15\u2005min for physicians (p\u2009<\u20090.001). The overall quality scores showed no significant difference between AI-generated and physician-written summaries for both AKI (26 vs. 27 points, p\u2009>\u20090.05) and CKD patients (25 vs. 26 points, p\u2009>\u20090.05). Conclusion Claude 3.5-Sonnet demonstrates high efficiency and reliability in generating discharge summaries for patients with renal insufficiency, with accuracy and quality comparable to those of human physicians. These findings suggest that AI has significant potential to improve the efficiency of medical documentation, though further research is needed to optimize its integration into clinical practice and address ethical and privacy concerns.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/083705b712d3bc7871f788416dd1e5209fc8cefb.pdf",
        "venue": "Frontiers Digit. Health",
        "citationCount": 0,
        "score": 0
    },
    "a714d172bbd0cb5ec3a40742128cc77b7f887c40.pdf": {
        "title": "Interoperability and governance in the European Health Data Space regulation",
        "authors": [
            "P. Terzis",
            "(Enrique) OE Santamaria Echeverria"
        ],
        "published_date": "2023",
        "abstract": "The proposal for a regulation on the European Health Data Space (EHDS) is a much-awaited project. It aspires to create a harmonised framework \u2013 a common European data space \u2013 for the administration of health data (primary use) across Member States and the promotion of healthcare research and innovation (by establishing rules for the secondary use of health data). As such, although the EHDS proposal is a legal document, in its essence, it includes provisions that introduce not only legal, but also institutional, and technical-infrastructural changes. Overall, together with the Regulation 2017/745 on medical devices, the Data Governance Act (DGA), the Data Act, the AI Act, and the General Data Protection Regulation (GDPR), the EHDS proposal will complete the regulatory canvas for the use of health data in the European Union. Although we are supportive of the EHDS initiative, there are aspects of the proposal that require further debate, reconsideration, and amendments. Following previous work on potential power asymmetries encapsulated in the Proposal, in this commentary, we focus on the provisions of/for interoperability of the Electronic Health Record (EHR) systems (Ar. 14\u201332) as well as the provisions on the structure of Health Data Access bodies and their cross-border organisation (section 3). We recommend a series of amendments to orientate the EHDS project better to its constitutive goals: the promotion of public health research and respect for the rights of the individuals.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/a714d172bbd0cb5ec3a40742128cc77b7f887c40.pdf",
        "venue": "Medical Law International",
        "citationCount": 0,
        "score": 0
    },
    "0dd9d7ed1c0ea7bbd605e0ed8daa26cfc21d274d.pdf": {
        "title": "AI-Assisted Detection and Localization of Spinal Metastatic Lesions",
        "authors": [
            "Edgars Edelmers",
            "Arturs Nikulins",
            "Klinta Lu\u012bze Spr\u016bd\u017ea",
            "Patr\u012bcija Stapulone",
            "Niks Saimons P\u016bce",
            "Elizabete Skrebele",
            "Everita El\u012bna Si\u0146icina",
            "Viktorija C\u012brule",
            "Ance Kazu\u0161a",
            "Katrina Bolo\u010dko"
        ],
        "published_date": "2024",
        "abstract": "Objectives: The integration of machine learning and radiomics in medical imaging has significantly advanced diagnostic and prognostic capabilities in healthcare. This study focuses on developing and validating an artificial intelligence (AI) model using U-Net architectures for the accurate detection and segmentation of spinal metastases from computed tomography (CT) images, addressing both osteolytic and osteoblastic lesions. Methods: Our methodology employs multiple variations of the U-Net architecture and utilizes two distinct datasets: one consisting of 115 polytrauma patients for vertebra segmentation and another comprising 38 patients with documented spinal metastases for lesion detection. Results: The model demonstrated strong performance in vertebra segmentation, achieving Dice Similarity Coefficient (DSC) values between 0.87 and 0.96. For metastasis segmentation, the model achieved a DSC of 0.71 and an F-beta score of 0.68 for lytic lesions but struggled with sclerotic lesions, obtaining a DSC of 0.61 and an F-beta score of 0.57, reflecting challenges in detecting dense, subtle bone alterations. Despite these limitations, the model successfully identified isolated metastatic lesions beyond the spine, such as in the sternum, indicating potential for broader skeletal metastasis detection. Conclusions: The study concludes that AI-based models can augment radiologists\u2019 capabilities by providing reliable second-opinion tools, though further refinements and diverse training data are needed for optimal performance, particularly for sclerotic lesion segmentation. The annotated CT dataset produced and shared in this research serves as a valuable resource for future advancements.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/0dd9d7ed1c0ea7bbd605e0ed8daa26cfc21d274d.pdf",
        "venue": "Diagnostics",
        "citationCount": 0,
        "score": 0
    },
    "ff72650acbfbbf38729ac540b6ff38530887cbae.pdf": {
        "title": "SOAP.AI: A Collaborative Tool for Documenting Human Behavior in Videos through Multimodal Generative AI",
        "authors": [
            "Qingxiao Zheng",
            "Parisa Rabbani",
            "Yu-Rou Lin",
            "Daan Mansour",
            "Yun Huang"
        ],
        "published_date": "2024",
        "abstract": "Large Multimodal Models offer new opportunities for analyzing human activities and social behavior in fields requiring expert knowledge. Their in-context learning and adaptive abilities make customization possible for experts without coding skills. This paper introduces SOAP.AI, a collaborative tool facilitating experts to analyze human behaviors using AI. SOAP.AI is designed to foster a sense of ownership during human-AI collaboration, encouraging task modifications and evaluations to meet diverse goals. For instance, teaching AI to recognize behavioral nuances in autistic individuals could enhance AI's inclusion and value alignment. Our demonstration will engage CSCW researchers and HCI practitioners to discuss the design of collaborative AI systems for behavioral insights generation in various settings, such as medical settings, sports, social media, education, home care, and more.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/ff72650acbfbbf38729ac540b6ff38530887cbae.pdf",
        "venue": "CSCW Companion",
        "citationCount": 0,
        "score": 0
    },
    "9be2253cd4780045263546ce52dae4d255766d05.pdf": {
        "title": "Identification of patients\u2019 smoking status using an explainable AI approach: a Danish electronic health records case study",
        "authors": [
            "Ali Ebrahimi",
            "M. Henriksen",
            "C.L. Brasen",
            "O. Hilberg",
            "T. Hansen",
            "L.H. Jensen",
            "A. Peimankar",
            "U. Wiil"
        ],
        "published_date": "2024",
        "abstract": "Background Smoking is a critical risk factor responsible for over eight million annual deaths worldwide. It is essential to obtain information on smoking habits to advance research and implement preventive measures such as screening of high-risk individuals. In most countries, including Denmark, smoking habits are not systematically recorded and at best documented within unstructured free-text segments of electronic health records (EHRs). This would require researchers and clinicians to manually navigate through extensive amounts of unstructured data, which is one of the main reasons that smoking habits are rarely integrated into larger studies. Our aim is to develop machine learning models to classify patients\u2019 smoking status from their EHRs. Methods This study proposes an efficient natural language processing (NLP) pipeline capable of classifying patients\u2019 smoking status and providing explanations for the decisions. The proposed NLP pipeline comprises four distinct components, which are; (1) considering preprocessing techniques to address abbreviations, punctuation, and other textual irregularities, (2) four cutting-edge feature extraction techniques, i.e. Embedding, BERT, Word2Vec, and Count Vectorizer, employed to extract the optimal features, (3) utilization of a Stacking-based Ensemble (SE) model and a Convolutional Long Short-Term Memory Neural Network (CNN-LSTM) for the identification of smoking status, and (4) application of a local interpretable model-agnostic explanation to explain the decisions rendered by the detection models. The EHRs of 23,132 patients with suspected lung cancer were collected from the Region of Southern Denmark during the period 1/1/2009-31/12/2018. A medical professional annotated the data into \u2018Smoker\u2019 and \u2018Non-Smoker\u2019 with further classifications as \u2018Active-Smoker\u2019, \u2018Former-Smoker\u2019, and \u2018Never-Smoker\u2019. Subsequently, the annotated dataset was used for the development of binary and multiclass classification models. An extensive comparison was conducted of the detection performance across various model architectures. Results The results of experimental validation confirm the consistency among the models. However, for binary classification, BERT method with CNN-LSTM architecture outperformed other models by achieving precision, recall, and F1-scores between 97% and 99% for both Never-Smokers and Active-Smokers. In multiclass classification, the Embedding technique with CNN-LSTM architecture yielded the most favorable results in class-specific evaluations, with equal performance measures of 97% for Never-Smoker and measures in the range of 86 to 89% for Active-Smoker and 91\u201392% for Never-Smoker. Conclusion Our proposed NLP pipeline achieved a high level of classification performance. In addition, we presented the explanation of the decision made by the best performing detection model. Future work will expand the model\u2019s capabilities to analyze longer notes and a broader range of categories to maximize its utility in further research and screening applications.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/9be2253cd4780045263546ce52dae4d255766d05.pdf",
        "venue": "BMC Medical Research Methodology",
        "citationCount": 0,
        "score": 0
    },
    "977122e69a7a717d5f8c0038e99cc1e323f0c445.pdf": {
        "title": "Public data homogenization for AI model development in breast cancer",
        "authors": [
            "Vassilis Kilintzis",
            "Varvara Kalokyri",
            "H. Kondylakis",
            "Smriti Joshi",
            "K. Nikiforaki",
            "Oliver D\u00edaz",
            "Karim Lekadir",
            "M. Tsiknakis",
            "K. Marias"
        ],
        "published_date": "2024",
        "abstract": "Background Developing trustworthy artificial intelligence (AI) models for clinical applications requires access to clinical and imaging data cohorts. Reusing of publicly available datasets has the potential to fill this gap. Specifically in the domain of breast cancer, a large archive of publicly accessible medical images along with the corresponding clinical data is available at The Cancer Imaging Archive (TCIA). However, existing datasets cannot be directly used as they are heterogeneous and cannot be effectively filtered for selecting specific image types required to develop AI models. This work focuses on the development of a homogenized dataset in the domain of breast cancer including clinical and imaging data. Methods Five datasets were acquired from the TCIA and were harmonized. For the clinical data harmonization, a common data model was developed and a repeatable, documented \u201cextract-transform-load\u201d process was defined and executed for their homogenization. Further, Digital Imaging and COmmunications in Medicine (DICOM) information was extracted from magnetic resonance imaging (MRI) data and made accessible and searchable. Results The resulting harmonized dataset includes information about 2,035 subjects with breast cancer. Further, a platform named RV-Cherry-Picker enables search over both the clinical and diagnostic imaging datasets, providing unified access, facilitating the downloading of all study imaging that correspond to specific series\u2019 characteristics (e.g., dynamic contrast-enhanced series), and reducing the burden of acquiring the appropriate set of images for the respective AI model scenario. Conclusions RV-Cherry-Picker provides access to the largest, publicly available, homogenized, imaging/clinical dataset for breast cancer to develop AI models on top. Relevance statement We present a solution for creating merged public datasets supporting AI model development, using as an example the breast cancer domain and magnetic resonance imaging images. Key points \u2022 The proposed platform allows unified access to the largest, homogenized public imaging dataset for breast cancer. \u2022 A methodology for the semantically enriched homogenization of public clinical data is presented. \u2022 The platform is able to make a detailed selection of breast MRI data for the development of AI models. Graphical Abstract Supplementary Information The online version contains supplementary material available at 10.1186/s41747-024-00442-4.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/977122e69a7a717d5f8c0038e99cc1e323f0c445.pdf",
        "venue": "European Radiology Experimental",
        "citationCount": 0,
        "score": 0
    },
    "de039759b6da9ffd23dec6d272e76015e50d7156.pdf": {
        "title": "Requirements for AI Development and Reporting for MRI Prostate Cancer Detection in Biopsy-Naive Men: PI-RADS Steering Committee, Version 1.0.",
        "authors": [
            "B. Turkbey",
            "Henkjan Huisman",
            "Andriy Fedorov",
            "K. Macura",
            "D. Margolis",
            "V. Panebianco",
            "Aytekin Oto",
            "Ivo G. Schoots",
            "M. M. Siddiqui",
            "Caroline M Moore",
            "Olivier Rouvi\u00e8re",
            "L. K. Bittencourt",
            "A. Padhani",
            "Clare Tempany",
            "Masoom A Haider"
        ],
        "published_date": "2025",
        "abstract": "This document defines the key considerations for developing and reporting an artificial intelligence (AI) interpretation model for the detection of clinically significant prostate cancer (PCa) at MRI in biopsy-naive men with a positive clinical screening status. Specific data and performance metric requirements and a checklist are provided for this use case. Data requirements emphasize the need for sufficient information to provide transparency and characterization of training and test data. The definition of a true-negative examination (which includes a minimum of 2-year follow-up), the need for image quality assessments, and nonimaging metadata requirements are provided. Performance metrics ranges are included, such as a cancer detection rate of 40%-70% for Prostate Imaging Reporting and Data System, or PI-RADS, 4 or higher lesions and demonstration of equivalent or better than human performance using receiver operating characteristic and precision-recall curves. The use of open datasets such as those used in the AI challenge model is encouraged. The study design should include conformity with the Checklist for Artificial Intelligence in Medical Imaging requirements. This article should be taken in the context of the current and evolving regulatory landscape. This review provides guidance based on subspeciality expertise in prostate MRI and will hopefully accelerate the clinical translation of AI in PCa detection.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/de039759b6da9ffd23dec6d272e76015e50d7156.pdf",
        "venue": "Radiology",
        "citationCount": 0,
        "score": 0
    },
    "1aad7f61e4f8988a0b201c85de7740bf05d157c0.pdf": {
        "title": "Assessing the Role Ghana's Public Health Act, 2012 (Act 851) Can Play in Oversight of Artificial Intelligence Healthcare Systems to Prevent Medical Errors and Improve Patient Safety",
        "authors": [
            "George Benneh Mensah",
            "Maad M. Mijwil",
            "Mostafa Abotaleb",
            "Sayed M. El-kenawy",
            "Marwa M. Eid",
            "Pushan Kumar Dutta",
            "Alfred Addy"
        ],
        "published_date": "2023",
        "abstract": "Purpose: Evaluate the possibilities and limitations of implementing the Essential Ghana Public Health Act to manage the growing development of artificial intelligence (AI)-enabled health care in light of the contemporary gap in research so. \nMethodology: A review of the 2012 public health regulatory provisions and anti-technology surveillance mechanisms document detailing the needs and risks of AI regulation. \nResults: Current regulations have a customizable foundation for documenting policies, reporting algorithmic errors, creating updated workplace safety audits, and enforcing non-compliance but required by fully implemented investigations that strong material differences are addressed and that AI-specific rules are codified into new legal rules. \nConclusions: Ghana currently has the mechanisms in place for an interim administration to flexibly implement long-term healthcare legislation on gaps awaiting reconciliation through investment in specific sectors, staffing and reforms. \nRecommendations: Immediate training to prepare inspection personnel before the onset of the crisis is guidelines and rules for algorithmic accounting. What really matters is the effective implementation of existing legislation and the informing of strategies for modernization and certainly also the innovation of policy frameworks for the innovation of new health care systems. \nScientific contribution: addresses the knowledge gap in maintaining vulnerabilities for emerging technologies that are tracked by regulations in disruption.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/1aad7f61e4f8988a0b201c85de7740bf05d157c0.pdf",
        "venue": "Babylonian Journal of Artificial Intelligence",
        "citationCount": 0,
        "score": 0
    },
    "1ce60e219788fb5b69e5c85daecbdb00fb392dad.pdf": {
        "title": "Preparing Well for Esophageal Endoscopic Detection Using a Hybrid Model and Transfer Learning",
        "authors": [
            "C. Chou",
            "H. Nguyen",
            "Yao-Kuang Wang",
            "Tsung-Hsien Chen",
            "I-Chen Wu",
            "Chien-Wei Huang",
            "Hsiang-Chen Wang"
        ],
        "published_date": "2023",
        "abstract": "Simple Summary The timely detection and accurate classification of esophageal cancer are critical for providing optimal treatment. However, assessing and categorizing pathological conditions related to the esophagus face limitations as they rely on reference document photo-documentation, and the accuracy heavily relies on the endoscopist\u2019s expertise. In recent times, computer-aided endoscopic image classification has achieved remarkable success in this domain. For this study, a dataset of 1002 endoscopic images, comprising 650 white-light images and 352 narrow-band images, was collected for training. The esophageal neoplasms were categorized into three groups: squamous cell carcinoma, high-grade dysplasia, and normal cases. To enhance the prediction results, a hybrid model was proposed, yielding an impressive accuracy of 96.32%, precision of 96.44%, recall of 95.70%, and f1-score of 96.04%. The introduction of AI-based diagnostic platforms is expected to effectively support medical professionals in formulating well-informed treatment regimens. Abstract Early detection of esophageal cancer through endoscopic imaging is pivotal for effective treatment. However, the intricacies of endoscopic diagnosis, contingent on the physician\u2019s expertise, pose challenges. Esophageal cancer features often manifest ambiguously, leading to potential confusions with other inflammatory esophageal conditions, thereby complicating diagnostic accuracy. In recent times, computer-aided diagnosis has emerged as a promising solution in medical imaging, particularly within the domain of endoscopy. Nonetheless, contemporary AI-based diagnostic models heavily rely on voluminous data sources, limiting their applicability, especially in scenarios with scarce datasets. To address this limitation, our study introduces novel data training strategies based on transfer learning, tailored to optimize performance with limited data. Additionally, we propose a hybrid model integrating EfficientNet and Vision Transformer networks to enhance prediction accuracy. Conducting rigorous evaluations on a carefully curated dataset comprising 1002 endoscopic images (comprising 650 white-light images and 352 narrow-band images), our model achieved exceptional outcomes. Our combined model achieved an accuracy of 96.32%, precision of 96.44%, recall of 95.70%, and f1-score of 96.04%, surpassing state-of-the-art models and individual components, substantiating its potential for precise medical image classification. The AI-based medical image prediction platform presents several advantageous characteristics, encompassing superior prediction accuracy, a compact model size, and adaptability to low-data scenarios. This research heralds a significant stride in the advancement of computer-aided endoscopic imaging for improved esophageal cancer diagnosis.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/1ce60e219788fb5b69e5c85daecbdb00fb392dad.pdf",
        "venue": "Cancers",
        "citationCount": 0,
        "score": 0
    },
    "31306a2f84da4f71a2cab9a3ffb9c9200b6dbc7e.pdf": {
        "title": "Fine-tuning and aligning question answering models for complex information extraction tasks",
        "authors": [
            "Matthias Engelbach",
            "Dennis Klau",
            "Felix Scheerer",
            "Jens Drawehn",
            "Maximilien Kintz"
        ],
        "published_date": "2023",
        "abstract": "The emergence of Large Language Models (LLMs) has boosted performance and possibilities in various NLP tasks. While the usage of generative AI models like ChatGPT opens up new opportunities for several business use cases, their current tendency to hallucinate fake content strongly limits their applicability to document analysis, such as information retrieval from documents. In contrast, extractive language models like question answering (QA) or passage retrieval models guarantee query results to be found within the boundaries of an according context document, which makes them candidates for more reliable information extraction in productive environments of companies. In this work we propose an approach that uses and integrates extractive QA models for improved feature extraction of German business documents such as insurance reports or medical leaflets into a document analysis solution. We further show that fine-tuning existing German QA models boosts performance for tailored extraction tasks of complex linguistic features like damage cause explanations or descriptions of medication appearance, even with using only a small set of annotated data. Finally, we discuss the relevance of scoring metrics for evaluating information extraction tasks and deduce a combined metric from Levenshtein distance, F1-Score, Exact Match and ROUGE-L to mimic the assessment criteria from human experts.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/31306a2f84da4f71a2cab9a3ffb9c9200b6dbc7e.pdf",
        "venue": "International Conference on Knowledge Discovery and Information Retrieval",
        "citationCount": 0,
        "score": 0
    },
    "5785e1136c7009f57b3ef4079a867c2435b0bdbb.pdf": {
        "title": "Trends in the Approval and Quality Management of Artificial Intelligence Medical Devices in the Republic of Korea",
        "authors": [
            "Kyoungtaek Lim",
            "Tae-Young Heo",
            "Jaesuk Yun"
        ],
        "published_date": "2022",
        "abstract": "Artificial intelligence (AI) is being implemented in many areas of medicine, such as patient-customized diagnosis. Growth in the artificial intelligence medical device (AIMD) field is expected in the coming years. Major countries are currently establishing systems and policies to gain a leading position in the medical artificial intelligence market. The Republic of Korea has initiated the Act on Nurturing the Medical Devices Industry and Supporting Innovative Medical Devices for the development of AIMDs and is implementing it preemptively. As a result, the country has achieved an effective strategy for coping with the COVID-19 pandemic, an increase in the number of AIMD approvals (85 approved as of September 2021), and the creation of a document pertaining to internationally harmonized guidelines on AIMD-related terms and definitions. However, in order to develop and activate more AIMD products, it is necessary to improve post-market management such as product change and quality control in addition to approval. Here, we review the current regulatory status of AIMD in the Republic of Korea and what needs to be improved for AIMD to be more developed and activated.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/5785e1136c7009f57b3ef4079a867c2435b0bdbb.pdf",
        "venue": "Diagnostics",
        "citationCount": 0,
        "score": 0
    },
    "2253c84f0d7422bbbec496893948e1e1297bcab2.pdf": {
        "title": "Biomedical Large Languages Models Seem not to be Superior to Generalist Models on Unseen Medical Data",
        "authors": [
            "Felix J. Dorfner",
            "Amin Dada",
            "Felix Busch",
            "Marcus R. Makowski",
            "T. Han",
            "Daniel Truhn",
            "J. Kleesiek",
            "Madhumita Sushil",
            "Jacqueline Lammert",
            "Lisa C. Adams",
            "K. Bressem"
        ],
        "published_date": "2024",
        "abstract": "Large language models (LLMs) have shown potential in biomedical applications, leading to efforts to fine-tune them on domain-specific data. However, the effectiveness of this approach remains unclear. This study evaluates the performance of biomedically fine-tuned LLMs against their general-purpose counterparts on a variety of clinical tasks. We evaluated their performance on clinical case challenges from the New England Journal of Medicine (NEJM) and the Journal of the American Medical Association (JAMA) and on several clinical tasks (e.g., information extraction, document summarization, and clinical coding). Using benchmarks specifically chosen to be likely outside the fine-tuning datasets of biomedical models, we found that biomedical LLMs mostly perform inferior to their general-purpose counterparts, especially on tasks not focused on medical knowledge. While larger models showed similar performance on case tasks (e.g., OpenBioLLM-70B: 66.4% vs. Llama-3-70B-Instruct: 65% on JAMA cases), smaller biomedical models showed more pronounced underperformance (e.g., OpenBioLLM-8B: 30% vs. Llama-3-8B-Instruct: 64.3% on NEJM cases). Similar trends were observed across the CLUE (Clinical Language Understanding Evaluation) benchmark tasks, with general-purpose models often performing better on text generation, question answering, and coding tasks. Our results suggest that fine-tuning LLMs to biomedical data may not provide the expected benefits and may potentially lead to reduced performance, challenging prevailing assumptions about domain-specific adaptation of LLMs and highlighting the need for more rigorous evaluation frameworks in healthcare AI. Alternative approaches, such as retrieval-augmented generation, may be more effective in enhancing the biomedical capabilities of LLMs without compromising their general knowledge.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/2253c84f0d7422bbbec496893948e1e1297bcab2.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "48bae2de68dcf4535a7de76ce15d447e503fddc8.pdf": {
        "title": "Advancing Conversational Diagnostic AI with Multimodal Reasoning",
        "authors": [
            "Khaled Saab",
            "Jan Freyberg",
            "Chunjong Park",
            "Tim Strother",
            "Yong Cheng",
            "Wei-Hung Weng",
            "David G. T. Barrett",
            "David Stutz",
            "Nenad Toma\u0161ev",
            "Anil Palepu",
            "Valentin Li'evin",
            "Yash Sharma",
            "Roma Ruparel",
            "Abdullah Ahmed",
            "Elahe Vedadi",
            "K. Kanada",
            "C\u00edan Hughes",
            "Yun Liu",
            "Geoff Brown",
            "Yang Gao",
            "Sean Li",
            "S. Mahdavi",
            "James Manyika",
            "Katherine Chou",
            "Yossi Matias",
            "A. Hassidim",
            "Dale R. Webster",
            "Pushmeet Kohli",
            "S. M. A. Eslami",
            "Joelle K. Barral",
            "Adam Rodman",
            "Vivek Natarajan",
            "Mike Schaekermann",
            "Tao Tu",
            "A. Karthikesalingam",
            "Ryutaro Tanno"
        ],
        "published_date": "2025",
        "abstract": "Large Language Models (LLMs) have demonstrated great potential for conducting diagnostic conversations but evaluation has been largely limited to language-only interactions, deviating from the real-world requirements of remote care delivery. Instant messaging platforms permit clinicians and patients to upload and discuss multimodal medical artifacts seamlessly in medical consultation, but the ability of LLMs to reason over such data while preserving other attributes of competent diagnostic conversation remains unknown. Here we advance the conversational diagnosis and management performance of the Articulate Medical Intelligence Explorer (AMIE) through a new capability to gather and interpret multimodal data, and reason about this precisely during consultations. Leveraging Gemini 2.0 Flash, our system implements a state-aware dialogue framework, where conversation flow is dynamically controlled by intermediate model outputs reflecting patient states and evolving diagnoses. Follow-up questions are strategically directed by uncertainty in such patient states, leading to a more structured multimodal history-taking process that emulates experienced clinicians. We compared AMIE to primary care physicians (PCPs) in a randomized, blinded, OSCE-style study of chat-based consultations with patient actors. We constructed 105 evaluation scenarios using artifacts like smartphone skin photos, ECGs, and PDFs of clinical documents across diverse conditions and demographics. Our rubric assessed multimodal capabilities and other clinically meaningful axes like history-taking, diagnostic accuracy, management reasoning, communication, and empathy. Specialist evaluation showed AMIE to be superior to PCPs on 7/9 multimodal and 29/32 non-multimodal axes (including diagnostic accuracy). The results show clear progress in multimodal conversational diagnostic AI, but real-world translation needs further research.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/48bae2de68dcf4535a7de76ce15d447e503fddc8.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    },
    "30bee7c88ecb3a341904d674988bb1cece0fdec3.pdf": {
        "title": "MASS: A Multiattribute Sketch Secure Data Sharing Scheme for IoT Wearable Medical Devices Based on Blockchain",
        "authors": [
            "Lin Chen",
            "Yuxiang Chen",
            "Wei Liang",
            "Xiong Li",
            "Kuan Ching Li",
            "Jin Wang",
            "Neal N. Xiong"
        ],
        "published_date": "2025",
        "abstract": "With the swift advancement of the Internet of Things (IoT) and artificial intelligence (AI), various technologies have been integrated into wearable medical health devices, improving users\u2019 awareness of their physical states and enabling the analysis of a greater amount of human data. However, these sensitive pieces of information are prone to tampering or theft during storage and transmission, posing security risks. In this article, we propose a multiattribute sketch secure data sharing scheme for IoT wearable medical devices based on blockchain (MASS). We introduce a multiattribute sketch storage method that stores the encrypted hash of health data transmitted by medical wearable devices on the blockchain. This work also designs a ciphertext-policy attribute-based encryption (CP-ABE) access control mechanism that effectively addresses the secure sharing of data from wearable medical devices among healthcare professionals. Experimental findings indicate that with the rise in the number of medical health data documents, the costs associated with index generation and search time decrease by 55.3% and 10.83%, respectively. Additionally, as the frequency of data access increases, there is a 13.5% reduction in encryption time, and the implementation of multiattribute sketches results in a 24.8% and 11.3% reduction in index generation and search times, respectively.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/30bee7c88ecb3a341904d674988bb1cece0fdec3.pdf",
        "venue": "IEEE Internet of Things Journal",
        "citationCount": 0,
        "score": 0
    },
    "38e3c07394a9da343bbe3f3132cd79dec8c920b0.pdf": {
        "title": "AI-driven intelligent document processing for healthcare and insurance",
        "authors": [
            "Ramesh Pingili"
        ],
        "published_date": "2025",
        "abstract": "Healthcare and insurance industries handle millions of documents daily, leading to administrative bottlenecks, errors, and inefficiencies. This paper explores AI-driven Intelligent Document Processing (IDP) for automating claims, medical records, and regulatory compliance documents. Integrating machine learning (ML), natural language processing (NLP), and RPA, IDP reduces document processing time by 80% and error rates by 90%. Case studies from top hospitals and insurers demonstrate AI\u2019s role in streamlining workflows, enhancing patient care, and accelerating claims processing [1]. This research establishes IDP as a critical AI-driven transformation for document-heavy industries.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/38e3c07394a9da343bbe3f3132cd79dec8c920b0.pdf",
        "venue": "International Journal of Science and Research Archive",
        "citationCount": 0,
        "score": 0
    },
    "89f1a1abb18ff4fcca3a54df51905a4647bf36ba.pdf": {
        "title": "Quantum-assisted federated intelligent diagnosis algorithm with variational training supported by 5G networks",
        "authors": [
            "Arnaldo Rafael Camara Araujo",
            "O. Okey",
            "Muhammad Saadi",
            "P. Adasme",
            "R. L. Rosa",
            "D. Z. Rodr\u00edguez"
        ],
        "published_date": "2024",
        "abstract": "In the realm of intelligent healthcare, there is a growing ambition to reshape medical services through the integration of artificial intelligence (AI). However, conventional machine learning faces inherent challenges such as privacy issues, delayed updates, and protracted training times, particularly due to the hesitance of medical institutions to directly share sensitive data, with possible noises. In response to these concerns, a Quantum-Assisted Federated Intelligent Diagnosis Algorithm (\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$\\beta $$\\end{document}\u03b2-QuAFIDA) is proposed, applied into real medical data. Leveraging the capabilities of the 5G mobile network, this approach works the connection between Internet of Medical Things (IoMT) devices through the 5G, synchronizing training and updating the server model without disrupting their real-world applications. In our quest to safeguard patient data and enhance training efficiency, our study employs an innovative heuristic approach marked by a nested loop structure. Specifically, the inner loop is dedicated to training the beta-variational quantum eigensolver (\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$\\beta $$\\end{document}\u03b2-VQE) to approximate the expectation values of the proposed algorithm; the outer loop trains the \\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$\\beta $$\\end{document}\u03b2-QuAFIDA to reduce the relative entropy towards the target. This approach involves a balance between privacy considerations and the urgency of training. Results demonstrate that representations with low-rank attained through \\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$\\beta $$\\end{document}\u03b2-QuAFIDA offer an effective approach for acquiring low-rank states. This research signifies a step forward in the synergy between AI and 5G technologies, presenting a novel avenue for the advancement of intelligent healthcare.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/89f1a1abb18ff4fcca3a54df51905a4647bf36ba.pdf",
        "venue": "Scientific Reports",
        "citationCount": 0,
        "score": 0
    },
    "67335a676ae3b4e17a4494edf19b2101484cd5b4.pdf": {
        "title": "AI-assisted Blockchain-enabled Smart and Secure E-prescription Management Framework",
        "authors": [
            "Siva Sai",
            "V. Chamola"
        ],
        "published_date": "2024",
        "abstract": "Traditional medical prescriptions based on physical paper-based documents are prone to manipulation, errors, and unauthorized reproduction due to their format. Addressing the limitations of the traditional prescription system, e-prescription systems have been introduced in several countries. However, e-prescription systems lead to several concerns like the risk of privacy loss, the problem of double-spending prescriptions, lack of interoperability, and single point of failure, all of which need to be addressed immediately. We propose an AI-assisted blockchain-enabled smart and secure e-prescription management framework to address these issues. Our proposed system overcomes the problems of the centralized e-prescription systems and enables efficient consent management to access prescriptions by incorporating blockchain-based smart contracts. Our work incorporates the Umbral proxy re-encryption scheme in the proposed system, avoiding the need for repeated encryption and decryption of the prescriptions when transferred between different entities in the network. In our work, we employ two different machine learning models(Random Forest classifier and LightGBM classifier) to assist the doctor in prescribing medicines. One is a drug recommendation model, which is aimed at providing drug recommendations considering the medical history of the patients and the general prescription pattern for the particular ailment of the patient. We have fine-tuned the SciBERT model for adverse drug reaction detection. The extensive experimentation and results show that the proposed e-prescription framework is secure, scalable, and interoperable. Further, the proposed machine learning models produce results higher than 95%.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/67335a676ae3b4e17a4494edf19b2101484cd5b4.pdf",
        "venue": "ACM Transactions on Internet Technology",
        "citationCount": 0,
        "score": 0
    },
    "932e9cc1777b5c7857d05e85073592aa57bd9c7a.pdf": {
        "title": "The Role of AI in Cardiovascular Event Monitoring and Early Detection: Scoping Literature Review",
        "authors": [
            "L. Elvas",
            "Ana Almeida",
            "Jo\u00e3o C. Ferreira"
        ],
        "published_date": "2025",
        "abstract": "Abstract Background Artificial intelligence (AI) has shown exponential growth and advancements, revolutionizing various fields, including health care. However, domain adaptation remains a significant challenge, as machine learning (ML) models often need to be applied across different health care settings with varying patient demographics and practices. This issue is critical for ensuring effective and equitable AI deployment. Cardiovascular diseases (CVDs), the leading cause of global mortality with 17.9 million annual deaths, encompass conditions like coronary heart disease and hypertension. The increasing availability of medical data, coupled with AI advancements, offers new opportunities for early detection and intervention in cardiovascular events, leveraging AI\u2019s capacity to analyze complex datasets and uncover critical patterns. Objective This review aims to examine AI methodologies combined with medical data to advance the intelligent monitoring and detection of CVDs, identifying areas for further research to enhance patient outcomes and support early interventions. Methods This review follows the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) methodology to ensure a rigorous and transparent literature review process. This structured approach facilitated a comprehensive overview of the current state of research in this field. Results Through the methodology used, 64 documents were retrieved, of which 40 documents met the inclusion criteria. The reviewed papers demonstrate advancements in AI and ML for CVD detection, classification, prediction, diagnosis, and patient monitoring. Techniques such as ensemble learning, deep neural networks, and feature selection improve prediction accuracy over traditional methods. ML models predict cardiovascular events and risks, with applications in monitoring via wearable technology. The integration of AI in health care supports early detection, personalized treatment, and risk assessment, possibly improving the management of CVDs. Conclusions The study concludes that AI and ML techniques can improve the accuracy of CVD classification, prediction, diagnosis, and monitoring. The integration of multiple data sources and noninvasive methods supports continuous monitoring and early detection. These advancements help enhance CVD management and patient outcomes, indicating the potential for AI to offer more precise and cost-effective solutions in health care.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/932e9cc1777b5c7857d05e85073592aa57bd9c7a.pdf",
        "venue": "JMIR Medical Informatics",
        "citationCount": 0,
        "score": 0
    },
    "ef0281435edcd64ae07236fedbca3041f7de8fe4.pdf": {
        "title": "Assessing the documentation of publicly available medical image and signal datasets and their impact on bias using the BEAMRAD tool",
        "authors": [
            "Maria Galanty",
            "Dieuwertje Luitse",
            "Sijm H. Noteboom",
            "Philip Croon",
            "A. Vlaar",
            "Thomas Poell",
            "Clara I. S\u00e1nchez",
            "Tobias Blanke",
            "Ivana I\u0161gum"
        ],
        "published_date": "2024",
        "abstract": "Medical datasets are vital for advancing Artificial Intelligence (AI) in healthcare. Yet biases in these datasets on which deep-learning models are trained can compromise reliability. This study investigates biases stemming from dataset-creation practices. Drawing on existing guidelines, we first developed a BEAMRAD tool to assess the documentation of public Magnetic Resonance Imaging (MRI); Color Fundus Photography (CFP), and Electrocardiogram (ECG) datasets. In doing so, we provide an overview of the biases that may emerge due to inadequate dataset documentation. Second, we examine the current state of documentation for public medical images and signal data. Our research reveals that there is substantial variance in the documentation of image and signal datasets, even though guidelines have been developed in medical imaging. This indicates that dataset documentation is subject to individual discretionary decisions. Furthermore, we find that aspects such as hardware and data acquisition details are commonly documented, while information regarding data annotation practices, annotation error quantification, or data limitations are not consistently reported. This risks having considerable implications for the abilities of data users to detect potential sources of bias through these respective aspects and develop reliable and robust models that can be adapted for clinical practice. Supplementary Information The online version contains supplementary material available at 10.1038/s41598-024-83218-5.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/ef0281435edcd64ae07236fedbca3041f7de8fe4.pdf",
        "venue": "Scientific Reports",
        "citationCount": 0,
        "score": 0
    },
    "63f394b905ac6eec49cf0eaa42cbdaa35dd49d01.pdf": {
        "title": "A systematic review of AI-based chatbot usages in healthcare services.",
        "authors": [
            "K. Mohamed Jasim",
            "A. Malathi",
            "Seema Bhardwaj",
            "Eugene Cheng\u2010Xi Aw"
        ],
        "published_date": "2025",
        "abstract": "PURPOSE\nThis systematic literature review aims to provide a comprehensive and structured synthesis of the existing knowledge about chatbots in healthcare from both a theoretical and methodological perspective.\n\n\nDESIGN/METHODOLOGY/APPROACH\nTo this end, a systematic literature review was conducted with 89 articles selected through a SPAR-4-SLR systematic procedure. The document for this systematic review was collected from Scopus database. The VoSviewer software facilitates the analysis of keyword co-occurrence to form the fundamental structure of the subject field.\n\n\nFINDINGS\nIn addition, this study proposes a future research agenda revolving around three main themes such as (1) telemedicine, (2) mental health and (3) medical information.\n\n\nORIGINALITY/VALUE\nThis study underscores the significance, implications and predictors of chatbot usage in healthcare services. It is concluded that adopting the proposed future direction and further research on chatbots in healthcare will help to refine chatbot systems to better meet the needs of patients.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/63f394b905ac6eec49cf0eaa42cbdaa35dd49d01.pdf",
        "venue": "Journal of health organization and management",
        "citationCount": 0,
        "score": 0
    },
    "8b12f4303a7981806bf65c345f3b4291b556bfd8.pdf": {
        "title": "Investigating State-of-the-Art Frontiers in Artificial Intelligence: A Synopsis of Trends and Innovations",
        "authors": [
            "Sohana Akter"
        ],
        "published_date": "2024",
        "abstract": "Artificial intelligence (AI) has undergone rapid evolution in recent decades, catalysing the emergence of ground-breaking technologies that have reshaped various sectors. Among these advancements is the advent of autonomous vehicles, poised to revolutionize transportation and mobility. Moreover, AI has spurred the development of cutting-edge solutions in healthcare, exemplified by AI-powered medical imaging systems. This manuscript presents an overview of AI's evolution and explores the latest strides in autonomous vehicles and healthcare innovations. Delving into the foundational technologies like machine learning and computer vision, it elucidates the methodologies employed in crafting autonomous vehicles and healthcare solutions. The document also scrutinizes the advantages and hurdles inherent in these innovations, while offering insights into future avenues of research. Overall, it underscores AI's profound impact on transportation, healthcare, and beyond, underscoring the transformative potential of autonomous vehicles and healthcare technologies in fostering safer and more efficient mobility and healthcare systems.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/8b12f4303a7981806bf65c345f3b4291b556bfd8.pdf",
        "venue": "Journal of Artificial Intelligence General science (JAIGS) ISSN:3006-4023",
        "citationCount": 0,
        "score": 0
    },
    "0e526c254ff4c26bb42fd58d2a9eea5493c097da.pdf": {
        "title": "AI Scribes: Boosting Physician Efficiency in Clinical Documentation",
        "authors": [
            "Omosalewa Itauma",
            "I. Itauma"
        ],
        "published_date": "2024",
        "abstract": "The increasing demand on healthcare systems has amplified the burden on physicians and other healthcare professionals, with a huge portion of time dedicated to documenting patient encounters. Prolonged charting periods not only contribute to decreased physician productivity but also emerge as a prominent factor in physician burnout. This study investigates the potential of Artificial Intelligence (AI) to mitigate this challenge, focusing on AI-powered medical scribing as a solution to alleviate the burden of traditional charting methods in documentation of patient encounters and improve overall physician productivity. This research contributes to the ongoing discourse on the role of AI in healthcare and seeks to inform healthcare professionals, administrators, and policymakers about the potential benefits of integrating AI-powered medical scribing to improve physician efficiency and mitigate the impact of extensive charting on overall productivity and well-being.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/0e526c254ff4c26bb42fd58d2a9eea5493c097da.pdf",
        "venue": "International Journal on Bioinformatics &amp; Biosciences",
        "citationCount": 0,
        "score": 0
    },
    "82199d36d788f9683895ef4564103d2d51e0fd82.pdf": {
        "title": "Enhancing patient understanding in obstetrics: The role of generative AI in simplifying informed consent for labor induction with oxytocin",
        "authors": [
            "A. Gr\u00fcnebaum",
            "Joachim W. Dudenhausen",
            "F. Chervenak"
        ],
        "published_date": "2024",
        "abstract": "Abstract Informed consent is a cornerstone of ethical medical practice, particularly in obstetrics where procedures like labor induction carry significant risks and require clear patient understanding. Despite legal mandates for patient materials to be accessible, many consent forms remain too complex, resulting in patient confusion and dissatisfaction. This study explores the use of Generative Artificial Intelligence (GAI) to simplify informed consent for labor induction with oxytocin, ensuring content is both medically accurate and comprehensible at an 8th-grade readability level. GAI-generated consent forms streamline the process, automatically tailoring content to meet readability standards while retaining essential details such as the procedure\u2019s nature, risks, benefits, and alternatives. Through iterative prompts and expert refinement, the AI produces clear, patient-friendly language that bridges the gap between medical jargon and patient comprehension. Flesch Reading Ease scores show improved readability, meeting recommended levels for health literacy. GAI has the potential to revolutionize healthcare communication by enhancing patient understanding, promoting shared decision-making, and improving satisfaction with the consent process. However, human oversight remains critical to ensure that AI-generated content adheres to legal and ethical standards. This case study demonstrates that GAI can be an effective tool in creating accessible, standardized, yet personalized consent documents, contributing to better-informed patients and potentially reducing malpractice claims.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/82199d36d788f9683895ef4564103d2d51e0fd82.pdf",
        "venue": "Journal of Perinatal Medicine",
        "citationCount": 0,
        "score": 0
    },
    "83cd33a1b71ce8b5df6289120df41b0f9da3542f.pdf": {
        "title": "Retrieval-augmented systems can be dangerous medical communicators",
        "authors": [
            "Lionel Wong",
            "Ayman Ali",
            "Raymond Xiong",
            "Shannon Shen",
            "Yoon Kim",
            "Monica Agrawal"
        ],
        "published_date": "2025",
        "abstract": "Patients have long sought health information online, and increasingly, they are turning to generative AI to answer their health-related queries. Given the high stakes of the medical domain, techniques like retrieval-augmented generation and citation grounding have been widely promoted as methods to reduce hallucinations and improve the accuracy of AI-generated responses and have been widely adopted into search engines. This paper argues that even when these methods produce literally accurate content drawn from source documents sans hallucinations, they can still be highly misleading. Patients may derive significantly different interpretations from AI-generated outputs than they would from reading the original source material, let alone consulting a knowledgeable clinician. Through a large-scale query analysis on topics including disputed diagnoses and procedure safety, we support our argument with quantitative and qualitative evidence of the suboptimal answers resulting from current systems. In particular, we highlight how these models tend to decontextualize facts, omit critical relevant sources, and reinforce patient misconceptions or biases. We propose a series of recommendations -- such as the incorporation of communication pragmatics and enhanced comprehension of source documents -- that could help mitigate these issues and extend beyond the medical domain.",
        "file_path": "paper_data/AI_for_Medical_Document_Understanding/83cd33a1b71ce8b5df6289120df41b0f9da3542f.pdf",
        "venue": "arXiv.org",
        "citationCount": 0,
        "score": 0
    }
}