\subsection{Inherent Challenges: Mode Collapse and Training Instability}

Early Generative Adversarial Networks (GANs), despite their theoretical promise, were severely hampered by fundamental training difficulties that manifested as pervasive instability and a critical failure known as mode collapse \cite{jabbar2020aj0, wiatrak20194ib, chu2020zbv}. These issues stemmed directly from the adversarial training framework, where the generator (G) and discriminator (D) engage in a continuous minimax game, often leading to unstable dynamics, non-convergence, or oscillations during training rather than a stable Nash equilibrium \cite{grnarova20171tc}. Understanding these inherent challenges is crucial for appreciating the subsequent research trajectory aimed at GAN stabilization.

One of the most debilitating problems was \textit{mode collapse}, a phenomenon where the generator fails to capture the full diversity of the real data distribution \cite{jabbar2020aj0}. Instead of producing a wide variety of realistic outputs, the generator converges to a limited subset of the data's "modes," repeatedly generating similar, often high-quality, samples that represent only a fraction of the true data variability. This severely limited the practical utility of GANs for tasks requiring diverse sample generation, such as image synthesis or data augmentation. Mode collapse often arises when the generator finds a specific set of outputs that consistently fool the discriminator, and then exploits this weakness, ceasing to explore other parts of the data distribution. Conversely, if the discriminator becomes too strong too quickly, it might reject all generated samples, providing no useful gradient signal for the generator to learn from, thus causing the generator to collapse to a single, easily produced output. Early research quickly identified mode collapse as a central impediment, prompting immediate efforts to understand and mitigate this issue by encouraging the generator to explore the full data space \cite{metz20169ir, che2016kho}. The theoretical understanding of this challenge was further deepened by works highlighting a provable trade-off between the Lipschitz constant of generative networks and their ability to fit multimodal distributions, directly linking stability constraints to the challenge of capturing diversity \cite{salmona202283g}.

Beyond mode collapse, GANs also suffered from profound \textit{training instability}, primarily characterized by vanishing or exploding gradients, which made it exceedingly difficult for the networks to learn effectively or converge \cite{jabbar2020aj0, wiatrak20194ib}. The original GAN formulation, based on minimizing the Jensen-Shannon (JS) divergence between the real and generated data distributions, proved problematic. When the generator's distribution was far from the real data distribution—a common scenario early in training, especially in high-dimensional spaces—the JS divergence would often saturate. This saturation meant that the discriminator could easily distinguish real from fake samples, becoming "perfect" or near-perfect. In such cases, the gradients backpropagated to the generator would become vanishingly small, providing little to no learning signal and effectively halting the generator's progress \cite{arjovsky2017ze5}. Conversely, in some scenarios, gradients could explode, leading to erratic updates and divergence.

The adversarial nature of the training further exacerbated these instabilities. The continuous competition between the generator and discriminator often prevented the system from settling into a stable equilibrium. Instead, the training process would frequently oscillate, with one network overpowering the other, leading to a cycle of collapse and recovery, or simply non-convergence \cite{chu2020zbv}. This dynamic was also influenced by the unbounded function space of the discriminator, which, without proper constraints, could become overly confident and provide unreliable gradients \cite{chao2021ynq}. The inherent difficulty in finding a stable Nash equilibrium in this non-convex, high-dimensional game meant that training was highly sensitive to hyperparameter choices and initialization, making GANs notoriously fragile and challenging to deploy consistently \cite{bang2018ps8}.

These fundamental issues—mode collapse, vanishing/exploding gradients, and general training instability—resulted in poor quality generated samples, unreliable convergence, and a significant barrier to the widespread adoption of GANs. The recognition of these critical flaws underscored the urgent need for robust stabilization techniques, which became the primary focus of subsequent research. This foundational understanding of GAN failures directly motivated the development of alternative objective functions, novel regularization strategies, and architectural innovations, which are explored in the following sections, to transform GANs into reliably trainable and effective generative models.