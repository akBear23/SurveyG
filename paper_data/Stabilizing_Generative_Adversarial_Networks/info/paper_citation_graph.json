{
  "nodes": [
    {
      "id": "acd87843a451d18b4dc6474ddce1ae946429eaf1",
      "title": "Wasserstein Generative Adversarial Networks",
      "abstract": "",
      "authors": [
        "Martín Arjovsky",
        "Soumith Chintala",
        "L. Bottou"
      ],
      "year": 2017,
      "citation_count": 8420,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/acd87843a451d18b4dc6474ddce1ae946429eaf1",
      "pdf_link": "",
      "venue": "International Conference on Machine Learning",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "744fe47157477235032f7bb3777800f9f2f45e52",
      "title": "Progressive Growing of GANs for Improved Quality, Stability, and Variation",
      "abstract": "We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CelebA images at 1024^2. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CelebA dataset.",
      "authors": [
        "Tero Karras",
        "Timo Aila",
        "S. Laine",
        "J. Lehtinen"
      ],
      "year": 2017,
      "citation_count": 7647,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/744fe47157477235032f7bb3777800f9f2f45e52",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "84de7d27e2f6160f634a483e8548c499a2cda7fa",
      "title": "Spectral Normalization for Generative Adversarial Networks",
      "abstract": "One of the challenges in the study of generative adversarial networks is the instability of its training. In this paper, we propose a novel weight normalization technique called spectral normalization to stabilize the training of the discriminator. Our new normalization technique is computationally light and easy to incorporate into existing implementations. We tested the efficacy of spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and we experimentally confirmed that spectrally normalized GANs (SN-GANs) is capable of generating images of better or equal quality relative to the previous training stabilization techniques.",
      "authors": [
        "Takeru Miyato",
        "Toshiki Kataoka",
        "Masanori Koyama",
        "Yuichi Yoshida"
      ],
      "year": 2018,
      "citation_count": 4552,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/84de7d27e2f6160f634a483e8548c499a2cda7fa",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "29858b40a15704398aecdca6bd2820f2fcc99891",
      "title": "Training Generative Adversarial Networks with Limited Data",
      "abstract": "Training generative adversarial networks (GAN) using too little data typically leads to discriminator overfitting, causing training to diverge. We propose an adaptive discriminator augmentation mechanism that significantly stabilizes training in limited data regimes. The approach does not require changes to loss functions or network architectures, and is applicable both when training from scratch and when fine-tuning an existing GAN on another dataset. We demonstrate, on several datasets, that good results are now possible using only a few thousand training images, often matching StyleGAN2 results with an order of magnitude fewer images. We expect this to open up new application domains for GANs. We also find that the widely used CIFAR-10 is, in fact, a limited data benchmark, and improve the record FID from 5.59 to 2.42.",
      "authors": [
        "Tero Karras",
        "M. Aittala",
        "Janne Hellsten",
        "S. Laine",
        "J. Lehtinen",
        "Timo Aila"
      ],
      "year": 2020,
      "citation_count": 1971,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/29858b40a15704398aecdca6bd2820f2fcc99891",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921",
      "title": "StackGAN: Text to Photo-Realistic Image Synthesis with Stacked Generative Adversarial Networks",
      "abstract": "Synthesizing high-quality images from text descriptions is a challenging problem in computer vision and has many practical applications. Samples generated by existing textto- image approaches can roughly reflect the meaning of the given descriptions, but they fail to contain necessary details and vivid object parts. In this paper, we propose Stacked Generative Adversarial Networks (StackGAN) to generate 256.256 photo-realistic images conditioned on text descriptions. We decompose the hard problem into more manageable sub-problems through a sketch-refinement process. The Stage-I GAN sketches the primitive shape and colors of the object based on the given text description, yielding Stage-I low-resolution images. The Stage-II GAN takes Stage-I results and text descriptions as inputs, and generates high-resolution images with photo-realistic details. It is able to rectify defects in Stage-I results and add compelling details with the refinement process. To improve the diversity of the synthesized images and stabilize the training of the conditional-GAN, we introduce a novel Conditioning Augmentation technique that encourages smoothness in the latent conditioning manifold. Extensive experiments and comparisons with state-of-the-arts on benchmark datasets demonstrate that the proposed method achieves significant improvements on generating photo-realistic images conditioned on text descriptions.",
      "authors": [
        "Han Zhang",
        "Tao Xu",
        "Hongsheng Li",
        "Shaoting Zhang",
        "Xiaogang Wang",
        "Xiaolei Huang",
        "Dimitris N. Metaxas"
      ],
      "year": 2016,
      "citation_count": 2776,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921",
      "pdf_link": "",
      "venue": "IEEE International Conference on Computer Vision",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "68cb9fce1e6af2740377494350b650533c9a29e1",
      "title": "Learning from Simulated and Unsupervised Images through Adversarial Training",
      "abstract": "With recent progress in graphics, it has become more tractable to train models on synthetic images, potentially avoiding the need for expensive annotations. However, learning from synthetic images may not achieve the desired performance due to a gap between synthetic and real image distributions. To reduce this gap, we propose Simulated+Unsupervised (S+U) learning, where the task is to learn a model to improve the realism of a simulators output using unlabeled real data, while preserving the annotation information from the simulator. We develop a method for S+U learning that uses an adversarial network similar to Generative Adversarial Networks (GANs), but with synthetic images as inputs instead of random vectors. We make several key modifications to the standard GAN algorithm to preserve annotations, avoid artifacts, and stabilize training: (i) a self-regularization term, (ii) a local adversarial loss, and (iii) updating the discriminator using a history of refined images. We show that this enables generation of highly realistic images, which we demonstrate both qualitatively and with a user study. We quantitatively evaluate the generated images by training models for gaze estimation and hand pose estimation. We show a significant improvement over using synthetic images, and achieve state-of-the-art results on the MPIIGaze dataset without any labeled real data.",
      "authors": [
        "A. Shrivastava",
        "Tomas Pfister",
        "Oncel Tuzel",
        "J. Susskind",
        "Wenda Wang",
        "Russ Webb"
      ],
      "year": 2016,
      "citation_count": 1821,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/68cb9fce1e6af2740377494350b650533c9a29e1",
      "pdf_link": "",
      "venue": "Computer Vision and Pattern Recognition",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "670f9d0d8cafaeaeea564c88645b9816b1146cef",
      "title": "Differentiable Augmentation for Data-Efficient GAN Training",
      "abstract": "The performance of generative adversarial networks (GANs) heavily deteriorates given a limited amount of training data. This is mainly because the discriminator is memorizing the exact training set. To combat it, we propose Differentiable Augmentation (DiffAugment), a simple method that improves the data efficiency of GANs by imposing various types of differentiable augmentations on both real and fake samples. Previous attempts to directly augment the training data manipulate the distribution of real images, yielding little benefit; DiffAugment enables us to adopt the differentiable augmentation for the generated samples, effectively stabilizes training, and leads to better convergence. Experiments demonstrate consistent gains of our method over a variety of GAN architectures and loss functions for both unconditional and class-conditional generation. With DiffAugment, we achieve a state-of-the-art FID of 6.80 with an IS of 100.8 on ImageNet 128x128. Furthermore, with only 20% training data, we can match the top performance on CIFAR-10 and CIFAR-100. Finally, our method can generate high-fidelity images using only 100 images without pre-training, while being on par with existing transfer learning algorithms. Code is available at this https URL.",
      "authors": [
        "Shengyu Zhao",
        "Zhijian Liu",
        "Ji Lin",
        "Jun-Yan Zhu",
        "Song Han"
      ],
      "year": 2020,
      "citation_count": 624,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/670f9d0d8cafaeaeea564c88645b9816b1146cef",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "title": "Unrolled Generative Adversarial Networks",
      "abstract": "We introduce a method to stabilize Generative Adversarial Networks (GANs) by defining the generator objective with respect to an unrolled optimization of the discriminator. This allows training to be adjusted between using the optimal discriminator in the generator's objective, which is ideal but infeasible in practice, and using the current value of the discriminator, which is often unstable and leads to poor solutions. We show how this technique solves the common problem of mode collapse, stabilizes training of GANs with complex recurrent generators, and increases diversity and coverage of the data distribution by the generator.",
      "authors": [
        "Luke Metz",
        "Ben Poole",
        "David Pfau",
        "Jascha Narain Sohl-Dickstein"
      ],
      "year": 2016,
      "citation_count": 1025,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/488bb25e0b1777847f04c943e6dbc4f84415b712",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "3bf2147008e0bcb5d80298448fc4bf7f5d3c30ea",
      "title": "Underwater Image Enhancement Using a Multiscale Dense Generative Adversarial Network",
      "abstract": "Underwater image enhancement has received much attention in underwater vision research. However, raw underwater images easily suffer from color distortion, underexposure, and fuzz caused by the underwater scene. To address the above-mentioned problems, we propose a new multiscale dense generative adversarial network (GAN) for enhancing underwater images. The residual multiscale dense block is presented in the generator, where the multiscale, dense concatenation, and residual learning can boost the performance, render more details, and utilize previous features, respectively. And the discriminator employs computationally light spectral normalization to stabilize the training of the discriminator. Meanwhile, nonsaturating GAN loss function combining $L_1$ loss and gradient loss is presented to focus on image features of ground truth. Final enhanced results on synthetic and real underwater images demonstrate the superiority of the proposed method, which outperforms nondeep and deep learning methods in both qualitative and quantitative evaluations. Furthermore, we perform an ablation study to show the contributions of each component and carry out application tests to further demonstrate the effectiveness of the proposed method.",
      "authors": [
        "Ye-cai Guo",
        "Hanyu Li",
        "Peixian Zhuang"
      ],
      "year": 2020,
      "citation_count": 368,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/3bf2147008e0bcb5d80298448fc4bf7f5d3c30ea",
      "pdf_link": "",
      "venue": "IEEE Journal of Oceanic Engineering",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "df7ad8eeb595da5f7774e91dae06075be952acff",
      "title": "GAN Dissection: Visualizing and Understanding Generative Adversarial Networks",
      "abstract": "",
      "authors": [
        "David Bau",
        "Jun-Yan Zhu",
        "Hendrik Strobelt",
        "Bolei Zhou",
        "J. Tenenbaum",
        "W. Freeman",
        "A. Torralba"
      ],
      "year": 2018,
      "citation_count": 480,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/df7ad8eeb595da5f7774e91dae06075be952acff",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "024d30897e0a2b036bc122163a954b7f1a1d0679",
      "title": "Mode Regularized Generative Adversarial Networks",
      "abstract": "Although Generative Adversarial Networks achieve state-of-the-art results on a variety of generative tasks, they are regarded as highly unstable and prone to miss modes. We argue that these bad behaviors of GANs are due to the very particular functional shape of the trained discriminators in high dimensional spaces, which can easily make training stuck or push probability mass in the wrong direction, towards that of higher concentration than that of the data generating distribution. We introduce several ways of regularizing the objective, which can dramatically stabilize the training of GAN models. We also show that our regularizers can help the fair distribution of probability mass across the modes of the data generating distribution, during the early phases of training and thus providing a unified solution to the missing modes problem.",
      "authors": [
        "Tong Che",
        "Yanran Li",
        "Athul Paul Jacob",
        "Yoshua Bengio",
        "Wenjie Li"
      ],
      "year": 2016,
      "citation_count": 566,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/024d30897e0a2b036bc122163a954b7f1a1d0679",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "6c4fe31504d47b8547e47267c0cb4efa464f022b",
      "title": "Towards Faster and Stabilized GAN Training for High-fidelity Few-shot Image Synthesis",
      "abstract": "Training Generative Adversarial Networks (GAN) on high-fidelity images usually requires large-scale GPU-clusters and a vast number of training images. In this paper, we study the few-shot image synthesis task for GAN with minimum computing cost. We propose a light-weight GAN structure that gains superior quality on 1024*1024 resolution. Notably, the model converges from scratch with just a few hours of training on a single RTX-2080 GPU, and has a consistent performance, even with less than 100 training samples. Two technique designs constitute our work, a skip-layer channel-wise excitation module and a self-supervised discriminator trained as a feature-encoder. With thirteen datasets covering a wide variety of image domains (The datasets and code are available at: https://github.com/odegeasslbc/FastGAN-pytorch), we show our model's superior performance compared to the state-of-the-art StyleGAN2, when data and computing budget are limited.",
      "authors": [
        "Bingchen Liu",
        "Yizhe Zhu",
        "Kunpeng Song",
        "A. Elgammal"
      ],
      "year": 2021,
      "citation_count": 250,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/6c4fe31504d47b8547e47267c0cb4efa464f022b",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "d54d8c402785006faaf5de19e81f04eb484a3aa2",
      "title": "A Survey on Generative Adversarial Networks: Variants, Applications, and Training",
      "abstract": "The Generative Models have gained considerable attention in unsupervised learning via a new and practical framework called Generative Adversarial Networks (GAN) due to their outstanding data generation capability. Many GAN models have been proposed, and several practical applications have emerged in various domains of computer vision and machine learning. Despite GANs excellent success, there are still obstacles to stable training. The problems are Nash equilibrium, internal covariate shift, mode collapse, vanishing gradient, and lack of proper evaluation metrics. Therefore, stable training is a crucial issue in different applications for the success of GANs. Herein, we survey several training solutions proposed by different researchers to stabilize GAN training. We discuss (I) the original GAN model and its modified versions, (II) a detailed analysis of various GAN applications in different domains, and (III) a detailed study about the various GAN training obstacles as well as training solutions. Finally, we reveal several issues as well as research outlines to the topic.",
      "authors": [
        "Abdul Jabbar",
        "Xi Li",
        "Bourahla Omar"
      ],
      "year": 2020,
      "citation_count": 295,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/d54d8c402785006faaf5de19e81f04eb484a3aa2",
      "pdf_link": "",
      "venue": "ACM Computing Surveys",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "698d3b667a7f3073eed8368d9daf84f990c24a65",
      "title": "Stabilizing Training of Generative Adversarial Networks through Regularization",
      "abstract": "Deep generative models based on Generative Adversarial Networks (GANs) have demonstrated impressive sample quality but in order to work they require a careful choice of architecture, parameter initialization, and selection of hyper-parameters. This fragility is in part due to a dimensional mismatch or non-overlapping support between the model distribution and the data distribution, causing their density ratio and the associated f -divergence to be undefined. We overcome this fundamental limitation and propose a new regularization approach with low computational cost that yields a stable GAN training procedure. We demonstrate the effectiveness of this regularizer accross several architectures trained on common benchmark image generation tasks. Our regularization turns GAN models into reliable building blocks for deep learning.",
      "authors": [
        "Kevin Roth",
        "Aurélien Lucchi",
        "Sebastian Nowozin",
        "Thomas Hofmann"
      ],
      "year": 2017,
      "citation_count": 453,
      "layer": 1,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/698d3b667a7f3073eed8368d9daf84f990c24a65",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "8b1ba1037aefddec9ce9d07858f661b72a1b41fe",
      "title": "Physics-Informed Generative Adversarial Networks for Stochastic Differential Equations",
      "abstract": "We developed a new class of physics-informed generative adversarial networks (PI-GANs) to solve in a unified manner forward, inverse and mixed stochastic problems based on a limited number of scattered measurements. Unlike standard GANs relying only on data for training, here we encoded into the architecture of GANs the governing physical laws in the form of stochastic differential equations (SDEs) using automatic differentiation. In particular, we applied Wasserstein GANs with gradient penalty (WGAN-GP) for its enhanced stability compared to vanilla GANs. We first tested WGAN-GP in approximating Gaussian processes of different correlation lengths based on data realizations collected from simultaneous reads at sparsely placed sensors. We obtained good approximation of the generated stochastic processes to the target ones even for a mismatch between the input noise dimensionality and the effective dimensionality of the target stochastic processes. We also studied the overfitting issue for both the discriminator and generator, and we found that overfitting occurs also in the generator in addition to the discriminator as previously reported. Subsequently, we considered the solution of elliptic SDEs requiring approximations of three stochastic processes, namely the solution, the forcing, and the diffusion coefficient. We used three generators for the PI-GANs, two of them were feed forward deep neural networks (DNNs) while the other one was the neural network induced by the SDE. Depending on the data, we employed one or multiple feed forward DNNs as the discriminators in PI-GANs. Here, we have demonstrated the accuracy and effectiveness of PI-GANs in solving SDEs for up to 30 dimensions, but in principle, PI-GANs could tackle very high dimensional problems given more sensor data with low-polynomial growth in computational cost.",
      "authors": [
        "Liu Yang",
        "Dongkun Zhang",
        "G. Karniadakis"
      ],
      "year": 2018,
      "citation_count": 390,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/8b1ba1037aefddec9ce9d07858f661b72a1b41fe",
      "pdf_link": "",
      "venue": "SIAM Journal on Scientific Computing",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "63470afe06145e08c3b851491450f68c83cc938f",
      "title": "Consistency Regularization for Generative Adversarial Networks",
      "abstract": "Generative Adversarial Networks (GANs) are known to be difficult to train, despite considerable research effort. Several regularization techniques for stabilizing training have been proposed, but they introduce non-trivial computational overheads and interact poorly with existing techniques like spectral normalization. In this work, we propose a simple, effective training stabilizer based on the notion of consistency regularization---a popular technique in the semi-supervised learning literature. In particular, we augment data passing into the GAN discriminator and penalize the sensitivity of the discriminator to these augmentations. We conduct a series of experiments to demonstrate that consistency regularization works effectively with spectral normalization and various GAN architectures, loss functions and optimizer settings. Our method achieves the best FID scores for unconditional image generation compared to other regularization methods on CIFAR-10 and CelebA. Moreover, Our consistency regularized GAN (CR-GAN) improves state-of-the-art FID scores for conditional generation from 14.73 to 11.48 on CIFAR-10 and from 8.73 to 6.66 on ImageNet-2012.",
      "authors": [
        "Han Zhang",
        "Zizhao Zhang",
        "Augustus Odena",
        "Honglak Lee"
      ],
      "year": 2019,
      "citation_count": 287,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/63470afe06145e08c3b851491450f68c83cc938f",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "cb2bd9549791520deccadfde221f8ca699675a96",
      "title": "Regularizing Generative Adversarial Networks under Limited Data",
      "abstract": "Recent years have witnessed the rapid progress of generative adversarial networks (GANs). However, the success of the GAN models hinges on a large amount of training data. This work proposes a regularization approach for training robust GAN models on limited data. We theoretically show a connection between the regularized loss and an f-divergence called LeCam-divergence, which we find is more robust under limited training data. Extensive experiments on several benchmark datasets demonstrate that the proposed regularization scheme 1) improves the generalization performance and stabilizes the learning dynamics of GAN models under limited training data, and 2) complements the recent data augmentation methods. These properties facilitate training GAN models to achieve state-of-theart performance when only limited training data of the ImageNet benchmark is available. The source code is available at https://github.com/google/lecam-gan.",
      "authors": [
        "Hung-Yu Tseng",
        "Lu Jiang",
        "Ce Liu",
        "Ming-Hsuan Yang",
        "Weilong Yang"
      ],
      "year": 2021,
      "citation_count": 150,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/cb2bd9549791520deccadfde221f8ca699675a96",
      "pdf_link": "",
      "venue": "Computer Vision and Pattern Recognition",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "3228c8073f6aae9c287dbeea949fbad68f9d5ba1",
      "title": "Imbalanced Fault Diagnosis of Rolling Bearing Based on Generative Adversarial Network: A Comparative Study",
      "abstract": "Due to the real working conditions and data acquisition equipment, the collected working data of bearings are actually limited. Meanwhile, as the rolling bearing works in the normal state at most times, it is easy to raise the imbalance problem of fault types which restricts the diagnosis accuracy and stability. To solve these problems, we present an imbalanced fault diagnosis method based on the generative adversarial network (GAN) and provide a comparative study in detail. The key idea is utilizing GAN, a kind of deep learning technique, to generate synthetic samples for minority fault class and then improve the generalization ability of the fault diagnosis model. First, this method applies fast Fourier transform to pre-process the original vibration signal and then obtains the frequency spectrum of fault samples. Second, it uses the spectrum data as the input of GAN to generate the synthetic minority samples following the data distribution of the real samples. Finally, it puts the synthetic samples into the training set and builds a stacked denoising auto encoder model for fault diagnosis. To testify the effectiveness of the proposed method, a series of comparative experiments is carried out on the CWRU bearing dataset. The results show that the proposed method can provide a better solution for imbalanced fault diagnosis on the basis of generating similar fault samples. As a comparative study, the proposed method is compared to several diagnostic methods with traditional time-frequency domain characteristics. Moreover, we also demonstrate that the proposed method outperforms three widely used sample synthesis techniques, such as random oversampling, synthetic minority oversampling technique, and the principal curve-based oversampling method in terms of diagnosis accuracy and numerical stability.",
      "authors": [
        "Wentao Mao",
        "Yamin Liu",
        "Ling Ding",
        "Yuan Li"
      ],
      "year": 2019,
      "citation_count": 210,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/3228c8073f6aae9c287dbeea949fbad68f9d5ba1",
      "pdf_link": "",
      "venue": "IEEE Access",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "27e13389203b2f8f6138afed867965a3a38cbd8e",
      "title": "EEG-GAN: Generative adversarial networks for electroencephalograhic (EEG) brain signals",
      "abstract": "Generative adversarial networks (GANs) are recently highly successful in generative applications involving images and start being applied to time series data. Here we describe EEG-GAN as a framework to generate electroencephalographic (EEG) brain signals. We introduce a modification to the improved training of Wasserstein GANs to stabilize training and investigate a range of architectural choices critical for time series generation (most notably up- and down-sampling). For evaluation we consider and compare different metrics such as Inception score, Frechet inception distance and sliced Wasserstein distance, together showing that our EEG-GAN framework generated naturalistic EEG examples. It thus opens up a range of new generative application scenarios in the neuroscientific and neurological context, such as data augmentation in brain-computer interfacing tasks, EEG super-sampling, or restoration of corrupted data segments. The possibility to generate signals of a certain class and/or with specific properties may also open a new avenue for research into the underlying structure of brain signals.",
      "authors": [
        "K. Hartmann",
        "R. Schirrmeister",
        "T. Ball"
      ],
      "year": 2018,
      "citation_count": 242,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/27e13389203b2f8f6138afed867965a3a38cbd8e",
      "pdf_link": "",
      "venue": "arXiv.org",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "cd682f085af85526631dc33617ac4aaae7309634",
      "title": "Generative Adversarial Networks in Computer Vision",
      "abstract": "Generative adversarial networks (GANs) have been extensively studied in the past few years. Arguably their most significant impact has been in the area of computer vision where great advances have been made in challenges such as plausible image generation, image-to-image translation, facial attribute manipulation, and similar domains. Despite the significant successes achieved to date, applying GANs to real-world problems still poses significant challenges, three of which we focus on here. These are as follows: (1) the generation of high quality images, (2) diversity of image generation, and (3) stabilizing training. Focusing on the degree to which popular GAN technologies have made progress against these challenges, we provide a detailed review of the state-of-the-art in GAN-related research in the published scientific literature. We further structure this review through a convenient taxonomy we have adopted based on variations in GAN architectures and loss functions. While several reviews for GANs have been presented to date, none have considered the status of this field based on their progress toward addressing practical challenges relevant to computer vision. Accordingly, we review and critically discuss the most popular architecture-variant, and loss-variant GANs, for tackling these challenges. Our objective is to provide an overview as well as a critical analysis of the status of GAN research in terms of relevant progress toward critical computer vision application requirements. As we do this we also discuss the most compelling applications in computer vision in which GANs have demonstrated considerable success along with some suggestions for future research directions. Codes related to the GAN-variants studied in this work is summarized on https://github.com/sheqi/GAN_Review.",
      "authors": [
        "Zhengwei Wang",
        "Qi She",
        "T. Ward"
      ],
      "year": 2019,
      "citation_count": 206,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/cd682f085af85526631dc33617ac4aaae7309634",
      "pdf_link": "",
      "venue": "ACM Computing Surveys",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "1076a77834f11810fdcd100b21d90ca7bc1f9095",
      "title": "A case study of conditional deep convolutional generative adversarial networks in machine fault diagnosis",
      "abstract": "",
      "authors": [
        "Jia Luo",
        "Jinying Huang",
        "Hongmei Li"
      ],
      "year": 2020,
      "citation_count": 165,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/1076a77834f11810fdcd100b21d90ca7bc1f9095",
      "pdf_link": "",
      "venue": "Journal of Intelligent Manufacturing",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "237729237fde44eb7ab8f35aafb82c9b8a816e44",
      "title": "Generative Adversarial Networks for Image and Video Synthesis: Algorithms and Applications",
      "abstract": "The generative adversarial network (GAN) framework has emerged as a powerful tool for various image and video synthesis tasks, allowing the synthesis of visual content in an unconditional or input-conditional manner. It has enabled the generation of high-resolution photorealistic images and videos, a task that was challenging or impossible with prior methods. It has also led to the creation of many new applications in content creation. In this article, we provide an overview of GANs with a special focus on algorithms and applications for visual synthesis. We cover several important techniques to stabilize GAN training, which has a reputation for being notoriously difficult. We also discuss its applications to image translation, image processing, video synthesis, and neural rendering.",
      "authors": [
        "Ming-Yu Liu",
        "Xun Huang",
        "Jiahui Yu",
        "Ting-Chun Wang",
        "Arun Mallya"
      ],
      "year": 2020,
      "citation_count": 162,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/237729237fde44eb7ab8f35aafb82c9b8a816e44",
      "pdf_link": "",
      "venue": "Proceedings of the IEEE",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "2f12a10172f33523b288269e59211261ca2f6f67",
      "title": "Interaction Matters: A Note on Non-asymptotic Local Convergence of Generative Adversarial Networks",
      "abstract": "Motivated by the pursuit of a systematic computational and algorithmic understanding of Generative Adversarial Networks (GANs), we present a simple yet unified non-asymptotic local convergence theory for smooth two-player games, which subsumes several discrete-time gradient-based saddle point dynamics. The analysis reveals the surprising nature of the off-diagonal interaction term as both a blessing and a curse. On the one hand, this interaction term explains the origin of the slow-down effect in the convergence of Simultaneous Gradient Ascent (SGA) to stable Nash equilibria. On the other hand, for the unstable equilibria, exponential convergence can be proved thanks to the interaction term, for three modified dynamics which have been proposed to stabilize GAN training: Optimistic Mirror Descent (OMD), Consensus Optimization (CO) and Predictive Method (PM). The analysis uncovers the intimate connections among these stabilizing techniques, and provides detailed characterization on the choice of learning rate.",
      "authors": [
        "Tengyuan Liang",
        "J. Stokes"
      ],
      "year": 2018,
      "citation_count": 219,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/2f12a10172f33523b288269e59211261ca2f6f67",
      "pdf_link": "",
      "venue": "International Conference on Artificial Intelligence and Statistics",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "29a23cd054d7a8202e6cdc60a53321bbc6e1aefd",
      "title": "FuseGAN: Learning to Fuse Multi-Focus Image via Conditional Generative Adversarial Network",
      "abstract": "We study the problem of multi-focus image fusion, where the key challenge is detecting the focused regions accurately among multiple partially focused source images. Inspired by the conditional generative adversarial network (cGAN) to image-to-image task, we propose a novel FuseGAN to fulfill the images-to-image for multi-focus image fusion. To satisfy the requirement of dual input-to-one output, the encoder of the generator in FuseGAN is designed as a Siamese network. The least square GAN objective is employed to enhance the training stability of FuseGAN, resulting in an accurate confidence map for focus region detection. Also, we exploit the convolutional conditional random fields technique on the confidence map to reach a refined final decision map for better focus region detection. Moreover, due to the lack of a large-scale standard dataset, we synthesize a large enough multi-focus image dataset based on a public natural image dataset PASCAL VOC 2012, where we utilize a normalized disk point spread function to simulate the defocus and separate the background and foreground in the synthesis for each image. We conduct extensive experiments on two public datasets to verify the effectiveness of the proposed method. Results demonstrate that the proposed method presents accurate decision maps for focus regions in multi-focus images, such that the fused images are superior to 11 recent state-of-the-art algorithms, not only in visual perception, but also in quantitative analysis in terms of five metrics.",
      "authors": [
        "Xiaopeng Guo",
        "Rencan Nie",
        "Jinde Cao",
        "Dongming Zhou",
        "Liye Mei",
        "Kangjian He"
      ],
      "year": 2019,
      "citation_count": 162,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/29a23cd054d7a8202e6cdc60a53321bbc6e1aefd",
      "pdf_link": "",
      "venue": "IEEE transactions on multimedia",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "0b98a1efa7bef2acb2091d5b1659430ef4df1364",
      "title": "A Data Augmentation Method Based on Generative Adversarial Networks for Grape Leaf Disease Identification",
      "abstract": "The identification of grape leaf diseases based on deep learning is critical to controlling the spread of diseases and ensuring the healthy development of the grape industry. Focusing on the lack of training images of grape leaf diseases, this paper proposes a novel model named Leaf GAN, which is based on generative adversarial networks (GANs), to generate images of four different grape leaf diseases for training identification models. A generator model with degressive channels is first designed to generate grape leaf disease images; then, the dense connectivity strategy and instance normalization are fused into an efficient discriminator to identify real and fake disease images by utilizing their excellent feature extraction capability on grape leaf lesions. Finally, the deep regret gradient penalty method is applied to stabilize the training process of the model. Using a total of 4,062 grape leaf disease images, the Leaf GAN model ultimately generates 8,124 grape leaf disease images. The generated grape leaf disease images based on Leaf GAN model can obtain better performance than DCGAN and WGAN in terms of the Fréchet inception distance. The experimental results show that the proposed Leaf GAN model generates sufficient grape leaf disease images with prominent lesions, providing a feasible solution for the data augmentation of grape leaf disease images. For the eight prevailing classification models with the expanded dataset, the identification performance based on CNNs indicated higher accuracies, whereby all the accuracies were better than those of the initial dataset with other data augmentation methods. Among them, Xception achieves a recognition accuracy of 98.70% on the testing set. The results demonstrate that the proposed data augmentation method represents a new approach to overcoming the overfitting problem in disease identification and can effectively improve the identification accuracy.",
      "authors": [
        "B. Liu",
        "Cheng Tan",
        "Shuqin Li",
        "Jinrong He",
        "Hongyan Wang"
      ],
      "year": 2020,
      "citation_count": 130,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/0b98a1efa7bef2acb2091d5b1659430ef4df1364",
      "pdf_link": "",
      "venue": "IEEE Access",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "042116e805aa3b5171efaf0c822dc142310ceefe",
      "title": "Boundary-Seeking Generative Adversarial Networks",
      "abstract": "Generative adversarial networks (GANs) are a learning framework that rely on training a discriminator to estimate a measure of difference between a target and generated distributions. GANs, as normally formulated, rely on the generated samples being completely differentiable w.r.t. the generative parameters, and thus do not work for discrete data. We introduce a method for training GANs with discrete data that uses the estimated difference measure from the discriminator to compute importance weights for generated samples, thus providing a policy gradient for training the generator. The importance weights have a strong connection to the decision boundary of the discriminator, and we call our method boundary-seeking GANs (BGANs). We demonstrate the effectiveness of the proposed algorithm with discrete image and character-based natural language generation. In addition, the boundary-seeking objective extends to continuous data, which can be used to improve stability of training.",
      "authors": [
        "R. Devon Hjelm",
        "Athul Paul Jacob",
        "Tong Che",
        "Kyunghyun Cho",
        "Yoshua Bengio"
      ],
      "year": 2017,
      "citation_count": 172,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/042116e805aa3b5171efaf0c822dc142310ceefe",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "82f766d3c572b4c690b439edab5d32b3ba72852e",
      "title": "G-IDS: Generative Adversarial Networks Assisted Intrusion Detection System",
      "abstract": "The boundaries of cyber-physical systems (CPS) and the Internet of Things (IoT) are converging together day by day to introduce a common platform on hybrid systems. Moreover, the combination of artificial intelligence (AI) with CPS creates a new dimension of technological advancement. All these connectivity and dependability are creating massive space for the attackers to launch cyber attacks. To defend against these attacks, intrusion detection system (IDS) has been widely used. However, emerging CPS fields suffer from imbalanced and missing sample data, which makes the training of IDS difficult. In this paper, we propose a generative adversarial network (GAN) based intrusion detection system (G-IDS), where GAN generates synthetic samples, and IDS gets trained on them along with the original ones. G-IDS also fixes the difficulties of imbalanced or missing data problems. We model a network security dataset for an emerging CPS using NSL KDD-99 dataset and evaluate our proposed model's performance using different metrics. We find that our proposed G-IDS model performs much better in attack detection and model stabilization during the training process than a standalone IDS.",
      "authors": [
        "Md Hasan Shahriar",
        "Nur Imtiazul Haque",
        "M. Rahman",
        "M. Alonso"
      ],
      "year": 2020,
      "citation_count": 105,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/82f766d3c572b4c690b439edab5d32b3ba72852e",
      "pdf_link": "",
      "venue": "Annual International Computer Software and Applications Conference",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "29b8b97d554f5139fcf2064ce292204500eee31c",
      "title": "Connecting Generative Adversarial Networks and Actor-Critic Methods",
      "abstract": "Both generative adversarial networks (GAN) in unsupervised learning and actor-critic methods in reinforcement learning (RL) have gained a reputation for being difficult to optimize. Practitioners in both fields have amassed a large number of strategies to mitigate these instabilities and improve training. Here we show that GANs can be viewed as actor-critic methods in an environment where the actor cannot affect the reward. We review the strategies for stabilizing training for each class of models, both those that generalize between the two and those that are particular to that model. We also review a number of extensions to GANs and RL algorithms with even more complicated information flow. We hope that by highlighting this formal connection we will encourage both GAN and RL communities to develop general, scalable, and stable algorithms for multilevel optimization with deep networks, and to draw inspiration across communities.",
      "authors": [
        "David Pfau",
        "O. Vinyals"
      ],
      "year": 2016,
      "citation_count": 187,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/29b8b97d554f5139fcf2064ce292204500eee31c",
      "pdf_link": "",
      "venue": "arXiv.org",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "a4d0c0ca6445af0dc2e513c2e3ec5b852a0b5afa",
      "title": "On the Effectiveness of Least Squares Generative Adversarial Networks",
      "abstract": "Unsupervised learning with generative adversarial networks (GANs) has proven to be hugely successful. Regular GANs hypothesize the discriminator as a classifier with the sigmoid cross entropy loss function. However, we found that this loss function may lead to the vanishing gradients problem during the learning process. To overcome such a problem, we propose in this paper the Least Squares Generative Adversarial Networks (LSGANs) which adopt the least squares loss for both the discriminator and the generator. We show that minimizing the objective function of LSGAN yields minimizing the Pearson <inline-formula><tex-math notation=\"LaTeX\">$\\chi ^2$</tex-math><alternatives><mml:math><mml:msup><mml:mi>χ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href=\"mao-ieq1-2872043.gif\"/></alternatives></inline-formula> divergence. We also show that the derived objective function that yields minimizing the Pearson <inline-formula><tex-math notation=\"LaTeX\">$\\chi ^2$</tex-math><alternatives><mml:math><mml:msup><mml:mi>χ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math><inline-graphic xlink:href=\"mao-ieq2-2872043.gif\"/></alternatives></inline-formula> divergence performs better than the classical one of using least squares for classification. There are two benefits of LSGANs over regular GANs. First, LSGANs are able to generate higher quality images than regular GANs. Second, LSGANs perform more stably during the learning process. For evaluating the image quality, we conduct both qualitative and quantitative experiments, and the experimental results show that LSGANs can generate higher quality images than regular GANs. Furthermore, we evaluate the stability of LSGANs in two groups. One is to compare between LSGANs and regular GANs without gradient penalty. We conduct three experiments, including Gaussian mixture distribution, difficult architectures, and a newly proposed method — datasets with small variability, to illustrate the stability of LSGANs. The other one is to compare between LSGANs with gradient penalty (LSGANs-GP) and WGANs with gradient penalty (WGANs-GP). The experimental results show that LSGANs-GP succeed in training for all the difficult architectures used in WGANs-GP, including 101-layer ResNet.",
      "authors": [
        "Xudong Mao",
        "Qing Li",
        "Haoran Xie",
        "Raymond Y. K. Lau",
        "Zhen Wang",
        "Stephen Paul Smolley"
      ],
      "year": 2017,
      "citation_count": 162,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/a4d0c0ca6445af0dc2e513c2e3ec5b852a0b5afa",
      "pdf_link": "",
      "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "567a5d09647f787a37ce8ac300a221d8c4337688",
      "title": "Generating Energy Data for Machine Learning with Recurrent Generative Adversarial Networks",
      "abstract": "The smart grid employs computing and communication technologies to embed intelligence into the power grid and, consequently, make the grid more efficient. Machine learning (ML) has been applied for tasks that are important for smart grid operation including energy consumption and generation forecasting, anomaly detection, and state estimation. These ML solutions commonly require sufficient historical data; however, this data is often not readily available because of reasons such as data collection costs and concerns regarding security and privacy. This paper introduces a recurrent generative adversarial network (R-GAN) for generating realistic energy consumption data by learning from real data. Generativea adversarial networks (GANs) have been mostly used for image tasks (e.g., image generation, super-resolution), but here they are used with time series data. Convolutional neural networks (CNNs) from image GANs are replaced with recurrent neural networks (RNNs) because of RNN’s ability to capture temporal dependencies. To improve training stability and increase quality of generated data, Wasserstein GANs (WGANs) and Metropolis-Hastings GAN (MH-GAN) approaches were applied. The accuracy is further improved by adding features created with ARIMA and Fourier transform. Experiments demonstrate that data generated by R-GAN can be used for training energy forecasting models.",
      "authors": [
        "Mohammad Navid Fekri",
        "A. M. Ghosh",
        "Katarina Grolinger"
      ],
      "year": 2019,
      "citation_count": 119,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/567a5d09647f787a37ce8ac300a221d8c4337688",
      "pdf_link": "",
      "venue": "Energies",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "02c6dbdd1d492726f1fd70a9211f668a794e6975",
      "title": "Sergan: Speech Enhancement Using Relativistic Generative Adversarial Networks with Gradient Penalty",
      "abstract": "Popular neural network-based speech enhancement systems operate on the magnitude spectrogram and ignore the phase mismatch between the noisy and clean speech signals. Recently, conditional generative adversarial networks (cGANs) have shown promise in addressing the phase mismatch problem by directly mapping the raw noisy speech waveform to the underlying clean speech signal. However, stabilizing and training cGAN systems is difficult and they still fall short of the performance achieved by spectral enhancement approaches. This paper introduces relativistic GANs with a relativistic cost function at its discriminator and gradient penalty to improve time-domain speech enhancement. Simulation results show that relativistic discriminators provide a more stable training of cGANs and yield a better generator network for improved speech enhancement performance.",
      "authors": [
        "Deepak Baby",
        "S. Verhulst"
      ],
      "year": 2019,
      "citation_count": 109,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/02c6dbdd1d492726f1fd70a9211f668a794e6975",
      "pdf_link": "",
      "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "13fd8d61a6ea97c70f5154a23611c80203527818",
      "title": "Stabilizing Generative Adversarial Networks: A Survey",
      "abstract": "Generative Adversarial Networks (GANs) are a type of generative model which have received much attention due to their ability to model complex real-world data. Despite their recent successes, the process of training GANs remains challenging, suffering from instability problems such as non-convergence, vanishing or exploding gradients, and mode collapse. In recent years, a diverse set of approaches have been proposed which focus on stabilizing the GAN training procedure. The purpose of this survey is to provide a comprehensive overview of the GAN training stabilization methods which can be found in the literature. We discuss the advantages and disadvantages of each approach, offer a comparative summary, and conclude with a discussion of open problems.",
      "authors": [
        "Maciej Wiatrak",
        "Stefano V. Albrecht",
        "A. Nystrom"
      ],
      "year": 2019,
      "citation_count": 93,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/13fd8d61a6ea97c70f5154a23611c80203527818",
      "pdf_link": "",
      "venue": "",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "1e3194bf2bdc22a5d1750579a3d2553b61aa4045",
      "title": "Can Push-forward Generative Models Fit Multimodal Distributions?",
      "abstract": "Many generative models synthesize data by transforming a standard Gaussian random variable using a deterministic neural network. Among these models are the Variational Autoencoders and the Generative Adversarial Networks. In this work, we call them\"push-forward\"models and study their expressivity. We show that the Lipschitz constant of these generative networks has to be large in order to fit multimodal distributions. More precisely, we show that the total variation distance and the Kullback-Leibler divergence between the generated and the data distribution are bounded from below by a constant depending on the mode separation and the Lipschitz constant. Since constraining the Lipschitz constants of neural networks is a common way to stabilize generative models, there is a provable trade-off between the ability of push-forward models to approximate multimodal distributions and the stability of their training. We validate our findings on one-dimensional and image datasets and empirically show that generative models consisting of stacked networks with stochastic input at each step, such as diffusion models do not suffer of such limitations.",
      "authors": [
        "Antoine Salmona",
        "Valentin De Bortoli",
        "J. Delon",
        "A. Desolneux"
      ],
      "year": 2022,
      "citation_count": 42,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/1e3194bf2bdc22a5d1750579a3d2553b61aa4045",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "e32e9735b387080492cbf08f85c5e93fcef95b3a",
      "title": "InfoMax-GAN: Improved Adversarial Image Generation via Information Maximization and Contrastive Learning",
      "abstract": "While Geerative Adversarial Networks (GANs) are fundamental to many generative modelling applications, they suffer from numerous issues. In this work, we propose a principled framework to simultaneously mitigate two fundamental issues in GANs: catastrophic forgetting of the discriminator and mode collapse of the generator. We achieve this by employing for GANs a contrastive learning and mutual information maximization approach, and perform extensive analyses to understand sources of improvements. Our approach significantly stabilizes GAN training and improves GAN performance for image synthesis across five datasets under the same training and evaluation conditions against state-of-the-art works. In particular, compared to the state-of-the-art SSGAN, our approach does not suffer from poorer performance on image domains such as faces, and instead improves performance significantly. Our approach is simple to implement and practical: it involves only one auxiliary objective, has low computational cost, and performs robustly across a wide range of training settings and datasets without any hyperparameter tuning. For reproducibility, our code is available in the open-source GAN library, Mimicry [34].",
      "authors": [
        "Kwot Sin Lee",
        "Ngoc-Trung Tran",
        "Ngai-Man Cheung"
      ],
      "year": 2020,
      "citation_count": 69,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/e32e9735b387080492cbf08f85c5e93fcef95b3a",
      "pdf_link": "",
      "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "0d2818f1070fa5a6cf5d14a87a5d71b4107b4d60",
      "title": "Anomaly detection with variational quantum generative adversarial networks",
      "abstract": "Generative adversarial networks (GANs) are a machine learning framework comprising a generative model for sampling from a target distribution and a discriminative model for evaluating the proximity of a sample to the target distribution. GANs exhibit strong performance in imaging or anomaly detection. However, they suffer from training instabilities, and sampling efficiency may be limited by the classical sampling procedure. We introduce variational quantum–classical Wasserstein GANs (WGANs) to address these issues and embed this model in a classical machine learning framework for anomaly detection. Classical WGANs improve training stability by using a cost function better suited for gradient descent. Our model replaces the generator of WGANs with a hybrid quantum–classical neural net and leaves the classical discriminative model unchanged. This way, high-dimensional classical data only enters the classical model and need not be prepared in a quantum circuit. We demonstrate the effectiveness of this method on a credit card fraud dataset. For this dataset our method shows performance on par with classical methods in terms of the F 1 score. We analyze the influence of the circuit ansatz, layer width and depth, neural net architecture parameter initialization strategy, and sampling noise on convergence and performance.",
      "authors": [
        "Daniel Herr",
        "B. Obert",
        "Matthias Rosenkranz"
      ],
      "year": 2020,
      "citation_count": 66,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/0d2818f1070fa5a6cf5d14a87a5d71b4107b4d60",
      "pdf_link": "",
      "venue": "Quantum Science and Technology",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "cc34aea01322a8fb289e3d4486aad0f6641b472e",
      "title": "RDA-UNET-WGAN: An Accurate Breast Ultrasound Lesion Segmentation Using Wasserstein Generative Adversarial Networks",
      "abstract": "",
      "authors": [
        "Anuja Negi",
        "A. Noel",
        "Joseph Raj",
        "Ruban Nersisson",
        "Zhemin Zhuang",
        "·. M. Murugappan"
      ],
      "year": 2020,
      "citation_count": 64,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/cc34aea01322a8fb289e3d4486aad0f6641b472e",
      "pdf_link": "",
      "venue": "The Arabian journal for science and engineering",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "245f8b05bdd1ac65a09a476440dc4b05ac05d4a0",
      "title": "An Online Learning Approach to Generative Adversarial Networks",
      "abstract": "We consider the problem of training generative models with a Generative Adversarial Network (GAN). Although GANs can accurately model complex distributions, they are known to be difficult to train due to instabilities caused by a difficult minimax optimization problem. In this paper, we view the problem of training GANs as finding a mixed strategy in a zero-sum game. Building on ideas from online learning we propose a novel training method named Chekhov GAN 1 . On the theory side, we show that our method provably converges to an equilibrium for semi-shallow GAN architectures, i.e. architectures where the discriminator is a one layer network and the generator is arbitrary. On the practical side, we develop an efficient heuristic guided by our theoretical results, which we apply to commonly used deep GAN architectures. On several real world tasks our approach exhibits improved stability and performance compared to standard GAN training.",
      "authors": [
        "Paulina Grnarova",
        "K. Levy",
        "Aurélien Lucchi",
        "Thomas Hofmann",
        "Andreas Krause"
      ],
      "year": 2017,
      "citation_count": 92,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/245f8b05bdd1ac65a09a476440dc4b05ac05d4a0",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "a0cca4fe677af57d1a8491d698c0d709535c44dd",
      "title": "CatGAN: Category-aware Generative Adversarial Networks with Hierarchical Evolutionary Learning for Category Text Generation",
      "abstract": "Generating multiple categories of texts is a challenging task and draws more and more attention. Since generative adversarial nets (GANs) have shown competitive results on general text generation, they are extended for category text generation in some previous works. However, the complicated model structures and learning strategies limit their performance and exacerbate the training instability. This paper proposes a category-aware GAN (CatGAN) which consists of an efficient category-aware model for category text generation and a hierarchical evolutionary learning algorithm for training our model. The category-aware model directly measures the gap between real samples and generated samples on each category, then reducing this gap will guide the model to generate high-quality category samples. The Gumbel-Softmax relaxation further frees our model from complicated learning strategies for updating CatGAN on discrete data. Moreover, only focusing on the sample quality normally leads the mode collapse problem, thus a hierarchical evolutionary learning algorithm is introduced to stabilize the training procedure and obtain the trade-off between quality and diversity while training CatGAN. Experimental results demonstrate that CatGAN outperforms most of the existing state-of-the-art methods.",
      "authors": [
        "Zhiyue Liu",
        "Jiahai Wang",
        "Zhiwei Liang"
      ],
      "year": 2019,
      "citation_count": 68,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/a0cca4fe677af57d1a8491d698c0d709535c44dd",
      "pdf_link": "",
      "venue": "AAAI Conference on Artificial Intelligence",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "531836a1c3fbbf10eba5375d8558f218cdb9805e",
      "title": "Smoothness and Stability in GANs",
      "abstract": "Generative adversarial networks, or GANs, commonly display unstable behavior during training. In this work, we develop a principled theoretical framework for understanding the stability of various types of GANs. In particular, we derive conditions that guarantee eventual stationarity of the generator when it is trained with gradient descent, conditions that must be satisfied by the divergence that is minimized by the GAN and the generator's architecture. We find that existing GAN variants satisfy some, but not all, of these conditions. Using tools from convex analysis, optimal transport, and reproducing kernels, we construct a GAN that fulfills these conditions simultaneously. In the process, we explain and clarify the need for various existing GAN stabilization techniques, including Lipschitz constraints, gradient penalties, and smooth activation functions.",
      "authors": [
        "Casey Chu",
        "Kentaro Minami",
        "K. Fukumizu"
      ],
      "year": 2020,
      "citation_count": 56,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/531836a1c3fbbf10eba5375d8558f218cdb9805e",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "29c53d37cb9bec0210e1584493479df13be85d90",
      "title": "On Stabilizing Generative Adversarial Training With Noise",
      "abstract": "We present a novel method and analysis to train generative adversarial networks (GAN) in a stable manner. As shown in recent analysis, training is often undermined by the probability distribution of the data being zero on neighborhoods of the data space. We notice that the distributions of real and generated data should match even when they undergo the same filtering. Therefore, to address the limited support problem we propose to train GANs by using different filtered versions of the real and generated data distributions. In this way, filtering does not prevent the exact matching of the data distribution, while helping training by extending the support of both distributions. As filtering we consider adding samples from an arbitrary distribution to the data, which corresponds to a convolution of the data distribution with the arbitrary one. We also propose to learn the generation of these samples so as to challenge the discriminator in the adversarial training. We show that our approach results in a stable and well-behaved training of even the original minimax GAN formulation. Moreover, our technique can be incorporated in most modern GAN formulations and leads to a consistent improvement on several common datasets.",
      "authors": [
        "S. Jenni",
        "P. Favaro"
      ],
      "year": 2019,
      "citation_count": 65,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/29c53d37cb9bec0210e1584493479df13be85d90",
      "pdf_link": "",
      "venue": "Computer Vision and Pattern Recognition",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "22530627d05baba39628e9d365b2f7fd8e81fe11",
      "title": "On the Effects of Batch and Weight Normalization in Generative Adversarial Networks",
      "abstract": "Generative adversarial networks (GANs) are highly effective unsupervised learning frameworks that can generate very sharp data, even for data such as images with complex, highly multimodal distributions. However GANs are known to be very hard to train, suffering from problems such as mode collapse and disturbing visual artifacts. Batch normalization (BN) techniques have been introduced to address the training. Though BN accelerates the training in the beginning, our experiments show that the use of BN can be unstable and negatively impact the quality of the trained model. The evaluation of BN and numerous other recent schemes for improving GAN training is hindered by the lack of an effective objective quality measure for GAN models. To address these issues, we first introduce a weight normalization (WN) approach for GAN training that significantly improves the stability, efficiency and the quality of the generated samples. To allow a methodical evaluation, we introduce squared Euclidean reconstruction error on a test set as a new objective measure, to assess training performance in terms of speed, stability, and quality of generated samples. Our experiments with a standard DCGAN architecture on commonly used datasets (CelebA, LSUN bedroom, and CIFAR-10) indicate that training using WN is generally superior to BN for GANs, achieving 10% lower mean squared loss for reconstruction and significantly better qualitative results than BN. We further demonstrate the stability of WN on a 21-layer ResNet trained with the CelebA data set. The code for this paper is available at this https URL",
      "authors": [
        "Sitao Xiang",
        "Hao Li"
      ],
      "year": 2017,
      "citation_count": 85,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/22530627d05baba39628e9d365b2f7fd8e81fe11",
      "pdf_link": "",
      "venue": "",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "fae3d474c4d7745be06458df0c20bf837a6055ef",
      "title": "Prescribed Generative Adversarial Networks",
      "abstract": "Generative adversarial networks (GANs) are a powerful approach to unsupervised learning. They have achieved state-of-the-art performance in the image domain. However, GANs are limited in two ways. They often learn distributions with low support---a phenomenon known as mode collapse---and they do not guarantee the existence of a probability density, which makes evaluating generalization using predictive log-likelihood impossible. In this paper, we develop the prescribed GAN (PresGAN) to address these shortcomings. PresGANs add noise to the output of a density network and optimize an entropy-regularized adversarial loss. The added noise renders tractable approximations of the predictive log-likelihood and stabilizes the training procedure. The entropy regularizer encourages PresGANs to capture all the modes of the data distribution. Fitting PresGANs involves computing the intractable gradients of the entropy regularization term; PresGANs sidestep this intractability using unbiased stochastic estimates. We evaluate PresGANs on several datasets and found they mitigate mode collapse and generate samples with high perceptual quality. We further found that PresGANs reduce the gap in performance in terms of predictive log-likelihood between traditional GANs and variational autoencoders (VAEs).",
      "authors": [
        "A. B. Dieng",
        "Francisco J. R. Ruiz",
        "D. Blei",
        "Michalis K. Titsias"
      ],
      "year": 2019,
      "citation_count": 62,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/fae3d474c4d7745be06458df0c20bf837a6055ef",
      "pdf_link": "",
      "venue": "arXiv.org",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "6cfb89a73b12caf20dbcdb7c5f6d9a85f02b0730",
      "title": "Imbalanced Fault Diagnosis of Rolling Bearing Using Enhanced Generative Adversarial Networks",
      "abstract": "Machinery fault diagnosis tasks have been well addressed when sufficient and abundant data are available. However, the data imbalance problem widely exists in real-world scenarios, which leads to the performance deterioration of fault diagnosis markedly. To solve this problem, we present a novel imbalanced fault diagnosis method based on the enhanced generative adversarial networks (GAN). By artificially generating fake samples, the proposed method can mitigate the loss caused by the lack of real fault data. Specifically, in order to improve the quality of generated samples, a new discriminator is designed using spectrum normalization (SN) strategy and a two time-scale update rule (TTUR) method is used to stabilize the training process of GAN. Then, an enhanced Wasserstein GAN with gradient penalty is developed to generate high-quality synthetic samples for the fault samples set. Finally, a deep convolutional classifier is constructed to carry out fault classification. The performance and effectiveness of the proposed method are validated on the Case Western Reserve University bearing dataset and rolling bearing dataset acquired from our laboratory. The simulation results show that the proposed method has a superior performance than other methods for imbalanced fault diagnosis tasks.",
      "authors": [
        "Hongliang Zhang",
        "Rui Wang",
        "Ruilin Pan",
        "Haiyang Pan"
      ],
      "year": 2020,
      "citation_count": 51,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/6cfb89a73b12caf20dbcdb7c5f6d9a85f02b0730",
      "pdf_link": "",
      "venue": "IEEE Access",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "29424f3ba4b63eca794f4cde9f59d9e9838147c0",
      "title": "Fidelity-Controllable Extreme Image Compression with Generative Adversarial Networks",
      "abstract": "We propose a GAN-based image compression method working at extremely low bitrates below 0.1bpp. Most existing learned image compression methods suffer from blur at extremely low bitrates. Although GAN can help to reconstruct sharp images, there are two drawbacks. First, GAN makes training unstable. Second, the reconstructions often contain unpleasing noise or artifacts. To address both of the drawbacks, our method adopts two-stage training and network interpolation. The two-stage training is effective to stabilize the training. Moreover, the network interpolation utilizes the models in both stages and reduces undesirable noise and artifacts, while maintaining important edges. Hence, we can control the trade-off between perceptual quality and fidelity without re-training models. The experimental results show that our model can reconstruct high quality images. Furthermore, our user study confirms that our reconstructions are preferable to state-of-the-art GAN-based image compression model. Our source code is available at https://github.com/iwa-shi/fidelity_controllable_compression",
      "authors": [
        "Shoma Iwai",
        "Tomo Miyazaki",
        "Yoshihiro Sugaya",
        "S. Omachi"
      ],
      "year": 2020,
      "citation_count": 47,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/29424f3ba4b63eca794f4cde9f59d9e9838147c0",
      "pdf_link": "",
      "venue": "International Conference on Pattern Recognition",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "32e277b85802685105254430c4170ad2b1a16c04",
      "title": "Label-Noise Robust Generative Adversarial Networks",
      "abstract": "Generative adversarial networks (GANs) are a framework that learns a generative distribution through adversarial training. Recently, their class conditional extensions (e.g., conditional GAN (cGAN) and auxiliary classifier GAN (AC-GAN)) have attracted much attention owing to their ability to learn the disentangled representations and to improve the training stability. However, their training requires the availability of large-scale accurate class-labeled data, which are often laborious or impractical to collect in a real-world scenario. To remedy this, we propose a novel family of GANs called label-noise robust GANs (rGANs), which, by incorporating a noise transition model, can learn a clean label conditional generative distribution even when training labels are noisy. In particular, we propose two variants: rAC-GAN, which is a bridging model between AC-GAN and the label-noise robust classification model, and rcGAN, which is an extension of cGAN and solves this problem with no reliance on any classifier. In addition to providing the theoretical background, we demonstrate the effectiveness of our models through extensive experiments using diverse GAN configurations, various noise settings, and multiple evaluation metrics (in which we tested 402 conditions in total).",
      "authors": [
        "Takuhiro Kaneko",
        "Y. Ushiku",
        "T. Harada"
      ],
      "year": 2018,
      "citation_count": 63,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/32e277b85802685105254430c4170ad2b1a16c04",
      "pdf_link": "",
      "venue": "Computer Vision and Pattern Recognition",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "9e1019b67dc1012eba53b34968fe352dc432f49d",
      "title": "Multi-Class Skin Problem Classification Using Deep Generative Adversarial Network (DGAN)",
      "abstract": "The lack of annotated datasets makes the automatic detection of skin problems very difficult, which is also the case for most other medical applications. The outstanding results achieved by deep learning techniques in developing such applications have improved the diagnostic accuracy. Nevertheless, the performance of these models is heavily dependent on the volume of labelled data used for training, which is unfortunately not available. To address this problem, traditional data augmentation is usually adopted. Recently, the emergence of a generative adversarial network (GAN) seems a more plausible solution, where synthetic images are generated. In this work, we have developed a deep generative adversarial network (DGAN) multi-class classifier, which can generate skin problem images by learning the true data distribution from the available images. Unlike the usual two-class classifier, we have developed a multi-class solution, and to address the class-imbalanced dataset, we have taken images from different datasets available online. One main challenge faced during our development is mainly to improve the stability of the DGAN model during the training phase. To analyse the performance of GAN, we have developed two CNN models in parallel based on the architecture of ResNet50 and VGG16 by augmenting the training datasets using the traditional rotation, flipping, and scaling methods. We have used both labelled and unlabelled data for testing to test the models. DGAN has outperformed the conventional data augmentation by achieving a performance of 91.1% for the unlabelled dataset and 92.3% for the labelled dataset. On the contrary, CNN models with data augmentation have achieved a performance of up to 70.8% for the unlabelled dataset. The outcome of our DGAN confirms the ability of the model to learn from unlabelled datasets and yet produce a good diagnosis result.",
      "authors": [
        "Maleika Heenaye-Mamode Khan",
        "N. Gooda Sahib-Kaudeer",
        "Motean Dayalen",
        "Faadil Mahomedaly",
        "G. Sinha",
        "K. Nagwanshi",
        "Amelia Taylor"
      ],
      "year": 2022,
      "citation_count": 27,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/9e1019b67dc1012eba53b34968fe352dc432f49d",
      "pdf_link": "",
      "venue": "Computational Intelligence and Neuroscience",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "9d4b4b44da22d4afdf127a1e33108f37bf1ec4e4",
      "title": "Evolutionary Architectural Search for Generative Adversarial Networks",
      "abstract": "The Generative Adversarial Network (GAN) has shown powerfulness in various real-world artificial intelligence applications. However, its network architecture is generally designed through a manual trial-and-error process, which is relatively tedious, slow, and sub-optimal. This paper hence develops an evolutionary architectural search (EAS) technique to automate the entire design process of the GAN. In particular, different objective functions are used in the generator of a GAN as variation operators. This helps train the generator with various candidate architectures and their associated weights to play adversarial training against the discriminator of the GAN. Following evaluations by the discriminator, superior candidate generators survive to the next generation and evolve for potentially better architectures and their weights simultaneously, leading to more stabilized GANs with improved performance. The GAN designed through EAS is termed an EAS-GAN in this paper and is tested against existing evolutionary and other state-of-the-art GANs. The test results show that the EAS-GAN offers better generative performance overall, with the Fréchet inception distance scoring 22.1, 38.8, and 8.3 on the CIFAR-10, STL-10, and LSUN bedroom data sets, respectively.",
      "authors": [
        "Qiuzhen Lin",
        "Z. Fang",
        "Yi Chen",
        "K. Tan",
        "Yun Li"
      ],
      "year": 2022,
      "citation_count": 25,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/9d4b4b44da22d4afdf127a1e33108f37bf1ec4e4",
      "pdf_link": "",
      "venue": "IEEE Transactions on Emerging Topics in Computational Intelligence",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "162e5a6c7fa9236be27966fd32b8e8f3819fc5b6",
      "title": "Cancer classification with data augmentation based on generative adversarial networks",
      "abstract": "",
      "authors": [
        "Kaimin Wei",
        "Tianqi Li",
        "Feiran Huang",
        "Jinpeng Chen",
        "Zefan He"
      ],
      "year": 2021,
      "citation_count": 32,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/162e5a6c7fa9236be27966fd32b8e8f3819fc5b6",
      "pdf_link": "",
      "venue": "Frontiers of Computer Science",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "ad37850e17ce5ad9ca954ec97c1fe95c31cefc9e",
      "title": "MAGAN: Margin Adaptation for Generative Adversarial Networks",
      "abstract": "We propose the Margin Adaptation for Generative Adversarial Networks (MAGANs) algorithm, a novel training procedure for GANs to improve stability and performance by using an adaptive hinge loss function. We estimate the appropriate hinge loss margin with the expected energy of the target distribution, and derive principled criteria for when to update the margin. We prove that our method converges to its global optimum under certain assumptions. Evaluated on the task of unsupervised image generation, the proposed training procedure is simple yet robust on a diverse set of data, and achieves qualitative and quantitative improvements compared to the state-of-the-art.",
      "authors": [
        "Ruohan Wang",
        "Antoine Cully",
        "H. Chang",
        "Y. Demiris"
      ],
      "year": 2017,
      "citation_count": 64,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/ad37850e17ce5ad9ca954ec97c1fe95c31cefc9e",
      "pdf_link": "",
      "venue": "arXiv.org",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "30831a581be8b76a99ef079f82e3c1b5f8c2dc05",
      "title": "Logo Synthesis and Manipulation with Clustered Generative Adversarial Networks",
      "abstract": "Designing a logo for a new brand is a lengthy and tedious back-and-forth process between a designer and a client. In this paper we explore to what extent machine learning can solve the creative task of the designer. For this, we build a dataset - LLD - of 600k+ logos crawled from the world wide web. Training Generative Adversarial Networks (GANs) for logo synthesis on such multi-modal data is not straightforward and results in mode collapse for some state-of-the-art methods. We propose the use of synthetic labels obtained through clustering to disentangle and stabilize GAN training, and validate this approach on CIFAR-10 and ImageNet-small to demonstrate its generality. We are able to generate a high diversity of plausible logos and demonstrate latent space exploration techniques to ease the logo design task in an interactive manner. GANs can cope with multi-modal data by means of synthetic labels achieved through clustering, and our results show the creative potential of such techniques for logo synthesis and manipulation. Our dataset and models are publicly available at https://data.vision.ee.ethz.ch/sagea/lld/.",
      "authors": [
        "Alexander Sage",
        "E. Agustsson",
        "R. Timofte",
        "L. Gool"
      ],
      "year": 2017,
      "citation_count": 62,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/30831a581be8b76a99ef079f82e3c1b5f8c2dc05",
      "pdf_link": "",
      "venue": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "0984634505e7b4a8004eaf26416ffedd81cd5861",
      "title": "Improving GAN Training with Probability Ratio Clipping and Sample Reweighting",
      "abstract": "Despite success on a wide range of problems related to vision, generative adversarial networks (GANs) can suffer from inferior performance due to unstable training, especially for text generation. We propose a new variational GAN training framework which enjoys superior training stability. Our approach is inspired by a connection of GANs and reinforcement learning under a variational perspective. The connection leads to (1) probability ratio clipping that regularizes generator training to prevent excessively large updates, and (2) a sample re-weighting mechanism that stabilizes discriminator training by downplaying bad-quality fake samples. We provide theoretical analysis on the convergence of our approach. By plugging the training approach in diverse state-of-the-art GAN architectures, we obtain significantly improved performance over a range of tasks, including text generation, text style transfer, and image generation.",
      "authors": [
        "Yue Wu",
        "Pan Zhou",
        "A. Wilson",
        "E. Xing",
        "Zhiting Hu"
      ],
      "year": 2020,
      "citation_count": 36,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/0984634505e7b4a8004eaf26416ffedd81cd5861",
      "pdf_link": "",
      "venue": "Neural Information Processing Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "fc62dad5dc03f7b2a6d9b8e7d3934108f4b511f8",
      "title": "SGAN: An Alternative Training of Generative Adversarial Networks",
      "abstract": "The Generative Adversarial Networks (GANs) have demonstrated impressive performance for data synthesis, and are now used in a wide range of computer vision tasks. In spite of this success, they gained a reputation for being difficult to train, what results in a time-consuming and human-involved development process to use them. We consider an alternative training process, named SGAN, in which several adversarial \"local\" pairs of networks are trained independently so that a \"global\" supervising pair of networks can be trained against them. The goal is to train the global pair with the corresponding ensemble opponent for improved performances in terms of mode coverage. This approach aims at increasing the chances that learning will not stop for the global pair, preventing both to be trapped in an unsatisfactory local minimum, or to face oscillations often observed in practice. To guarantee the latter, the global pair never affects the local ones. The rules of SGAN training are thus as follows: the global generator and discriminator are trained using the local discriminators and generators, respectively, whereas the local networks are trained with their fixed local opponent. Experimental results on both toy and real-world problems demonstrate that this approach outperforms standard training in terms of better mitigating mode collapse, stability while converging and that it surprisingly, increases the convergence speed as well.",
      "authors": [
        "Tatjana Chavdarova",
        "F. Fleuret"
      ],
      "year": 2017,
      "citation_count": 57,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/fc62dad5dc03f7b2a6d9b8e7d3934108f4b511f8",
      "pdf_link": "",
      "venue": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "32038e56d0174b33a93c66258f346c1a173fe81d",
      "title": "A New Perspective on Stabilizing GANs Training: Direct Adversarial Training",
      "abstract": "Generative Adversarial Networks (GANs) are the most popular image generation models that have achieved remarkable progress on various computer vision tasks. However, training instability is still one of the open problems for all GAN-based algorithms. Quite a number of methods have been proposed to stabilize the training of GANs, the focuses of which were respectively put on the loss functions, regularization and normalization technologies, training algorithms, and model architectures. Different from the above methods, in this paper, a new perspective on stabilizing GANs training is presented. It is found that sometimes the images produced by the generator act like adversarial examples of the discriminator during the training process, which may be part of the reason causing the unstable training of GANs. With this finding, we propose the Direct Adversarial Training (DAT) method to stabilize the training process of GANs. Furthermore, we prove that the DAT method is able to minimize the Lipschitz constant of the discriminator adaptively. The advanced performance of DAT is verified on multiple loss functions, network architectures, hyper-parameters, and datasets. Specifically, DAT achieves significant improvements of 11.5% FID on CIFAR-100 unconditional generation based on SSGAN, 10.5% FID on STL-10 unconditional generation based on SSGAN, and 13.2% FID on LSUN-Bedroom unconditional generation based on SSGAN.",
      "authors": [
        "Ziqiang Li",
        "Pengfei Xia",
        "Rentuo Tao",
        "Hongjing Niu",
        "Bin Li"
      ],
      "year": 2020,
      "citation_count": 35,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/32038e56d0174b33a93c66258f346c1a173fe81d",
      "pdf_link": "",
      "venue": "IEEE Transactions on Emerging Topics in Computational Intelligence",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "bffb2fe8b60d7acd307f28ff04b1f3f486511639",
      "title": "Fast Multi-Focus Ultrasound Image Recovery Using Generative Adversarial Networks",
      "abstract": "In conventional ultrasound (US) imaging, it is common to transmit several focused beams at multiple locations to generate a multi-focus image with constant lateral resolution throughout the image. However, this method comes at the expense of a loss in temporal resolution, which is important in applications requiring both high-frame rate and constant lateral resolution. Moreover, relative motions of the target with respect to the probe often exist due to hand tremors or biological motions, causing blurring artifacts in the multi-focus image. This article introduces a novel approach for multi-focus US image recovery based on Generative Adversarial Network (GAN) without a reduction in the frame-rate. Herein, a mapping function between the single-focus US image and multi-focus version for having a constant lateral resolution everywhere is estimated through different GANs. We use adversarial loss functions in addition to Mean Square Error (MSE) to generate more realistic ultrasound images. Moreover, we use the boundary seeking method for improving the stability of training, which is currently the main challenge in using GANs. Experiments on simulated and real phantoms as well as on ex vivo data are performed. Results confirm that having both adversarial loss function and boundary seeking training provides better results in terms of the mean opinion score test. Furthermore, the proposed method enhances the resolution and contrast indexes without sacrificing the frame-rate. As for the comparison with other approaches which are not based on NNs, the proposed approach gives similar results while requiring neither channel data nor computationally expensive algorithms.",
      "authors": [
        "Sobhan Goudarzi",
        "A. Asif",
        "H. Rivaz"
      ],
      "year": 2020,
      "citation_count": 35,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/bffb2fe8b60d7acd307f28ff04b1f3f486511639",
      "pdf_link": "",
      "venue": "IEEE Transactions on Computational Imaging",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "e4abcf52b65969f8fed43eff8f5cc512553b41d0",
      "title": "Channel Estimation Enhancement With Generative Adversarial Networks",
      "abstract": "Improving the accuracy of channel estimation is a significant topic in the context of wireless communications. For training-based channel estimations, increasing the length of a training sequence may improve the accuracy of channel estimation but causes a higher overhead. Nevertheless, this paper shows that benefiting from generative adversarial networks (GANs), which is an emerging deep learning framework, the accuracy of channel estimation can be improved without transmitting a longer training sequence. To this end, this paper proposes a GAN-based channel estimation enhancement algorithm, where GANs are trained online with receive sequence so as to obtain a longer mimic sequence and enhance channel estimation. In order to address the problem of improving the training stability and the learning ability of GANs, this paper proposes a novel framework by integrating a conditional GAN with an improved Wasserstein GAN. Furthermore, a strategy based on a lookup table is proposed to alleviate overfitting that may occur during the training of GANs. Simulation results indicate that the proposed GAN-based channel estimation enhancement algorithm can benefit the conventional training-based channel estimation, yielding lower relative error performance, especially in the low SNR regions.",
      "authors": [
        "Tianyu Hu",
        "Yang Huang",
        "Qiuming Zhu",
        "Qi-hui Wu"
      ],
      "year": 2021,
      "citation_count": 27,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/e4abcf52b65969f8fed43eff8f5cc512553b41d0",
      "pdf_link": "",
      "venue": "IEEE Transactions on Cognitive Communications and Networking",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "25cb41a83ce6b70681b037c21e6d2c147dfc001b",
      "title": "A Novel Method for Fault Diagnosis of Bearings with Small and Imbalanced Data Based on Generative Adversarial Networks",
      "abstract": "The data-driven intelligent fault diagnosis method of rolling bearings has strict requirements regarding the number and balance of fault samples. However, in practical engineering application scenarios, mechanical equipment is usually in a normal state, and small and imbalanced (S & I) fault samples are common, which seriously reduces the accuracy and stability of the fault diagnosis model. To solve this problem, an auxiliary classifier generative adversarial network with spectral normalization (ACGAN-SN) is proposed in this paper. First, a generation module based on a deconvolution layer is built to generate false data from Gaussian noise. Second, to enhance the training stability of the model, the data label information is used to make label constraints on the generated fake data under the basic GAN framework. Spectral normalization constraints are imposed on the output of each layer of the neural network of the discriminator to realize the Lipschitz continuity condition so as to avoid vanishing or exploding gradients. Finally, based on the generated data and the original S & I dataset, seven kinds of bearing fault datasets are made, and the prediction results of the Bi-directional Long Short-Term Memory (BiLSTM) model is verified. The results show that the data generated by ACGAN-SN can significantly promote the performance of the fault diagnosis model under the S & I fault samples.",
      "authors": [
        "Q. Tong",
        "Feiyu Lu",
        "Ziwei Feng",
        "Qingzhu Wan",
        "Guoping An",
        "Junci Cao",
        "Tao Guo"
      ],
      "year": 2022,
      "citation_count": 19,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/25cb41a83ce6b70681b037c21e6d2c147dfc001b",
      "pdf_link": "",
      "venue": "Applied Sciences",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "b48b68f52b2ebaa8c7b428e98eafe1953045067f",
      "title": "Coevolution of Generative Adversarial Networks",
      "abstract": "Generative adversarial networks (GAN) became a hot topic, presenting impressive results in the field of computer vision. However, there are still open problems with the GAN model, such as the training stability and the hand-design of architectures. Neuroevolution is a technique that can be used to provide the automatic design of network architectures even in large search spaces as in deep neural networks. Therefore, this project proposes COEGAN, a model that combines neuroevolution and coevolution in the coordination of the GAN training algorithm. The proposal uses the adversarial characteristic between the generator and discriminator components to design an algorithm using coevolution techniques. Our proposal was evaluated in the MNIST dataset. The results suggest the improvement of the training stability and the automatic discovery of efficient network architectures for GANs. Our model also partially solves the mode collapse problem.",
      "authors": [
        "Victor Costa",
        "Nuno Lourenço",
        "P. Machado"
      ],
      "year": 2019,
      "citation_count": 37,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/b48b68f52b2ebaa8c7b428e98eafe1953045067f",
      "pdf_link": "",
      "venue": "EvoApplications",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "16dc13f77f8631aefb47ee57cadf5676b926e9bb",
      "title": "Laplacian Pyramid Generative Adversarial Network for Infrared and Visible Image Fusion",
      "abstract": "Generative adversarial network (GAN) has recently demonstrated a powerful tool for infrared and visible image fusion. However, existing methods extract the features incompletely, miss some textures, and lack the stability of training. To cope with these issues, this article proposes a novel image fusion Laplacian pyramid GAN (IF-LapGAN). Firstly, a generator is constructed which consists of shallow features extraction module, Laplacian pyramid module, and reconstruction module. Specifically, the Laplacian pyramid module is a pyramid-style encoder-decoder architecture, which progressively extracts the multi-scale features. Moreover, the attention module is equipped in the decoder to effectively decode the salient features. Then, two discriminators are adopted to discriminate the fused image and two different modalities respectively. To improve the stability of adversarial learning, we propose to develop another side supervised loss based on the side pre-trained fusion network. Extensive experiments show that IF-LapGAN achieves 3.27%, 27.28%, 6.32%, 1.39%, 3.14%, 1.15% and 1.07% improvement gains in terms of <inline-formula><tex-math notation=\"LaTeX\">$Q_{NMI}$</tex-math></inline-formula>, <inline-formula><tex-math notation=\"LaTeX\">$Q_{M}$</tex-math></inline-formula>, <inline-formula><tex-math notation=\"LaTeX\">$Q_{Yang}$</tex-math></inline-formula>, <inline-formula><tex-math notation=\"LaTeX\">$Q^{AB/F}$</tex-math></inline-formula>, MI, VIF, and FMI, respectively, compared with the second best values.",
      "authors": [
        "Haitao Yin",
        "Jing Xiao"
      ],
      "year": 2022,
      "citation_count": 17,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/16dc13f77f8631aefb47ee57cadf5676b926e9bb",
      "pdf_link": "",
      "venue": "IEEE Signal Processing Letters",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "6c01187f5930e9618b05611dca1065b926ed4ab6",
      "title": "Deep Convolutional Generative Adversarial Network With Autoencoder for Semisupervised SAR Image Classification",
      "abstract": "Effective and efficient classification of synthetic aperture radar (SAR) images represents an important step toward image interpretation and knowledge discovery. Keys to classification performance include feature extraction and availability of class labels for training. Generative adversarial networks (GANs) are a recently advanced powerful framework to offer both automatic feature extraction and semisupervised and unsupervised learning. For its known drawbacks such as mode collapse and training instability, noteworthy improvements include the deep convolutional GANs (DCGANs). In the letter, we proposed a new approach, which further advances DCGANs with autoencoder (AE) for intermediate feature extraction and reconstruction, in combination with multiclassifier (MC) for better context treatment. The resulting improvement on training stability and mode preservation over DCGAN is clearly demonstrated by the classification results across multifrequency bands (L-, C-, and X-bands).",
      "authors": [
        "Zheng Zhang",
        "Jingsong Yang",
        "Yang Du"
      ],
      "year": 2022,
      "citation_count": 16,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/6c01187f5930e9618b05611dca1065b926ed4ab6",
      "pdf_link": "",
      "venue": "IEEE Geoscience and Remote Sensing Letters",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "344e8d09cd6144e84a92273d2b5be6c885ce2c22",
      "title": "Adversarial Training for Sketch Retrieval",
      "abstract": "Generative Adversarial Networks (GAN) are able to learn excellent representations for unlabelled data which can be applied to image generation and scene classification. Representations learned by GANs have not yet been applied to retrieval. In this paper, we show that the representations learned by GANs can indeed be used for retrieval. We consider heritage documents that contain unlabelled Merchant Marks, sketch-like symbols that are similar to hieroglyphs. We introduce a novel GAN architecture with design features that make it suitable for sketch retrieval. The performance of this sketch-GAN is compared to a modified version of the original GAN architecture with respect to simple invariance properties. Experiments suggest that sketch-GANs learn representations that are suitable for retrieval and which also have increased stability to rotation, scale and translation compared to the standard GAN architecture.",
      "authors": [
        "Antonia Creswell",
        "A. Bharath"
      ],
      "year": 2016,
      "citation_count": 47,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/344e8d09cd6144e84a92273d2b5be6c885ce2c22",
      "pdf_link": "",
      "venue": "ECCV Workshops",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "72a6044a0108e0f8f1e68cd70ada46c81a416324",
      "title": "Improved Training of Generative Adversarial Networks Using Representative Features",
      "abstract": "Despite the success of generative adversarial networks (GANs) for image generation, the trade-off between visual quality and image diversity remains a significant issue. This paper achieves both aims simultaneously by improving the stability of training GANs. The key idea of the proposed approach is to implicitly regularize the discriminator using representative features. Focusing on the fact that standard GAN minimizes reverse Kullback-Leibler (KL) divergence, we transfer the representative feature, which is extracted from the data distribution using a pre-trained autoencoder (AE), to the discriminator of standard GANs. Because the AE learns to minimize forward KL divergence, our GAN training with representative features is influenced by both reverse and forward KL divergence. Consequently, the proposed approach is verified to improve visual quality and diversity of state of the art GANs using extensive evaluations.",
      "authors": [
        "Duhyeon Bang",
        "Hyunjung Shim"
      ],
      "year": 2018,
      "citation_count": 34,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/72a6044a0108e0f8f1e68cd70ada46c81a416324",
      "pdf_link": "",
      "venue": "International Conference on Machine Learning",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "f9d11bdadd0a10f9cf74da34796328cb77de134d",
      "title": "Stabilizing Training of Generative Adversarial Nets via Langevin Stein Variational Gradient Descent",
      "abstract": "Generative adversarial networks (GANs), which are famous for the capability of learning complex underlying data distribution, are, however, known to be tricky in the training process, which would probably result in mode collapse or performance deterioration. Current approaches of dealing with GANs’ issues almost utilize some practical training techniques for the purpose of regularization, which, on the other hand, undermines the convergence and theoretical soundness of GAN. In this article, we propose to stabilize GAN training via a novel particle-based variational inference—Langevin Stein variational gradient descent (LSVGD), which not only inherits the flexibility and efficiency of original SVGD but also aims to address its instability issues by incorporating an extra disturbance into the update dynamics. We further demonstrate that, by properly adjusting the noise variance, LSVGD simulates a Langevin process whose stationary distribution is exactly the target distribution. We also show that LSVGD dynamics has an implicit regularization, which is able to enhance particles’ spread-out and diversity. Finally, we present an efficient way of applying particle-based variational inference on a general GAN training procedure no matter what loss function is adopted. Experimental results on one synthetic data set and three popular benchmark data sets—Cifar-10, Tiny-ImageNet, and CelebA—validate that LSVGD can remarkably improve the performance and stability of various GAN models.",
      "authors": [
        "Dong Wang",
        "Xiaoqian Qin",
        "F. Song",
        "Li Cheng"
      ],
      "year": 2020,
      "citation_count": 24,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/f9d11bdadd0a10f9cf74da34796328cb77de134d",
      "pdf_link": "",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "23006dfeb539bc4f4f66e43e6d6670c4f3510a4c",
      "title": "Utilizing Amari-Alpha Divergence to Stabilize the Training of Generative Adversarial Networks",
      "abstract": "Generative Adversarial Nets (GANs) are one of the most popular architectures for image generation, which has achieved significant progress in generating high-resolution, diverse image samples. The normal GANs are supposed to minimize the Kullback–Leibler divergence between distributions of natural and generated images. In this paper, we propose the Alpha-divergence Generative Adversarial Net (Alpha-GAN) which adopts the alpha divergence as the minimization objective function of generators. The alpha divergence can be regarded as a generalization of the Kullback–Leibler divergence, Pearson χ2 divergence, Hellinger divergence, etc. Our Alpha-GAN employs the power function as the form of adversarial loss for the discriminator with two-order indexes. These hyper-parameters make our model more flexible to trade off between the generated and target distributions. We further give a theoretical analysis of how to select these hyper-parameters to balance the training stability and the quality of generated images. Extensive experiments of Alpha-GAN are performed on SVHN and CelebA datasets, and evaluation results show the stability of Alpha-GAN. The generated samples are also competitive compared with the state-of-the-art approaches.",
      "authors": [
        "Likun Cai",
        "Yanjie Chen",
        "Ning Cai",
        "Wei Cheng",
        "Hao Wang"
      ],
      "year": 2020,
      "citation_count": 24,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/23006dfeb539bc4f4f66e43e6d6670c4f3510a4c",
      "pdf_link": "",
      "venue": "Entropy",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "c9f6ff493aade94a2fd6f4e89201e3d7333aedcb",
      "title": "Generative Adversarial Networks and Other Generative Models",
      "abstract": "Generative networks are fundamentally different in their aim and methods compared to CNNs for classification, segmentation, or object detection. They have initially not been meant to be an image analysis tool, but to produce naturally looking images. The adversarial training paradigm has been proposed to stabilize generative methods, and has proven to be highly successful – though by no means from the first attempt. This chapter gives a basic introduction into the motivation for Generative Adversarial Networks (GANs) and traces the path of their success by abstracting the basic task and working mechanism, and deriving the difficulty of early practical approaches. Methods for a more stable training will be shown, and also typical signs for poor convergence and their reasons. Though this chapter focuses on GANs that are meant for image generation and image analysis, the adversarial training paradigm itself is not specific to images, and also generalizes to tasks in image analysis. Examples of architectures for image semantic segmentation and abnormality detection will be acclaimed, before contrasting GANs with further generative modeling approaches lately entering the scene. This will allow a contextualized view on the limits but also benefits of GANs.",
      "authors": [
        "Markus T. Wenzel"
      ],
      "year": 2022,
      "citation_count": 14,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/c9f6ff493aade94a2fd6f4e89201e3d7333aedcb",
      "pdf_link": "",
      "venue": "arXiv.org",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "0edc142b51581a358055d7eddada8a4d0f9d021b",
      "title": "A Variational Inequality Perspective on Generative Adversarial Nets",
      "abstract": "",
      "authors": [
        "G. Gidel",
        "Hugo Berard",
        "Pascal Vincent",
        "Simon Lacoste-Julien"
      ],
      "year": 2018,
      "citation_count": 32,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/0edc142b51581a358055d7eddada8a4d0f9d021b",
      "pdf_link": "",
      "venue": "arXiv.org",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "4136412ac44e9185125246be447d2c06e8676dcc",
      "title": "Class-Splitting Generative Adversarial Networks",
      "abstract": "Generative Adversarial Networks (GANs) produce systematically better quality samples when class label information is provided., i.e. in the conditional GAN setup. This is still observed for the recently proposed Wasserstein GAN formulation which stabilized adversarial training and allows considering high capacity network architectures such as ResNet. In this work we show how to boost conditional GAN by augmenting available class labels. The new classes come from clustering in the representation space learned by the same GAN model. The proposed strategy is also feasible when no class information is available, i.e. in the unsupervised setup. Our generated samples reach state-of-the-art Inception scores for CIFAR-10 and STL-10 datasets in both supervised and unsupervised setup.",
      "authors": [
        "G. Grinblat",
        "Lucas C. Uzal",
        "P. Granitto"
      ],
      "year": 2017,
      "citation_count": 35,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/4136412ac44e9185125246be447d2c06e8676dcc",
      "pdf_link": "",
      "venue": "arXiv.org",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "4795c82ec752177a2904da44b05231da93d69c4f",
      "title": "GANDALF: Generative Adversarial Networks with Discriminator-Adaptive Loss Fine-tuning for Alzheimer's Disease Diagnosis from MRI",
      "abstract": "Positron Emission Tomography (PET) is now regarded as the gold standard for the diagnosis of Alzheimer's Disease (AD). However, PET imaging can be prohibitive in terms of cost and planning, and is also among the imaging techniques with the highest dosage of radiation. Magnetic Resonance Imaging (MRI), in contrast, is more widely available and provides more flexibility when setting the desired image resolution. Unfortunately, the diagnosis of AD using MRI is difficult due to the very subtle physiological differences between healthy and AD subjects visible on MRI. As a result, many attempts have been made to synthesize PET images from MR images using generative adversarial networks (GANs) in the interest of enabling the diagnosis of AD from MR. Existing work on PET synthesis from MRI has largely focused on Conditional GANs, where MR images are used to generate PET images and subsequently used for AD diagnosis. There is no end-to-end training goal. This paper proposes an alternative approach to the aforementioned, where AD diagnosis is incorporated in the GAN training objective to achieve the best AD classification performance. Different GAN lossesare fine-tuned based on the discriminator performance, and the overall training is stabilized. The proposed network architecture and training regime show state-of-the-art performance for three- and four- class AD classification tasks.",
      "authors": [
        "Hoo-Chang Shin",
        "Alvin Ihsani",
        "Ziyue Xu",
        "Swetha Mandava",
        "Sharath Turuvekere Sreenivas",
        "Christopher Forster",
        "Jiook Cha",
        "Alzheimer's Disease Neuroimaging Initiative"
      ],
      "year": 2020,
      "citation_count": 21,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/4795c82ec752177a2904da44b05231da93d69c4f",
      "pdf_link": "",
      "venue": "International Conference on Medical Image Computing and Computer-Assisted Intervention",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "7ece301f8d69674b49c3485af49668ed9f6084c8",
      "title": "Anomaly Detection via Minimum Likelihood Generative Adversarial Networks",
      "abstract": "Anomaly detection aims to detect abnormal events by a model of normality. It plays an important role in many domains such as network intrusion detection, criminal activity identity and so on. With the rapidly growing size of accessible training data and high computation capacities, deep learning based anomaly detection has become more and more popular. In this paper, a new domain-based anomaly detection method based on generative adversarial networks (GAN) is proposed. Minimum likelihood regularization is proposed to make the generator produce more anomalies and prevent it from converging to normal data distribution. Proper ensemble of anomaly scores is shown to improve the stability of discriminator effectively. The proposed method has achieved significant improvement than other anomaly detection methods on Cifar10 and UCI datasets.",
      "authors": [
        "Chu Wang",
        "Yanming Zhang",
        "Cheng-Lin Liu"
      ],
      "year": 2018,
      "citation_count": 29,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/7ece301f8d69674b49c3485af49668ed9f6084c8",
      "pdf_link": "",
      "venue": "International Conference on Pattern Recognition",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "6a514c0c8c031bb4e1cc2ae9032780df408442a5",
      "title": "GANai: Standardizing CT Images using Generative Adversarial Network with Alternative Improvement",
      "abstract": "Computed tomography (CT) is a widely-used diag-reproducibility regarding radiomic features, such as intensity, nostic image modality routinely used for assessing anatomical tissue characteristics. However, non-standardized imaging pro-tocols are commonplace, which poses a fundamental challenge in large-scale cross-center CT image analysis. One approach to address the problem is to standardize CT images using generative adversarial network models (GAN). GAN learns the data distribution of training images and generate synthesized images under the same distribution. However, existing GAN models are not directly applicable to this task mainly due to the lack of constraints on the mode of data to generate. Furthermore, they treat every image equally, but in real applications, some images are more difficult to standardize than the others. All these may lead to the lack-of-detail problem in CT image synthesis. We present a new GAN model called GANai to mitigate the differences in radiomic features across CT images captured using non-standard imaging protocols. Given source images, GANai composes new images by specifying a high-level goal that the image features of the synthesized images should be similar to those of the standard images. GANai introduces an alternative improvement training strategy to alternatively and steadily improve model performance. The new training strategy enables a series of technical improvements, including phase-specific loss functions, phase-specific training data, and the adoption of ensemble learning, leading to better model performance. The experimental results show that GANai is significantly better than the existing state-of-the-art image synthesis algorithms on CT image standardization. Also, it significantly improves the efficiency and stability of GAN model training.",
      "authors": [
        "G. Liang",
        "S. Fouladvand",
        "Jie Zhang",
        "Michael A. Brooks",
        "Nathan Jacobs",
        "Jin Chen"
      ],
      "year": 2018,
      "citation_count": 29,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/6a514c0c8c031bb4e1cc2ae9032780df408442a5",
      "pdf_link": "",
      "venue": "bioRxiv",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "2844a274111907daea511f8378ccca67a9eb81d1",
      "title": "PEGANs: Phased Evolutionary Generative Adversarial Networks with Self-Attention Module",
      "abstract": "Generative adversarial networks have made remarkable achievements in generative tasks. However, instability and mode collapse are still frequent problems. We improve the framework of evolutionary generative adversarial networks (E-GANs), calling it phased evolutionary generative adversarial networks (PEGANs), and adopt a self-attention module to improve upon the disadvantages of convolutional operations. During the training process, the discriminator will play against multiple generators simultaneously, where each generator adopts a different objective function as a mutation operation. Every time after the specified number of training iterations, the generator individuals will be evaluated and the best performing generator offspring will be retained for the next round of evolution. Based on this, the generator can continuously adjust the training strategy during training, and the self-attention module also enables the model to obtain the modeling ability of long-range dependencies. Experiments on two datasets showed that PEGANs improve the training stability and are competitive in generating high-quality samples.",
      "authors": [
        "Yu Xue",
        "Weinan Tong",
        "Ferrante Neri",
        "Yixia Zhang"
      ],
      "year": 2022,
      "citation_count": 12,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/2844a274111907daea511f8378ccca67a9eb81d1",
      "pdf_link": "",
      "venue": "Mathematics",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "36f7724f28f497d55f720719fb58f1c146ecbc32",
      "title": "LoGANv2: Conditional Style-Based Logo Generation with Generative Adversarial Networks",
      "abstract": "Domains such as logo synthesis, in which the data has a high degree of multi-modality, still pose a challenge for generative adversarial networks (GANs). Recent research shows that progressive training (ProGAN) and mapping network extensions (StyleGAN) enable both increased training stability for higher dimensional problems and better feature separation within the embedded latent space. However, these architectures leave limited control over shaping the output of the network. This paper explores a conditional extension to the StyleGAN architecture with the aim of firstly, improving on the low resolution results of previous research and, secondly, increasing the controllability of the output through the use of synthetic class-conditions. Furthermore, methods of extracting such class conditions are explored, where the challenge lies in the fact that, visual logo characteristics are hard to define. The introduced conditional style-based generator architecture is trained on the extracted class-conditions in two experiments and studied relative to the performance of an unconditional model. Results show that, whilst the unconditional model more closely matches the training distribution, high quality conditions enabled the embedding of finer details onto the latent space, leading to more diverse output.",
      "authors": [
        "Cedric Oeldorf",
        "Gerasimos Spanakis"
      ],
      "year": 2019,
      "citation_count": 24,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/36f7724f28f497d55f720719fb58f1c146ecbc32",
      "pdf_link": "",
      "venue": "International Conference on Machine Learning and Applications",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "2cc9e70cd4664533af9bf34b2da7a1c2694616f8",
      "title": "Tempered Adversarial Networks",
      "abstract": "Generative adversarial networks (GANs) have been shown to produce realistic samples from high-dimensional distributions, but training them is considered hard. A possible explanation for training instabilities is the inherent imbalance between the networks: While the discriminator is trained directly on both real and fake samples, the generator only has control over the fake samples it produces since the real data distribution is fixed by the choice of a given dataset. We propose a simple modification that gives the generator control over the real samples which leads to a tempered learning process for both generator and discriminator. The real data distribution passes through a lens before being revealed to the discriminator, balancing the generator and discriminator by gradually revealing more detailed features necessary to produce high-quality results. The proposed module automatically adjusts the learning process to the current strength of the networks, yet is generic and easy to add to any GAN variant. In a number of experiments, we show that this can improve quality, stability and/or convergence speed across a range of different GAN architectures (DCGAN, LSGAN, WGAN-GP).",
      "authors": [
        "Mehdi S. M. Sajjadi",
        "B. Scholkopf"
      ],
      "year": 2018,
      "citation_count": 28,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/2cc9e70cd4664533af9bf34b2da7a1c2694616f8",
      "pdf_link": "",
      "venue": "International Conference on Machine Learning",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "a4f020c2339f1cf3595bef233b429f93460f0c0c",
      "title": "Evasion Generative Adversarial Network for Low Data Regimes",
      "abstract": "A myriad of recent literary works have leveraged generative adversarial networks (GANs) to generate unseen evasion samples. The purpose is to annex the generated data with the original train set for adversarial training to improve the detection performance of machine learning (ML) classifiers. The quality of generated adversarial samples relies on the adequacy of training data samples. However, in low data regimes like medical diagnostic imaging and cybersecurity, the anomaly samples are scarce in number. This paper proposes a novel GAN design called evasion generative adversarial network (EVAGAN) that is more suitable for low data regime problems that use oversampling for detection improvement of ML classifiers. EVAGAN not only can generate evasion samples but its discriminator can act as an evasion-aware classifier. We have considered auxiliary classifier GAN (ACGAN) as a benchmark to evaluate the performance of EVAGAN on cybersecurity (ISCX-2014, CIC-2017, and CIC2018) botnet and computer vision (MNIST) datasets. We demonstrate that EVAGAN outperforms ACGAN for unbalanced datasets with respect to detection performance, training stability, and time complexity. EVAGAN's generator quickly learns to generate the low sample class and hardens its discriminator simultaneously. In contrast to ML classifiers that require security hardening after being adversarially trained by GAN-generated data, EVAGAN renders it needless. The experimental analysis proves that EVAGAN is an efficient evasion hardened model for low data regimes for the selected cybersecurity and computer vision datasets.",
      "authors": [
        "Rizwan Hamid Randhawa",
        "N. Aslam",
        "Mohammad Alauthman",
        "Husnain Rafiq"
      ],
      "year": 2021,
      "citation_count": 15,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/a4f020c2339f1cf3595bef233b429f93460f0c0c",
      "pdf_link": "",
      "venue": "IEEE Transactions on Artificial Intelligence",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "1d21ce033822c23f499179dd19769f7b94077d6b",
      "title": "Semi-Supervised Generative Adversarial Nets with Multiple Generators for SAR Image Recognition",
      "abstract": "As an important model of deep learning, semi-supervised learning models are based on Generative Adversarial Nets (GANs) and have achieved a competitive performance on standard optical images. However, the training of GANs becomes unstable when they are applied to SAR images, which reduces the feature extraction capability of the discriminator in GANs. This paper presents a new semi-supervised GANs with Multiple generators and a classifier (MCGAN). This model improves the stability of training for SAR images by employing multiple generators. A multi-classifier is introduced to the new GANs to utilize the labeled images during the training of the GANs, which shares the low level layers with the discriminator. Then, the layers of the trained discriminator and the classifier construct the recognition network for SAR images after having been finely tuned using a small number of the labeled images. Experiments on the Moving and Stationary Target Acquisition and Recognition (MSTAR) databases show that the proposed recognition network achieves a better and more stable recognition performance than several traditional semi-supervised methods as well as other GANs-based semi-supervised methods.",
      "authors": [
        "F. Gao",
        "Fei Ma",
        "Jun Wang",
        "Jinping Sun",
        "Erfu Yang",
        "Huiyu Zhou"
      ],
      "year": 2018,
      "citation_count": 24,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/1d21ce033822c23f499179dd19769f7b94077d6b",
      "pdf_link": "",
      "venue": "Italian National Conference on Sensors",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "1ea136c958425ddd113e48eebdd07865ebf3a745",
      "title": "Bayesian Cycle-Consistent Generative Adversarial Networks via Marginalizing Latent Sampling",
      "abstract": "Recent techniques built on generative adversarial networks (GANs), such as cycle-consistent GANs, are able to learn mappings among different domains built from unpaired data sets, through min–max optimization games between generators and discriminators. However, it remains challenging to stabilize the training process and thus cyclic models fall into mode collapse accompanied by the success of discriminator. To address this problem, we propose an novel Bayesian cyclic model and an integrated cyclic framework for interdomain mappings. The proposed method motivated by Bayesian GAN explores the full posteriors of cyclic model via sampling latent variables and optimizes the model with maximum a posteriori (MAP) estimation. Hence, we name it Bayesian CycleGAN. In addition, original CycleGAN cannot generate diversified results. But it is feasible for Bayesian framework to diversify generated images by replacing restricted latent variables in inference process. We evaluate the proposed Bayesian CycleGAN on multiple benchmark data sets, including Cityscapes, Maps, and Monet2photo. The proposed method improve the per-pixel accuracy by 15% for the Cityscapes semantic segmentation task within origin framework and improve 20% within the proposed integrated framework, showing better resilience to imbalance confrontation. The diversified results of Monet2Photo style transfer also demonstrate its superiority over original cyclic model. We provide codes for all of our experiments in https://github.com/ranery/Bayesian-CycleGAN.",
      "authors": [
        "Haoran You",
        "Yu Cheng",
        "Tianheng Cheng",
        "Chun-Liang Li",
        "Pan Zhou"
      ],
      "year": 2018,
      "citation_count": 23,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/1ea136c958425ddd113e48eebdd07865ebf3a745",
      "pdf_link": "",
      "venue": "IEEE Transactions on Neural Networks and Learning Systems",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "7564221c59886c6411b6fa474852d8012908cbfa",
      "title": "DuelGAN: A Duel Between Two Discriminators Stabilizes the GAN Training",
      "abstract": "In this paper, we introduce DuelGAN, a generative adversarial network (GAN) solution to improve the stability of the generated samples and to mitigate mode collapse. Built upon the Vanilla GAN's two-player game between the discriminator $D_1$ and the generator $G$, we introduce a peer discriminator $D_2$ to the min-max game. Similar to previous work using two discriminators, the first role of both $D_1$, $D_2$ is to distinguish between generated samples and real ones, while the generator tries to generate high-quality samples which are able to fool both discriminators. Different from existing methods, we introduce another game between $D_1$ and $D_2$ to discourage their agreement and therefore increase the level of diversity of the generated samples. This property alleviates the issue of early mode collapse by preventing $D_1$ and $D_2$ from converging too fast. We provide theoretical analysis for the equilibrium of the min-max game formed among $G, D_1, D_2$. We offer convergence behavior of DuelGAN as well as stability of the min-max game. It's worth mentioning that DuelGAN operates in the unsupervised setting, and the duel between $D_1$ and $D_2$ does not need any label supervision. Experiments results on a synthetic dataset and on real-world image datasets (MNIST, Fashion MNIST, CIFAR-10, STL-10, CelebA, VGG, and FFHQ) demonstrate that DuelGAN outperforms competitive baseline work in generating diverse and high-quality samples, while only introduces negligible computation cost.",
      "authors": [
        "Jiaheng Wei",
        "Minghao Liu",
        "Jiahao Luo",
        "Andrew Zhu",
        "James Davis",
        "Yang Liu"
      ],
      "year": 2021,
      "citation_count": 13,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/7564221c59886c6411b6fa474852d8012908cbfa",
      "pdf_link": "",
      "venue": "European Conference on Computer Vision",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "44d1a62a864ee8a41f0477529ec0662758d4be74",
      "title": "Autoencoding Generative Adversarial Networks",
      "abstract": "In the years since Goodfellow et al. introduced Generative Adversarial Networks (GANs), there has been an explosion in the breadth and quality of generative model applications. Despite this work, GANs still have a long way to go before they see mainstream adoption, owing largely to their infamous training instability. Here I propose the Autoencoding Generative Adversarial Network (AEGAN), a four-network model which learns a bijective mapping between a specified latent space and a given sample space by applying an adversarial loss and a reconstruction loss to both the generated images and the generated latent vectors. The AEGAN technique offers several improvements to typical GAN training, including training stabilization, mode-collapse prevention, and permitting the direct interpolation between real samples. The effectiveness of the technique is illustrated using an anime face dataset.",
      "authors": [
        "Conor Lazarou"
      ],
      "year": 2020,
      "citation_count": 16,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/44d1a62a864ee8a41f0477529ec0662758d4be74",
      "pdf_link": "",
      "venue": "arXiv.org",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "01e9750abbaca78cecbb33cbb7aebfd7a5de91f0",
      "title": "TWGAN: Twin Discriminator Generative Adversarial Networks",
      "abstract": "Generative Adversarial Networks (GAN) has become more and more popular these years. However, it is difficult to train and suffers from the training instability problem. To tackle this difficulty, this paper proposes a novel approach. Our idea is intuitive but proven to be very useful. In essence, it combines saturating loss and non-saturating loss into the loss function. Thus it will exploit the complementary statistical properties from two kinds of loss functions to effectively improve the training stability. We term our method twin discriminator Generative Adversarial Networks (TWGAN), which, unlike GAN, has a generator and a twin discriminator. The twin discriminator consists of two discriminators with identical architecture and both of them aim to distinguish whether the samples are from real data or fake data. We develop theoretical analysis to show that, given the optimal discriminators, optimizing the generator of TWGAN reduces to minimizing the Kullback-Leibler (KL) divergence between the distribution of generated data (<inline-formula><tex-math notation=\"LaTeX\">$P_g$</tex-math></inline-formula>) and the distribution of real data (<inline-formula><tex-math notation=\"LaTeX\">$P_data$</tex-math></inline-formula>), hence effectively addressing the training instability problem. Extensive experiments on MNIST, Fashion MNIST, CIFAR-10/100 and STL-10 datasets demonstrate that the competitive performance of our TWGAN in generating good quality and diverse samples over baselines. The obtained highest inception score (IS) and lowest Fr <inline-formula><tex-math notation=\"LaTeX\">$\\acute{e}$</tex-math></inline-formula> chet Inception Distance (FID), compared with other state-of-the-art GANs, show the superiority of our TWGAN.",
      "authors": [
        "Zhaoyu Zhang",
        "Mengyan Li",
        "Haonian Xie",
        "Jun Yu",
        "Tongliang Liu",
        "Chang Wen Chen"
      ],
      "year": 2021,
      "citation_count": 12,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/01e9750abbaca78cecbb33cbb7aebfd7a5de91f0",
      "pdf_link": "",
      "venue": "IEEE transactions on multimedia",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "284d6ebdd626885c857c096a2d564092b6c28b93",
      "title": "Image Inpainting Based on Generative Adversarial Networks",
      "abstract": "Image inpainting aims to fill missing regions of a damaged image with plausibly synthesized content. Existing methods for image inpainting either fill the missing regions by borrowing information from surrounding areas or generating semantically coherent content from region context. They often produce ambiguous or semantically incoherent content when the missing region is large or with complex structures. In this paper, we present an approach for image inpainting. The completion model based on our proposed algorithm contains one generator, one global discriminator, and one local discriminator. The generator is responsible for inpainting the missing area, the global discriminator aims evaluating whether the repair result has global consistency, and the local discriminator is responsible for identifying whether the repair area is correct. The architecture of the generator is an auto-encoder. We use the skip-connection in the generator to improve the prediction power of the model. Also, we use Wasserstein GAN loss to ensure the stability of training. Experiments on CelebA dataset and LFW dataset demonstrate that our proposed model can deal with large-scale missing pixels and generate realistic completion results.",
      "authors": [
        "Yi Jiang",
        "Jiajie Xu",
        "Baoqing Yang",
        "Jing Xu",
        "Junwu Zhu"
      ],
      "year": 2020,
      "citation_count": 15,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/284d6ebdd626885c857c096a2d564092b6c28b93",
      "pdf_link": "",
      "venue": "IEEE Access",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "627d4f69b76bb3fc88283de9e8e9f7ee6c598ea7",
      "title": "Generative Adversarial Networks for Unsupervised Fault Detection",
      "abstract": "Fault detection is an important and demanding problem in industry. However, in many applications, abnormal data are difficult to be collected and are not available during training. In this paper, we propose a one class fault detection scheme, based on the unsupervised training of a Generative Adversarial Network (GAN). The generator tries to learn the manifold of normal behavior of the process, while the final decision of fault occurrence is taken from the discriminator. The network architectures of the discriminator and the generator and the hyper-parameters, that are used during training, are crucial for the stability of the GAN model. To ensure system convergence during training and to enhance the accuracy of the unsupervised classifier, a model selection algorithm is used. The latter one evaluates each trained model on a validation set of the normal training dataset, based on a proposed performance metric. Also, a method for evaluating the generating ability of each trained generative model is introduced, based on the reconstruction cost of an Autoencoder (AE). The proposed evaluation method of generative models, is used on the search algorithm, which selects the final classifier model. Finally, the proposed system is tested and compared with One-class SVM (OCSVM) on the industrial benchmark of Tennessee Eastman (TE) process with satisfactory results.",
      "authors": [
        "Spyridon Plakias",
        "Y. Boutalis"
      ],
      "year": 2018,
      "citation_count": 20,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/627d4f69b76bb3fc88283de9e8e9f7ee6c598ea7",
      "pdf_link": "",
      "venue": "European Control Conference",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "7281ed8e5c3ef03dde6bbf4bf5df247f00182311",
      "title": "Constrained Generative Adversarial Networks",
      "abstract": "Generative Adversarial Networks (GANs) are a powerful subclass of generative models. Yet, how to effectively train them to reach Nash equilibrium is a challenge. A number of experiments have indicated that one possible solution is to bound the function space of the discriminator. In practice, when optimizing the standard loss function without limiting the discriminator’s output, the discriminator may suffer from lack of convergence. To be able to reach the Nash equilibrium in a faster way during training and obtain better generative data, we propose constrained generative adversarial networks, GAN-C, where a constraint on the discriminator’s output is introduced. We theoretically prove that our proposed loss function shares the same Nash equilibrium as the standard one, and our experiments on mixture of Gaussians, MNIST, CIFAR-10, STL-10, FFHQ, and CAT datasets show that our loss function can better stabilize training and yield even better high-quality images.",
      "authors": [
        "Xiaopeng Chao",
        "Jiangzhong Cao",
        "Yuqin Lu",
        "Qingyun Dai",
        "Shangsong Liang"
      ],
      "year": 2021,
      "citation_count": 11,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/7281ed8e5c3ef03dde6bbf4bf5df247f00182311",
      "pdf_link": "",
      "venue": "IEEE Access",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "9f074217d51ffb0da3b9716af4adae56215de488",
      "title": "Improving GAN Training via Binarized Representation Entropy (BRE) Regularization",
      "abstract": "We propose a novel regularizer to improve the training of Generative Adversarial Networks (GANs). The motivation is that when the discriminator D spreads out its model capacity in the right way, the learning signals given to the generator G are more informative and diverse. These in turn help G to explore better and discover the real data manifold while avoiding large unstable jumps due to the erroneous extrapolation made by D. Our regularizer guides the rectifier discriminator D to better allocate its model capacity, by encouraging the binary activation patterns on selected internal layers of D to have a high joint entropy. Experimental results on both synthetic data and real datasets demonstrate improvements in stability and convergence speed of the GAN training, as well as higher sample quality. The approach also leads to higher classification accuracies in semi-supervised learning.",
      "authors": [
        "Yanshuai Cao",
        "G. Ding",
        "Kry Yik-Chau Lui",
        "Ruitong Huang"
      ],
      "year": 2018,
      "citation_count": 19,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/9f074217d51ffb0da3b9716af4adae56215de488",
      "pdf_link": "",
      "venue": "International Conference on Learning Representations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "b81957019c4e323552e0113da78a7611c160651e",
      "title": "A Semi-Supervised Wasserstein Generative Adversarial Network for Classifying Driving Fatigue from EEG signals",
      "abstract": "Predicting driver’s cognitive states using deep learning from electroencephalography (EEG) signals is considered this paper. To address the challenge posed by limited labeled training samples, a semi-supervised Wasserstein Generative Adversarial Network with gradient penalty (sWGAN-GP) is proposed. The proposed sWGAN-GP includes a classifier with the shared architecture with the discriminator in GAN and its loss function enables the augmentation of limited training samples with generated EEG samples during training, thus resulting in improved classification performance. The several modeling challenges including frequency artifacts and training instability, are also considered. The test results on predicting the alert and drowsy states from a simulated driving experiment demonstrate improved prediction performance and training stability over the baseline semi-supervised GAN and a convolutional neural network model.",
      "authors": [
        "Sharaj Panwar",
        "P. Rad",
        "J. Quarles",
        "E. Golob",
        "Yufei Huang"
      ],
      "year": 2019,
      "citation_count": 15,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/b81957019c4e323552e0113da78a7611c160651e",
      "pdf_link": "",
      "venue": "IEEE International Conference on Systems, Man and Cybernetics",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "14b1c76014eeabc8a2d56a7b06cc39d95981de75",
      "title": "Augmenting Seismic Data Using Generative Adversarial Network for Low-Cost MEMS Sensors",
      "abstract": "The performance of a deep learning (DL) model depends on sufficient training datasets and its algorithmic structure. Even though seismological research using low-cost micro-electro-mechanical systems (MEMS) sensor received much attention recently, because of the lack of data recorded by such MEMS sensors whose data are usually polluted by different types of noise. Therefore, increasing seismic datasets is required by intelligently generating seismic data through data-augmentation techniques. However, it is difficult to characterize and measure the evolution process of seismic sequences, making the feature extraction and data generation of seismic sequences still a significant challenge. By combining the framework of Generative Adversarial Network (GAN) with long short-term memory (LSTM), attention mechanism and neural network (NN), a novel deep generation model (DGM) named EQGAN is developed to overcome the challenges, which can automatically capture the different time histories and dimension characteristics of seismic sequences, meanwhile stably generating high-quality seismic data. The reality of generated data is qualitatively clarified through the analysis of frequency domain and data autocorrelation distribution. Based on the High-throughput Screening (HTS) Theory, the quantitative evaluation index of statistical metrics is designed, and the generation performance of different machine learning models (standard GAN, LSTM, NN) is compared to prove the stability and effectiveness of EQGAN. The experimental results denote that the EQGAN has excellent stability and performance (up to 81%, much higher than that of other generation models), which provides a suitable data expansion approach for the field of seismological research.",
      "authors": [
        "Aming Wu",
        "Juyong Shin",
        "Jae-Kwang Ahn",
        "Young-Woo Kwon"
      ],
      "year": 2021,
      "citation_count": 10,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/14b1c76014eeabc8a2d56a7b06cc39d95981de75",
      "pdf_link": "",
      "venue": "IEEE Access",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "1ad242cd529f848252a244bb0e9c01480520cfd5",
      "title": "Defect Detection with Generative Adversarial Networks for Electroluminescence Images of Solar Cells",
      "abstract": "Solar cells are the core module of photovoltaic (PV) modules. Defects will decrease the power efficiency of solar cells and reduce the stability of PV power systems. Electroluminescence (EL) imaging is able to image solar modules with higher resolution so that defects can be better detected. The current manual detection of EL images is slow and requires relevant expertise, so methods based on computer vision for automatic detection in EL images are appearing. However, due to the heterogeneously background of the EL images and the lack of defect samples, automatic detection of defects has been a challenging task. We design a model based on generative adversarial networks (GAN) and auto-encoder (AE) to perform defect detection for EL images of solar cells. It only requires normal images in the training process and detect defects by measuring the residuals between the test image and the constructed image generated by the generator. To reduce the effects of image distortion, we combine structural similarity index (SSIM) with feature residuals to train the encoder, which can get better results than the model using typical mean square error (MSE). During the detection phase, SSIM and MSE are combined as the anomaly score. Our method has higher recognition of defective EL images and achieves detection accuracy of 90.0% on the test set. Compared with the method using only MSE, the F1 score is increased obviously.",
      "authors": [
        "Chunhui Shou",
        "Ling Hong",
        "Waner Ding",
        "Qu Shen",
        "W. Zhou",
        "Yu Jiang",
        "Chunhui Zhao"
      ],
      "year": 2020,
      "citation_count": 12,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/1ad242cd529f848252a244bb0e9c01480520cfd5",
      "pdf_link": "",
      "venue": "Youth Academic Annual Conference of Chinese Association of Automation",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "8c5bae51a1292767c13b5fed339ea94dc971ff9b",
      "title": "Adaptive Weighted Discriminator for Training Generative Adversarial Networks",
      "abstract": "Generative adversarial network (GAN) has become one of the most important neural network models for classical unsupervised machine learning. A variety of discriminator loss functions have been developed to train GAN’s discriminators and they all have a common structure: a sum of real and fake losses that only depends on the actual and generated data respectively. One challenge associated with an equally weighted sum of two losses is that the training may benefit one loss but harm the other, which we show causes instability and mode collapse. In this paper, we introduce a new family of discriminator loss functions that adopts a weighted sum of real and fake parts, which we call adaptive weighted loss functions or aw-loss functions. Using the gradients of the real and fake parts of the loss, we can adaptively choose weights to train a discriminator in the direction that benefits the GAN’s stability. Our method can be potentially applied to any discriminator model with a loss that is a sum of the real and fake parts. Experiments validated the effectiveness of our loss functions on unconditional and conditional image generation tasks, improving the baseline results by a significant margin on CIFAR-10, STL-10, and CIFAR-100 datasets in Inception Scores (IS) and Fréchet Inception Distance (FID) metrics.",
      "authors": [
        "Vasily Zadorozhnyy",
        "Q. Cheng",
        "Q. Ye"
      ],
      "year": 2020,
      "citation_count": 10,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/8c5bae51a1292767c13b5fed339ea94dc971ff9b",
      "pdf_link": "",
      "venue": "Computer Vision and Pattern Recognition",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "6d94348f7f752cfd095fb9aedaef7ad00ba8c5e3",
      "title": "Inverse Estimation of Elastic Modulus Using Physics-Informed Generative Adversarial Networks",
      "abstract": "While standard generative adversarial networks (GANs) rely solely on training data to learn unknown probability distributions, physics-informed GANs (PI-GANs) encode physical laws in the form of stochastic partial differential equations (PDEs) using auto differentiation. By relating observed data to unobserved quantities of interest through PDEs, PI-GANs allow for the estimation of underlying probability distributions without their direct measurement (i.e. inverse problems). The scalable nature of GANs allows high-dimensional, spatially-dependent probability distributions (i.e., random fields) to be inferred, while incorporating prior information through PDEs allows the training datasets to be relatively small. \nIn this work, PI-GANs are demonstrated for the application of elastic modulus estimation in mechanical testing. Given measured deformation data, the underlying probability distribution of spatially-varying elastic modulus (stiffness) is learned. Two feed-forward deep neural network generators are used to model the deformation and material stiffness across a two dimensional domain. Wasserstein GANs with gradient penalty are employed for enhanced stability. In the absence of explicit training data, it is demonstrated that the PI-GAN learns to generate realistic, physically-admissible realizations of material stiffness by incorporating the PDE that relates it to the measured deformation. It is shown that the statistics (mean, standard deviation, point-wise distributions, correlation length) of these generated stiffness samples have good agreement with the true distribution.",
      "authors": [
        "J. Warner",
        "Julian Cuevas",
        "G. Bomarito",
        "P. Leser",
        "W. Leser"
      ],
      "year": 2020,
      "citation_count": 10,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/6d94348f7f752cfd095fb9aedaef7ad00ba8c5e3",
      "pdf_link": "",
      "venue": "arXiv.org",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "142c254eb3c3ff50b82beeb0e2de5c8d7393f922",
      "title": "Polyphonic Music Generation with Sequence Generative Adversarial Networks",
      "abstract": "We propose an application of sequence generative adversarial networks (SeqGAN), which are generative adversarial networks for discrete sequence generation, for creating polyphonic musical sequences. Instead of a monophonic melody generation suggested in the original work, we present an efficient representation of a polyphony MIDI file that simultaneously captures chords and melodies with dynamic timings. The proposed method condenses duration, octaves, and keys of both melodies and chords into a single word vector representation, and recurrent neural networks learn to predict distributions of sequences from the embedded musical word space. We experiment with the original method and the least squares method to the discriminator, which is known to stabilize the training of GANs. The network can create sequences that are musically coherent and shows an improved quantitative and qualitative measures. We also report that careful optimization of reinforcement learning signals of the model is crucial for general application of the model.",
      "authors": [
        "Sang-gil Lee",
        "Uiwon Hwang",
        "Seonwoo Min",
        "Sungroh Yoon"
      ],
      "year": 2017,
      "citation_count": 14,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/142c254eb3c3ff50b82beeb0e2de5c8d7393f922",
      "pdf_link": "",
      "venue": "Journal of KIISE",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "466f2700541252556dea82ec3ba625c6e7a61c29",
      "title": "Understanding and Stabilizing GANs' Training Dynamics with Control Theory",
      "abstract": "Generative adversarial networks (GANs) are effective in generating realistic images but the training is often unstable. There are existing efforts that model the training dynamics of GANs in the parameter space but the analysis cannot directly motivate practically effective stabilizing methods. To this end, we present a conceptually novel perspective from control theory to directly model the dynamics of GANs in the function space and provide simple yet effective methods to stabilize GANs' training. We first analyze the training dynamic of a prototypical Dirac GAN and adopt the widely-used closed-loop control (CLC) to improve its stability. We then extend CLC to stabilize the training dynamic of normal GANs, where CLC is implemented as a squared $L2$ regularizer on the output of the discriminator. Empirical results show that our method can effectively stabilize the training and obtain state-of-the-art performance on data generation tasks.",
      "authors": [
        "Kun Xu",
        "Chongxuan Li",
        "Huanshu Wei",
        "Jun Zhu",
        "Bo Zhang"
      ],
      "year": 2019,
      "citation_count": 10,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/466f2700541252556dea82ec3ba625c6e7a61c29",
      "pdf_link": "",
      "venue": "arXiv.org",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "9f1c57e9807835eba3d6b7991e8b371e9df5ec77",
      "title": "Robust generative adversarial network",
      "abstract": "Generative Adversarial Networks (GANs) are one of the most popular and powerful models to learn the complex high dimensional distributions. However, they usually suffer from instability and generalization issues which may lead to poor generations. Most existing works focus on stabilizing the training for the discriminators of GANs while ignoring their generalization issue. In this work, we aim to improve the generalization capability of GANs by promoting the local robustness within the small neighborhood of the training samples. We prove that the robustness in the small neighborhood of the training sets can lead to better generalization. Particularly, we design a new robust method called Robust Generative Adversarial Network (RGAN) in which the generator and discriminator compete with each other in a worst-case setting within a small Wasserstein ball. The generator tries to map the worst input distribution (rather than a Gaussian distribution used in most GANs) to the real data distribution, while the discriminator attempts to distinguish the real and fake distributions with the worst perturbations . Intuitively, the proposed RGAN can learn a good generator and discriminator that can even perform well on the worst-case input points. Strictly, we have proved that RGAN can obtain a tighter generalization upper bound than the traditional GANs under mild assumptions, ensuring a theoretical superiority of RGAN over GANs. We conduct our proposed method on five different baselines (five popular GAN models). And a series of experiments on CIFAR-10, STL-10 and CelebA datasets indicate that our proposed robust frameworks outperform five baseline models substantially and consistently.",
      "authors": [
        "Shufei Zhang",
        "Zhuang Qian",
        "Kaizhu Huang",
        "Jimin Xiao",
        "Yuan He"
      ],
      "year": 2019,
      "citation_count": 10,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/9f1c57e9807835eba3d6b7991e8b371e9df5ec77",
      "pdf_link": "",
      "venue": "Machine-mediated learning",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "dd8254e104ddc7f2fa80f3baaa8537780aa2f65c",
      "title": "GPR-GAN: A Ground-Penetrating Radar Data Generative Adversarial Network",
      "abstract": "Deep learning (DL) has gained traction in ground-penetrating radar (GPR) tasks. However, obtaining sufficient training data presents a significant challenge. We introduce a structure-adaptive GPR-generative adversarial network (GAN) to generate GPR defect data. GPR-GAN employs double normalization for stabilizing parameters and convolution outputs, an adaptive discriminator augmentation (ADA) module for small dataset training stability, and a modified self-attention (MSA) module to generate GPR defects with complex features. We evaluated the performance of GPR-GAN using three datasets in conjunction with three state-of-the-art detection networks (faster region-based convolutional neural network (FasterRCNN), single-shot multibox detector (SSD), and YOLOv5). Our results reveal that GPR-GAN exhibits strong generalization skills, adeptly adapting to GPR data generation tasks that encompasses a variety of targets, frequencies, and equipment. GPR-GAN generated data increased the <inline-formula> <tex-math notation=\"LaTeX\">$F1$ </tex-math></inline-formula> score for void recognition in simulation data by at least 5.27%, improved the average <inline-formula> <tex-math notation=\"LaTeX\">$F1$ </tex-math></inline-formula> score for highway pavement defect detection by at least 7.68%, and enhanced the average <inline-formula> <tex-math notation=\"LaTeX\">$F1$ </tex-math></inline-formula> score for railway subgrade defect detection by at least 9.22%. GPR-GAN offers a powerful data support tool for DL research in GPR.",
      "authors": [
        "Hongqiang Xiong",
        "Jing Li",
        "Zhilian Li",
        "Zhiyu Zhang"
      ],
      "year": 2024,
      "citation_count": 36,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/dd8254e104ddc7f2fa80f3baaa8537780aa2f65c",
      "pdf_link": "",
      "venue": "IEEE Transactions on Geoscience and Remote Sensing",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "71a373b66f3c48c49901183d2df269e2fee78c44",
      "title": "Evolutionary Architecture Search for Generative Adversarial Networks Based on Weight Sharing",
      "abstract": "Generative adversarial networks (GANs) are a powerful generative technique but frequently face challenges with training stability. Network architecture plays a significant role in determining the final output of GANs, but designing a fine architecture demands extensive domain expertise. This article aims to address this issue by searching for high-performance generator’s architectures through neural architecture search (NAS). The proposed approach, called evolutionary weight sharing GANs (EWSGAN), is based on weight sharing and comprises two steps. First, a supernet of the generator is trained using weight sharing. Second, a multiobjective evolutionary algorithm (MOEA) is employed to identify optimal subnets from the supernet. These subnets inherit weights directly from the supernet for fitness assessment. Two strategies are used to stabilize the training of the generator supernet: 1) a fair single-path sampling strategy and 2) a discarding strategy. Experimental results indicate that the architecture searched by our method achieved a new state-of-the-art among NAS–GAN methods with a Fréchet inception distance (FID) of 9.09 and an inception score (IS) of 8.99 on the CIFAR-10 dataset. It also demonstrates competitive performance on the STL-10 dataset, achieving FID of 21.89 and IS of 10.51.",
      "authors": [
        "Yu Xue",
        "Weinan Tong",
        "Ferrante Neri",
        "Peng Chen",
        "Tao Luo",
        "Liangli Zhen",
        "Xiao Wang"
      ],
      "year": 2024,
      "citation_count": 19,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/71a373b66f3c48c49901183d2df269e2fee78c44",
      "pdf_link": "",
      "venue": "IEEE Transactions on Evolutionary Computation",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "cfbafb898a5fd26324c30eecf384dfdc34521090",
      "title": "Differentiable Architecture Search With Attention Mechanisms for Generative Adversarial Networks",
      "abstract": "Generative adversarial networks (GANs) are machine learning algorithms that can efficiently generate data such as images. Although GANs are very popular, their training usually lacks stability, with the generator and discriminator networks failing to converge during the training process. To address this problem and improve the stability of GANs, in this paper, we automate the design of stable GANs architectures through a novel approach: differentiable architecture search with attention mechanisms for generative adversarial networks (DAMGAN). We construct a generator supernet and search for the optimal generator network within it. We propose incorporating two attention mechanisms between each pair of nodes in the supernet. The first attention mechanism, down attention, selects the optimal candidate operation of each edge in the supernet, while the second attention mechanism, up attention, improves the training stability of the supernet and limits the computational cost of the search by selecting the most important feature maps for the following candidate operations. Experimental results show that the architectures searched by our method obtain a state-of-the-art inception score (IS) of 8.99 and a very competitive Fréchet inception distance (FID) of 10.27 on the CIFAR-10 dataset. Competitive results were also obtained on the STL-10 dataset (IS = 10.35, FID = 22.18). Notably, our search time was only 0.09 GPU days.",
      "authors": [
        "Yu Xue",
        "Kun Chen",
        "Ferrante Neri"
      ],
      "year": 2024,
      "citation_count": 13,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/cfbafb898a5fd26324c30eecf384dfdc34521090",
      "pdf_link": "",
      "venue": "IEEE Transactions on Emerging Topics in Computational Intelligence",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "9d305eb1ff2b48c1e8fd53747983bcdae6ab1753",
      "title": "Generative Adversarial Networks with Learnable Auxiliary Module for Image Synthesis",
      "abstract": "Training generative adversarial networks (GANs) for noise-to-image synthesis is a challenge task, primarily due to the instability of GANs’ training process. One of the key issues is the generator’s sensitivity to input data, which can cause sudden fluctuations in the generator’s loss value with certain inputs. This sensitivity suggests an inadequate ability to resist disturbances in the generator, causing the discriminator’s loss value to oscillate and negatively impacting the discriminator. Then, the negative feedback of discriminator is also not conducive to updating generator’s parameters, leading to suboptimal image generation quality. In response to this challenge, we present an innovative GANs model equipped with a learnable auxiliary module that processes auxiliary noise. The core objective of this module is to enhance the stability of both the generator and discriminator throughout the training process. To achieve this target, we incorporate a learnable auxiliary penalty and an augmented discriminator, designed to control the generator and reinforce the discriminator’s stability, respectively. We further apply our method to the Hinge and LSGANs loss functions, illustrating its efficacy in reducing the instability of both the generator and the discriminator. The tests we conducted on LSUN, CelebA, Market-1501, and Creative Senz3D datasets serve as proof of our method’s ability to improve the training stability and overall performance of the baseline methods.",
      "authors": [
        "Yan Gan",
        "Chenxue Yang",
        "Mao Ye",
        "Renjie Huang",
        "Deqiang Ouyang"
      ],
      "year": 2024,
      "citation_count": 8,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/9d305eb1ff2b48c1e8fd53747983bcdae6ab1753",
      "pdf_link": "",
      "venue": "ACM Trans. Multim. Comput. Commun. Appl.",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "9602146b95175c69ff187a9ee3bfe45fbc01fa1e",
      "title": "EGANS: Evolutionary Generative Adversarial Network Search for Zero-Shot Learning",
      "abstract": "Zero-shot learning (ZSL) aims to recognize the novel classes which cannot be collected for training a prediction model. Accordingly, generative models [e.g., generative adversarial network (GAN)] are typically used to synthesize the visual samples conditioned by the class semantic vectors and achieve remarkable progress for ZSL. However, existing GAN-based generative ZSL methods are based on hand-crafted models, which cannot adapt to various datasets/scenarios and fails to model instability. To alleviate these challenges, we propose evolutionary GAN search (termed EGANS) to automatically design the generative network with good adaptation and stability, enabling reliable visual feature sample synthesis for advancing ZSL. Specifically, we adopt cooperative dual evolution to conduct a neural architecture search (NAS) for both generator and discriminator under a unified evolutionary adversarial framework. EGANS is learned by two stages: 1) evolution generator architecture search and 2) evolution discriminator architecture search. During the evolution generator architecture search, we adopt a many-to-one adversarial training strategy to evolutionarily search for the optimal generator. Then the optimal generator is further applied to search for the optimal discriminator in the evolution discriminator architecture search with a similar evolution search algorithm. Once the optimal generator and discriminator are searched, we entail them into various generative ZSL baselines for ZSL classification. Extensive experiments show that EGANS consistently improve existing generative ZSL methods on the standard CUB, SUN, AWA2 and FLO datasets. The significant performance gains indicate that the evolutionary NAS explores a virgin field in ZSL.",
      "authors": [
        "Shiming Chen",
        "Shuhuang Chen",
        "W. Hou",
        "Weiping Ding",
        "Xinge You"
      ],
      "year": 2023,
      "citation_count": 15,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/9602146b95175c69ff187a9ee3bfe45fbc01fa1e",
      "pdf_link": "",
      "venue": "IEEE Transactions on Evolutionary Computation",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "88cffe6fdf149250c09ae90498431379dd813d3a",
      "title": "MEvo-GAN: A Multi-Scale Evolutionary Generative Adversarial Network for Underwater Image Enhancement",
      "abstract": "Inunderwater imaging, achieving high-quality imagery is essential but challenging due to factors such as wavelength-dependent absorption and complex lighting dynamics. This paper introduces MEvo-GAN, a novel methodology designed to address these challenges by combining generative adversarial networks with genetic algorithms. The key innovation lies in the integration of genetic algorithm principles with multi-scale generator and discriminator structures in Generative Adversarial Networks (GANs). This approach enhances image details and structural integrity while significantly improving training stability. This combination enables more effective exploration and optimization of the solution space, leading to reduced oscillation, mitigated mode collapse, and smoother convergence to high-quality generative outcomes. By analyzing various public datasets in a quantitative and qualitative manner, the results confirm the effectiveness of MEvo-GAN in improving the clarity, color fidelity, and detail accuracy of underwater images. The results of the experiments on the UIEB dataset are remarkable, with MEvo-GAN attaining a Peak Signal-to-Noise Ratio (PSNR) of 21.2758, Structural Similarity Index (SSIM) of 0.8662, and Underwater Color Image Quality Evaluation (UCIQE) of 0.6597.",
      "authors": [
        "Feiran Fu",
        "Peng Liu",
        "Zhen Shao",
        "Jing Xu",
        "Ming Fang"
      ],
      "year": 2024,
      "citation_count": 7,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/88cffe6fdf149250c09ae90498431379dd813d3a",
      "pdf_link": "",
      "venue": "Journal of Marine Science and Engineering",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "94087f564f2fc3760f170c35801df0dc511aecb9",
      "title": "Stabilizing and Improving Training of Generative Adversarial Networks Through Identity Blocks and Modified Loss Function",
      "abstract": "Generative adversarial networks (GANs) are a powerful tool for synthesizing realistic images, but they can be difficult to train and are prone to instability and mode collapse. This paper proposes a new model called Identity Generative Adversarial Network (IGAN) that addresses these issues. This model is based on three modifications to the baseline deep convolutional generative adversarial network (DCGAN). The first change is to add a non-linear identity block to the architecture. This will make it easier for the model to fit complex data types and cut down on the time it takes to train. The second change is to smooth out the standard GAN loss function by using a modified loss function and label smoothing. The third and final change is to use minibatch training to let the model use other examples from the same minibatch as side information to improve the quality and variety of generated images. These changes help to stabilize the training process and improve the model’s performance. The performance of the GAN models is compared using the inception score (IS) and the Fréchet inception distance (FID), which are widely used metrics for evaluating the quality and diversity of generated images. The effectiveness of our approach was tested by comparing an IGAN model with other GAN models on the CelebA and stacked MNIST datasets. Results show that IGAN outperforms all the other models, achieving an IS of 13.95 and an FID of 43.71 after traning for 200 epochs. In addition to demonstrating the improvement in the performance of the IGAN, the instabilities, diversity, and fidelity of the models were investigated. The results showed that the IGAN was able to converge to a distribution of the real data more quickly. Furthermore, the experiments revealed that IGAN is capable of producing more stable and high-quality images. This suggests that IGAN is a promising approach for improving the training and performance of GANs and may have a range of applications in image synthesis and other areas.",
      "authors": [
        "Mohamed Fathallah",
        "Mohamed Sakr",
        "Sherif Eletriby"
      ],
      "year": 2023,
      "citation_count": 12,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/94087f564f2fc3760f170c35801df0dc511aecb9",
      "pdf_link": "",
      "venue": "IEEE Access",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "2a4bcdfb38fd8627b5a1e6161b253ae5b980cfeb",
      "title": "Soft Generative Adversarial Network: Combating Mode Collapse in Generative Adversarial Network Training via Dynamic Borderline Softening Mechanism",
      "abstract": "In this paper, we propose the Soft Generative Adversarial Network (SoftGAN), a strategy that utilizes a dynamic borderline softening mechanism to train Generative Adversarial Networks. This mechanism aims to solve the mode collapse problem and enhance the training stability of the generated outputs. Within the SoftGAN, the objective of the discriminator is to learn a fuzzy concept of real data with a soft borderline between real and generated data. This objective is achieved by balancing the principles of maximum concept coverage and maximum expected entropy of fuzzy concepts. During the early training stage of the SoftGAN, the principle of maximum expected entropy of fuzzy concepts guides the learning process due to the significant divergence between the generated and real data. However, in the final stage of training, the principle of maximum concept coverage dominates as the divergence between the two distributions decreases. The dynamic borderline softening mechanism of the SoftGAN can be likened to a student (the generator) striving to create realistic images, with the tutor (the discriminator) dynamically guiding the student towards the right direction and motivating effective learning. The tutor gives appropriate encouragement or requirements according to abilities of the student at different stages, so as to promote the student to improve themselves better. Our approach offers both theoretical and practical benefits for improving GAN training. We empirically demonstrate the superiority of our SoftGAN approach in addressing mode collapse issues and generating high-quality outputs compared to existing approaches.",
      "authors": [
        "Wei Li",
        "Yongchuan Tang"
      ],
      "year": 2024,
      "citation_count": 5,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/2a4bcdfb38fd8627b5a1e6161b253ae5b980cfeb",
      "pdf_link": "",
      "venue": "Applied Sciences",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "1e98ac158f0fefdefe9d44d9dc95399bee8ecef6",
      "title": "Enhancing capabilities of generative models through VAE-GAN integration: A review",
      "abstract": "Our review explores the integration of Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs), which are pivotal in the realm of generative models. VAEs are renowned for their robust probabilistic foundations and capacity for complex data representation learning, while GANs are celebrated for generating high-fidelity images. Despite their strengths, both models have limitations: VAEs often produce less sharp outputs, and GANs face challenges with training stability. The hybrid VAE-GAN models harness the strengths of both architectures to overcome these limitations, enhancing output quality and diversity. We provide a comprehensive overview of VAEs and GANs technology developments, their integration strategies, and resultant performance improvements. Applications across various fields, such as artistic creation, medical imaging, e-commerce, and video gaming, highlight the transformative potential of these models. However, challenges in model robustness, ethical concerns, and computational demands persist, posing significant hurdles. Future research directions are poised to transform the VAE-GAN landscape significantly. Enhancing training stability remains a priority, with new approaches such as incorporating self-correcting mechanisms into GANs training being tested. Addressing ethical issues is also critical, as policymakers and technologists work together to develop standards that prevent misuse. Moreover, reducing computational costs is fundamental to democratizing access to these technologies. Projects such as the development of MobileNetV2 have made strides in creating more efficient neural network architectures that maintain performance while being less resource-intensive. Further, the exploration of VAE-GAN applications in fields like augmented reality and personalized medicine offers exciting opportunities for growth, as evidenced by recent pilot studies.",
      "authors": [
        "Dongting Cai"
      ],
      "year": 2024,
      "citation_count": 5,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/1e98ac158f0fefdefe9d44d9dc95399bee8ecef6",
      "pdf_link": "",
      "venue": "Applied and Computational Engineering",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "0fe35c17baf4a451ed11981ac518b89abf618278",
      "title": "SUGAN: A Stable U-Net Based Generative Adversarial Network",
      "abstract": "As one of the representative models in the field of image generation, generative adversarial networks (GANs) face a significant challenge: how to make the best trade-off between the quality of generated images and training stability. The U-Net based GAN (U-Net GAN), a recently developed approach, can generate high-quality synthetic images by using a U-Net architecture for the discriminator. However, this model may suffer from severe mode collapse. In this study, a stable U-Net GAN (SUGAN) is proposed to mainly solve this problem. First, a gradient normalization module is introduced to the discriminator of U-Net GAN. This module effectively reduces gradient magnitudes, thereby greatly alleviating the problems of gradient instability and overfitting. As a result, the training stability of the GAN model is improved. Additionally, in order to solve the problem of blurred edges of the generated images, a modified residual network is used in the generator. This modification enhances its ability to capture image details, leading to higher-definition generated images. Extensive experiments conducted on several datasets show that the proposed SUGAN significantly improves over the Inception Score (IS) and Fréchet Inception Distance (FID) metrics compared with several state-of-the-art and classic GANs. The training process of our SUGAN is stable, and the quality and diversity of the generated samples are higher. This clearly demonstrates the effectiveness of our approach for image generation tasks. The source code and trained model of our SUGAN have been publicly released.",
      "authors": [
        "Shijie Cheng",
        "Lingfeng Wang",
        "M. Zhang",
        "Cheng Zeng",
        "Yan Meng"
      ],
      "year": 2023,
      "citation_count": 6,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/0fe35c17baf4a451ed11981ac518b89abf618278",
      "pdf_link": "",
      "venue": "Italian National Conference on Sensors",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "f92e1f06c6f12a287d82ecf06b555b9fcf0b9d99",
      "title": "Dynamics of Fourier Modes in Torus Generative Adversarial Networks",
      "abstract": "Generative Adversarial Networks (GANs) are powerful machine learning models capable of generating fully synthetic samples of a desired phenomenon with a high resolution. Despite their success, the training process of a GAN is highly unstable, and typically, it is necessary to implement several accessory heuristics to the networks to reach acceptable convergence of the model. In this paper, we introduce a novel method to analyze the convergence and stability in the training of generative adversarial networks. For this purpose, we propose to decompose the objective function of the adversary min–max game defining a periodic GAN into its Fourier series. By studying the dynamics of the truncated Fourier series for the continuous alternating gradient descend algorithm, we are able to approximate the real flow and to identify the main features of the convergence of GAN. This approach is confirmed empirically by studying the training flow in a 2-parametric GAN, aiming to generate an unknown exponential distribution. As a by-product, we show that convergent orbits in GANs are small perturbations of periodic orbits so the Nash equillibria are spiral attractors. This theoretically justifies the slow and unstable training observed in GANs.",
      "authors": [
        "Ángel González-Prieto",
        "Alberto Mozo",
        "Edgar Talavera",
        "Sandra Gómez Canaval"
      ],
      "year": 2021,
      "citation_count": 7,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/f92e1f06c6f12a287d82ecf06b555b9fcf0b9d99",
      "pdf_link": "",
      "venue": "Mathematics",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "b0f12decb3b54ad0eec46d7c29385d714cb879f0",
      "title": "Asymmetric Training of Generative Adversarial Network for High Fidelity SAR Image Generation",
      "abstract": "In practical application, the research of synthetic aperture radar (SAR) target recognition has fallen into a bottle-neck due to the lack of samples. Data argumentation methods based on generative adversarial networks (GAN) have received widespread attention in solving this type of few-shot sample problem. However, the generated images suffer from various shortcomings, such as lack of diversity, low signal-to-noise ratio, blur, etc. In this article, the VAE-WGANGP is proposed, which combines GAN and variational autoencoder (VAE) to alleviate these shortcomings. The innovations of this paper are as follows: firstly, the generator of GAN is replaced with VAE, which constructs an asymmetric network ensuring the stability of GAN training; secondly, the asymmetric loss function is composed of four parts, including reconstruction loss, divergence loss, adversarial loss, and gradient penalty. In this way, the problem of gradient explosion or gradient disappearance is alleviated. The experimental results with the MSTAR dataset show that the images generated by the proposed model outperform the advanced technology with many similar deep features and achieve significant improvement in the target recognition accuracy rate.",
      "authors": [
        "Ying Huang",
        "Wenhao Mei",
        "Su Liu",
        "Tangsheng Li"
      ],
      "year": 2022,
      "citation_count": 5,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/b0f12decb3b54ad0eec46d7c29385d714cb879f0",
      "pdf_link": "",
      "venue": "IEEE International Geoscience and Remote Sensing Symposium",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "29bdd183402a94e3cca7531ced412bb427e9285a",
      "title": "iSEGAN: Improved Speech Enhancement Generative Adversarial Networks",
      "abstract": "Popular neural network-based speech enhancement systems operate on the magnitude spectrogram and ignore the phase mismatch between the noisy and clean speech signals. Conditional generative adversarial networks (cGANs) show promise in addressing the phase mismatch problem by directly mapping the raw noisy speech waveform to the underlying clean speech signal. However, stabilizing and training cGAN systems is difficult and they still fall short of the performance achieved by the spectral enhancement approaches. This paper investigates whether different normalization strategies and one-sided label smoothing can further stabilize the cGAN-based speech enhancement model. In addition, we propose incorporating a Gammatone-based auditory filtering layer and a trainable pre-emphasis layer to further improve the performance of the cGAN framework. Simulation results show that the proposed approaches improve the speech enhancement performance of cGAN systems in addition to yielding improved stability and reduced computational effort.",
      "authors": [
        "Deepak Baby"
      ],
      "year": 2020,
      "citation_count": 7,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/29bdd183402a94e3cca7531ced412bb427e9285a",
      "pdf_link": "",
      "venue": "arXiv.org",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "bd8b0558c9d72fa09f849768879777f04599f7d4",
      "title": "Stable parallel training of Wasserstein conditional generative adversarial neural networks",
      "abstract": "We propose a stable, parallel approach to train Wasserstein conditional generative adversarial neural networks (W-CGANs) under the constraint of a fixed computational budget. Differently from previous distributed GANs training techniques, our approach avoids inter-process communications, reduces the risk of mode collapse and enhances scalability by using multiple generators, each one of them concurrently trained on a single data label. The use of the Wasserstein metric also reduces the risk of cycling by stabilizing the training of each generator. We illustrate the approach on the CIFAR10, CIFAR100, and ImageNet1k datasets, three standard benchmark image datasets, maintaining the original resolution of the images for each dataset. Performance is assessed in terms of scalability and final accuracy within a limited fixed computational time and computational resources. To measure accuracy, we use the inception score, the Fréchet inception distance, and image quality. An improvement in inception score and Fréchet inception distance is shown in comparison to previous results obtained by performing the parallel approach on deep convolutional conditional generative adversarial neural networks as well as an improvement of image quality of the new images created by the GANs approach. Weak scaling is attained on both datasets using up to 2000 NVIDIA V100 GPUs on the OLCF supercomputer Summit.",
      "authors": [
        "Massimiliano Lupo Pasini",
        "Junqi Yin"
      ],
      "year": 2021,
      "citation_count": 5,
      "layer": 2,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/bd8b0558c9d72fa09f849768879777f04599f7d4",
      "pdf_link": "",
      "venue": "2021 International Conference on Computational Science and Computational Intelligence (CSCI)",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "6fba827469a0cd3d090ec9898593445783ab484e",
      "title": "A Novel Approach for Intelligent Fault Diagnosis in Bearing With Imbalanced Data Based on Cycle-Consistent GAN",
      "abstract": "The rise of industrial progress has advanced the growth of deep learning (DL)-driven smart fault diagnosis techniques, particularly for condition-based maintenance (CBM). However, the training of these DL methods relies on large dataset, which is unrealistic to collect because fault signal is not practically viable in real case. To address this issue, this article proposes a conditional auxiliary classier cycle-consistent generative adversarial network restrained by Wasserstein distance with gradient penalty (CAC-CycleGAN-WGP). This model can generate superior-quality signals of the minority classes with stability from majority class. In the experimental section, a stacked autoencoder (AE)-based evaluator is proposed to evaluate the quality of these generated sample, and then imbalanced fault diagnosis is conducted at varying balance ratios based on two benchmarked datasets. The outcomes indicate that the proposed approach is adept at generating fault signals, leading to a notable enhancement in fault diagnosis accuracy as the generated samples are added. Additionally, the efficacy of the proposed framework was benchmarked against other commonly employed techniques. Among them, CAC-CycleGAN-WGP stands out with superior performance.",
      "authors": [
        "Wenjie Liao",
        "Like Wu",
        "Shihui Xu",
        "Shigeru Fujimura"
      ],
      "year": 2024,
      "citation_count": 16,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/6fba827469a0cd3d090ec9898593445783ab484e",
      "pdf_link": "",
      "venue": "IEEE Transactions on Instrumentation and Measurement",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "15f5dc4ed2ee1152aea4ee1e042e80f96316377b",
      "title": "A Comparative Analysis Between GAN and Diffusion Models in Image Generation",
      "abstract": "In the field of artificial intelligence, image-generation techniques have been a hotspot for research. Two generative models that have garnered a lot of attention are diffusion models and generative adversarial networks (GANs). This review paper aims to compare and analyze GAN and Diffusion Models in the field of picture generation, as well as to give a thorough discussion of their features, applications, benefits, and drawbacks. Firstly, the work related to the working principle of GAN and diffusion models are introduced, and then their applications and results in image generation are reviewed. By comparing the existing research results, the author find that GAN performs well in generating realistic images but suffers from problems such as pattern collapse and unstable training, while the diffusion model has better stability and controllability. Combining the advantages of the two methods, this paper explores the possible fusion methods and looks forward to the future development direction in the field of image generation. These research results provide important references and insights to further enhance the level and application scope of image generation technology.",
      "authors": [
        "Yingying Peng"
      ],
      "year": 2024,
      "citation_count": 14,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/15f5dc4ed2ee1152aea4ee1e042e80f96316377b",
      "pdf_link": "",
      "venue": "Transactions on Computer Science and Intelligent Systems Research",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "bfb9ec2a6583e6e86716d12f1273e97626bbe5f0",
      "title": "Rolling bearing fault diagnosis in electric motors based on IDIG-GAN under small sample conditions",
      "abstract": "The bearing fault diagnosis based on deep learning algorithms requires a substantial amount of data. However, in practical industrial production, the diagnostic algorithms tend to work ineffectively due to the limitations of samples. Therefore, in this article, we propose an improved method of deep convolutional generative adversarial networks (DCGAN) with discriminator gradient gap regularization (IDIG-GAN), which can effectively solve the problems of unstable training and poor training performance under a small sample dataset. Firstly, the self-attention mechanism is integrated into the DCGAN to capture global information to enhance the generalization capability of the network. Moreover, gradient normalization is applied to the discriminator to address the problem of vanishing gradients in the network. Furthermore, gradient gap regularization is incorporated into the loss function to narrow the gap between the discriminator gradient norms, thereby improving network stability when dealing with small fault datasets. Through training with the improved IDIG-GAN, then the generated samples are used to expand the dataset and construct a fault diagnosis model. By verifying under two bearing datasets, the results demonstrate that the proposed method can generate high-quality samples and effectively enhance the diagnostic capability of the network when working with small datasets.",
      "authors": [
        "Xiangjin Song",
        "Zhicheng Liu",
        "Zhaowei Wang"
      ],
      "year": 2024,
      "citation_count": 8,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/bfb9ec2a6583e6e86716d12f1273e97626bbe5f0",
      "pdf_link": "",
      "venue": "Measurement science and technology",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "70f107e0c675dcac8fd9a4f9a11fd78c1ae8700f",
      "title": "Improved Generative Adversarial Network for Bearing Fault Diagnosis with a Small Number of Data and Unbalanced Data",
      "abstract": "Fault data under real operating conditions are often difficult to collect, making the number of trained fault data small and out of proportion to normal data. Thus, fault diagnosis symmetry (balance) is compromised. This will result in less effective fault diagnosis methods for cases with a small number of data and data imbalances (S&I). We present an innovative solution to overcome this problem, which is composed of two components: data augmentation and fault diagnosis. In the data augmentation section, the S&I dataset is supplemented with a deep convolutional generative adversarial network based on a gradient penalty and Wasserstein distance (WDCGAN-GP), which solve the problems of the generative adversarial network (GAN) being prone to model collapse and the gradient vanishing during the training time. The addition of self-attention allows for a better identification and generation of sample features. Finally, the addition of spectral normalization can stabilize the training of the model. In the fault diagnosis section, fault diagnosis is performed through a convolutional neural network with coordinate attention (CNN-CA). Our experiments conducted on two bearing fault datasets for comparison demonstrate that the proposed method surpasses other comparative approaches in terms of the quality of data augmentation and the accuracy of fault diagnosis. It effectively addresses S&I fault diagnosis challenges.",
      "authors": [
        "Zhaohui Qin",
        "Faguo Huang",
        "Jiafang Pan",
        "Junlin Niu",
        "Haihua Qin"
      ],
      "year": 2024,
      "citation_count": 7,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/70f107e0c675dcac8fd9a4f9a11fd78c1ae8700f",
      "pdf_link": "",
      "venue": "Symmetry",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "3314863efff246ae64bb266dc920ae44afb24674",
      "title": "Adversarial denoising of EEG signals: a comparative analysis of standard GAN and WGAN-GP approaches",
      "abstract": "Introduction Electroencephalography (EEG) signals frequently contain substantial noise and interference, which can obscure clinically and scientifically relevant features. Traditional denoising approaches, such as linear filtering or wavelet thresholding, often struggle with nonlinear or time-varying artifacts. In response, the present study explores a Generative Adversarial Network (GAN) framework to enhance EEG signal quality, focusing on two variants: a conventional GAN model and a Wasserstein GAN with Gradient Penalty (WGAN-GP). Methods Data were obtained from two distinct EEG datasets: a “healthy” set of 64-channel recordings collected during various motor/imagery tasks, and an “unhealthy” set of 18-channel recordings from individuals with orthopedic impairments. Both datasets underwent comprehensive preprocessing, including band-pass filtering (8–30 Hz), channel standardization, and artifact trimming. The training stage involved adversarial learning, in which a generator sought to reconstruct clean EEG signals while a discriminator (or critic in the case of WGAN-GP) attempted to distinguish between real and generated signals. The model evaluation was conducted using quantitative metrics such as signal-to-noise ratio (SNR), peak signal-to-noise ratio (PSNR), correlation coefficient, mutual information, and dynamic time warping (DTW) distance. Results Experimental findings indicate that adversarial learning substantially improves EEG signal fidelity across multiple quantitative metrics. Specifically, WGAN-GP achieved an SNR of up to 14.47 dB (compared to 12.37 dB for the standard GAN) and exhibited greater training stability, as evidenced by consistently lower relative root mean squared error (RRMSE) values. In contrast, the conventional GAN model excelled in preserving finer signal details, reflected in a PSNR of 19.28 dB and a correlation coefficient exceeding 0.90 in several recordings. Both adversarial frameworks outperformed classical wavelet-based thresholding and linear filtering methods, demonstrating superior adaptability to nonlinear distortions and dynamic interference patterns in EEG time-series data. Discussion By systematically comparing standard GAN and WGAN-GP architectures, this study highlights a practical trade-off between aggressive noise suppression and high-fidelity signal reconstruction. The demonstrated improvements in signal quality underscore the promise of adversarially trained models for applications ranging from basic neuroscience research to real-time brain–computer interfaces (BCIs) in clinical or consumer-grade settings. The results further suggest that GAN-based frameworks can be easily scaled to next-generation wireless networks and complex electrophysiological datasets, offering robust and dynamic solutions to long-standing challenges in EEG denoising.",
      "authors": [
        "Imad Eddine Tibermacine",
        "Samuele Russo",
        "Francesco Citeroni",
        "Giuseppe Mancini",
        "Abdelaziz Rabehi",
        "Amal H. Alharbi",
        "El-Sayed M. El-Kenawy",
        "Christian Napoli"
      ],
      "year": 2025,
      "citation_count": 6,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/3314863efff246ae64bb266dc920ae44afb24674",
      "pdf_link": "",
      "venue": "Frontiers in Human Neuroscience",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "d3c97a9cae3cee24a66f42c5800e438290b7a8ea",
      "title": "SpecDiff-GAN: A Spectrally-Shaped Noise Diffusion GAN for Speech and Music Synthesis",
      "abstract": "Generative adversarial network (GAN) models can synthesize high-quality audio signals while ensuring fast sample generation. However, they are difficult to train and are prone to several issues including mode collapse and divergence. In this paper, we introduce SpecDiff-GAN, a neural vocoder based on HiFi-GAN, which was initially devised for speech synthesis from mel spectrogram. In our model, the training stability is enhanced by means of a forward diffusion process which consists in injecting noise from a Gaussian distribution to both real and fake samples before inputting them to the discriminator. We further improve the model by exploiting a spectrally-shaped noise distribution with the aim to make the discriminator's task more challenging. We then show the merits of our proposed model for speech and music synthesis on several datasets. Our experiments confirm that our model compares favorably in audio quality and efficiency compared to several baselines.",
      "authors": [
        "Teysir Baoueb",
        "Haocheng Liu",
        "Mathieu Fontaine",
        "Jonathan Le Roux",
        "G. Richard"
      ],
      "year": 2024,
      "citation_count": 6,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/d3c97a9cae3cee24a66f42c5800e438290b7a8ea",
      "pdf_link": "",
      "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "1f76f23c919c9b4503a9a369c11ef303822646cd",
      "title": "A data-driven approach for the partial reconstruction of individual human molar teeth using generative deep learning",
      "abstract": "Background and objective\nDue to the high prevalence of dental caries, fixed dental restorations are regularly required to restore compromised teeth or replace missing teeth while retaining function and aesthetic appearance. The fabrication of dental restorations, however, remains challenging due to the complexity of the human masticatory system as well as the unique morphology of each individual dentition. Adaptation and reworking are frequently required during the insertion of fixed dental prostheses (FDPs), which increase cost and treatment time. This article proposes a data-driven approach for the partial reconstruction of occlusal surfaces based on a data set that comprises 92 3D mesh files of full dental crown restorations.\n\n\nMethods\nA Generative Adversarial Network (GAN) is considered for the given task in view of its ability to represent extensive data sets in an unsupervised manner with a wide variety of applications. Having demonstrated good capabilities in terms of image quality and training stability, StyleGAN-2 has been chosen as the main network for generating the occlusal surfaces. A 2D projection method is proposed in order to generate 2D representations of the provided 3D tooth data set for integration with the StyleGAN architecture. The reconstruction capabilities of the trained network are demonstrated by means of 4 common inlay types using a Bayesian Image Reconstruction method. This involves pre-processing the data in order to extract the necessary information of the tooth preparations required for the used method as well as the modification of the initial reconstruction loss.\n\n\nResults\nThe reconstruction process yields satisfactory visual and quantitative results for all preparations with a root mean square error (RMSE) ranging from 0.02 mm to 0.18 mm. When compared against a clinical procedure for CAD inlay fabrication, the group of dentists preferred the GAN-based restorations for 3 of the total 4 inlay geometries.\n\n\nConclusions\nThis article shows the effectiveness of the StyleGAN architecture with a downstream optimization process for the reconstruction of 4 different inlay geometries. The independence of the reconstruction process and the initial training of the GAN enables the application of the method for arbitrary inlay geometries without time-consuming retraining of the GAN.",
      "authors": [
        "Alexander Broll",
        "M. Rosentritt",
        "Thomas Schlegl",
        "Markus Goldhacker"
      ],
      "year": 2024,
      "citation_count": 5,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/1f76f23c919c9b4503a9a369c11ef303822646cd",
      "pdf_link": "",
      "venue": "Frontiers Artif. Intell.",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "d38bec69a9ebbf9d57de0baf131e711c7c7fbfb4",
      "title": "WTE-CGAN Based Signal Enhancement for Weak Target Detection",
      "abstract": "In this letter, we provide the target signal enhancement method based on deep learning for weak target detection. First, the proposed method fully considers the nature characteristic of radar complex echoes and exploits the complex-valued neural networks. Then, the architecture of weak target enhancement complex-valued generative adversarial network (WTE-CGAN) is proposed. More specifically, the generator loss function of generative adversarial network (GAN) is modified, which can be used to reflect the difference between the generated target signal by the generator and the label signal. To keep the training stability of the proposed method, a gradient penalty factor is randomly added to every sample, which embodies the loss function of discriminator. Finally, simulation and measured experiments are given to demonstrate the effectiveness of the proposed method compared with other methods, and it has a significant signal enhancement effect on weak targets.",
      "authors": [
        "Yumiao Wang",
        "Chuanfei Zang",
        "Bo Yu",
        "Wenjing Zhao",
        "Xiangrong Wang",
        "Cong'an Xu",
        "Guolong Cui"
      ],
      "year": 2024,
      "citation_count": 5,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/d38bec69a9ebbf9d57de0baf131e711c7c7fbfb4",
      "pdf_link": "",
      "venue": "IEEE Geoscience and Remote Sensing Letters",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "f47efc7762b9025ce17fad7a8ffc81c672362851",
      "title": "Collaborative-GAN: An Approach for Stabilizing the Training Process of Generative Adversarial Network",
      "abstract": "Generative Adversarial Network (GAN) outperforms its peers in the generative models’ family and is widely used to generate realistic samples in various domains. The basic idea of GAN is a competition between two networks called a generator and discriminator. Throughout the training process of GAN, the two networks face various challenges that affect the quality and diversity of the generated samples of GAN. These challenges include training instability and mode collapse problem. Training instability happens due to the variance of the performance between the generator and discriminator. The mode collapse, on the other hand, happens when the generator is stuck to generate diverse samples. One of the promising techniques that might overcome these issues and increase the networks’ performance is transfer learning between discriminators as same as generators. In this regard, the contribution of this paper is fourfold. First, it proposes a novel approach called Collaborative-GAN based on transfer learning to mitigate the training instability and tackle the mode collapse issues. In the proposed approach, the well-performer network transfers its learned weights to the low-performer ones based on a periodical evaluation during the training process. Second, the paper proposes a novel method to evaluate the discriminators’ performance based on a fuzzy inference system. Third, the paper proposes a method to evaluate the generators’ performance based on a series of detected FID scores that measure the diversity of the generated samples every certain intervals during the training process. We apply the proposed approach on two different architectures of GAN, which we called Single-GAN and Dual-GANs. In Single-GAN, the weights are transferred between the identical networks within the same GAN model. In Dual-GANs, on the other hand, the weights are transferred between identical networks across different GAN models. Thus, the paper introduces two types of transfer learning for GANs; inter and intra-transfer learning based on the paradigm of GAN architecture as a fourth contribution. We validate the proposed approach on three different benchmarks representing CelebA, Cifar-10, and Fashion-Mnist. The experimental results indicate that the proposed approach outperforms the state-of-the-art GAN models in terms of FID metric that measures the generated sample diversity. It is worth noting that the proposed approach achieved remarkable FID scores of 11.44, 24.19, and 11.21 on the Fashion-Mnist, Cifar-10, and CelebA datasets respectively.",
      "authors": [
        "Mohammed Megahed",
        "Ammar Mohammed"
      ],
      "year": 2024,
      "citation_count": 4,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/f47efc7762b9025ce17fad7a8ffc81c672362851",
      "pdf_link": "",
      "venue": "IEEE Access",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "a40eff8cfc5fad3870fa6be8aa55f314316013af",
      "title": "Anomaly Detection using Generative Adversarial Networks Reviewing methodological progress and challenges",
      "abstract": "The applications of Generative Adversarial Networks (GANs) are just as diverse as their architectures, problem settings as well as challenges. A key area of research on GANs is anomaly detection where they are most often utilized when only the data of one class is readily available. In this work, we organize, summarize and compare key concepts and challenges of anomaly detection based on GANs. Common problems which have to be investigated to progress the applicability of GANs are identified and discussed. This includes stability and time requirements during training as well as inference, the restriction of the latent space to produce solely data from the normal class distribution, contaminated training data as well as the composition of the resulting anomaly detection score. We discuss the problems using existing work as well as possible (partial) solutions, including related work from similar areas of research such as related generative models or novelty detection. Our findings are also relevant for a variety of closely related generative modeling approaches, such as autoencoders, and are of interest for areas of research tangent to anomaly detection such as image inpainting or image translation.",
      "authors": [
        "Fiete Lüer",
        "Christian Böhm"
      ],
      "year": 2024,
      "citation_count": 4,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/a40eff8cfc5fad3870fa6be8aa55f314316013af",
      "pdf_link": "",
      "venue": "SIGKDD Explorations",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "8ac65e097e13c58825e5dd7b83da911cd37a0d33",
      "title": "Understanding Generative Adversarial Networks (GANs): A Review",
      "abstract": "Generative Adversarial Networks (GANs) is an important breakthrough in artificial intelligence that uses two neural networks, a generator and a discriminator, that work in an adversarial framework. The generator generates synthetic data, while the discriminator evaluates the authenticity of the data. This dynamic interaction forms a minimax game that produces high-quality synthetic data. Since its introduction in 2014 by Ian Goodfellow, GAN has evolved through various innovative architectures, including Vanilla GAN, Conditional GAN (cGAN), Deep Convolutional GAN (DCGAN), CycleGAN, StyleGAN, Wasserstein GAN (WGAN), and BigGAN. Each of these architectures presents a novel approach to address technical challenges such as training stability, data diversification, and result quality. GANs have been widely applied in various sectors. In healthcare, GANs are used to generate synthetic medical images that support diagnostic development without violating patient privacy. In the media and entertainment industry, GANs facilitate the enhancement of image and video resolution, as well as the creation of realistic content. However, the development of GANs faces challenges such as mode collapse, training instability, and inadequate quality evaluation. In addition to technical challenges, GANs raise ethical issues, such as the misuse of the technology for deepfake creation. Legal regulations, detection tools, and public education are important mitigation measures. Future trends suggest that GANs will be increasingly used in text-to-image synthesis, realistic video generation, and integration with multimodal systems to support cross-disciplinary innovation.",
      "authors": [
        "Purwono Purwono",
        "Annastasya Nabila Elsa Wulandari",
        "Alfian Ma’arif",
        "Wael A. Salah"
      ],
      "year": 2025,
      "citation_count": 4,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/8ac65e097e13c58825e5dd7b83da911cd37a0d33",
      "pdf_link": "",
      "venue": "Control Systems and Optimization Letters",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "31a841e28be8f81f1c83b34edc51b350b9000236",
      "title": "A Distributed Conditional Wasserstein Deep Convolutional Relativistic Loss Generative Adversarial Network With Improved Convergence",
      "abstract": "Generative adversarial networks (GANs) excel in diverse applications such as image enhancement, manipulation, and generating images and videos from text. Yet, training GANs with large datasets remains computationally intensive for standalone systems. Synchronization issues between the generator and discriminator lead to unstable training, poor convergence, vanishing, and exploding gradient challenges. In decentralized environments, standalone GANs struggle with distributed data on client machines. Researchers have turned to federated learning (FL) for distributed-GAN (D-GAN) implementations, but efforts often fall short due to training instability and poor synchronization within GAN components. In this study, we present DRL-GAN, a lightweight Wasserstein conditional distributed relativistic loss-GAN designed to overcome existing limitations. DRL-GAN ensures training stability in the face of nonconvex losses by employing a single global generator on the central server and a discriminator per client. Utilizing Wasserstein-1 for relativistic loss computation between real and fake samples, DRL-GAN effectively addresses issues, such as mode collapses, vanishing, and exploding gradients, accommodating both iid and non-iid private data in clients and fostering strong convergence. The absence of a robust conditional distributed-GAN model serves as another motivation for this work. We provide a comprehensive mathematical formulation of DRL-GAN and validate our claims empirically on CIFAR-10, MNIST, EuroSAT, and LSUN-Bedroom datasets.",
      "authors": [
        "Arunava Roy",
        "Dipankar Dasgupta"
      ],
      "year": 2024,
      "citation_count": 4,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/31a841e28be8f81f1c83b34edc51b350b9000236",
      "pdf_link": "",
      "venue": "IEEE Transactions on Artificial Intelligence",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "045884983c01e75cda7d299e0d31530dd4019b69",
      "title": "Least Information Spectral GAN With Time-Series Data Augmentation for Industrial IoT",
      "abstract": "In industrial Internet of Things (IIoT) systems, imbalanced datasets are prevalent because of the relative ease of acquiring normal operational data compared to abnormal or faulty data. An unbalanced distribution of data may lead to a biased learning problem, resulting in performance degradation of deep learning models. Data augmentation approaches based on generative adversarial networks (GAN) have been proposed to mitigate biased learning problems. However, GAN-based approaches constructed solely with convolutional neural networks may be incapable of extracting temporal properties from data. To utilize the temporal properties of data, a novel GAN structure consisting of an embedding network and recurrent neural networks is proposed in this paper. Additionally, in the novel GAN model based on mean-squared error, modified loss and mutual information terms are employed to improve training stability. From simulation results, it is confirmed that classification accuracy can be significantly improved by up to 54% based on the proposed method when compared with conventional fault diagnosis methods.",
      "authors": [
        "Joonho Seon",
        "Seongwoo Lee",
        "Youngghyu Sun",
        "Soohyun Kim",
        "Dong In Kim",
        "Jin Young Kim"
      ],
      "year": 2025,
      "citation_count": 4,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/045884983c01e75cda7d299e0d31530dd4019b69",
      "pdf_link": "",
      "venue": "IEEE Transactions on Emerging Topics in Computational Intelligence",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "a3a910ba06e4d5564ac3763f617f220d8fd4a146",
      "title": "$\\bigcirc\\!\\!\\!\\!\\bigcirc$ CHAIN: Enhancing Generalization in Data-Efficient GANs via LipsCHitz Continuity ConstrAIned Normalization",
      "abstract": "Generative Adversarial Networks (GANs) significantly advanced image generation but their performance heavily depends on abundant training data. In scenarios with limited data, GANs often struggle with discriminator overfitting and unstable training. Batch Normalization (BN), despite being known for enhancing generalization and training stability, has rarely been used in the discriminator of Data-Efficient GANs. Our work addresses this gap by identifying a critical flaw in BN: the tendency for gradient explosion during the centering and scaling steps. To tackle this issue, we present CHAIN (lipsCHitz continuity constrAIned Normalization), which replaces the conventional centering step with zero-mean regularization and integrates a Lips-chitz continuity constraint in the scaling step. CHAIN further enhances GAN training by adaptively interpolating the normalized and unnormalized features, effectively avoiding discriminator overfitting. Our theoretical analyses firmly establishes CHAIN's effectiveness in reducing gradients in latent features and weights, improving stability and generalization in GAN training. Empirical evidence supports our theory. CHAIN achieves state-of-the-art results in data-limited scenarios on CIFAR-10/100, ImageNet, five low-shot and seven high-resolution few-shot image datasets.",
      "authors": [
        "Yao Ni",
        "Piotr Koniusz"
      ],
      "year": 2024,
      "citation_count": 4,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/a3a910ba06e4d5564ac3763f617f220d8fd4a146",
      "pdf_link": "",
      "venue": "Computer Vision and Pattern Recognition",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "df09f8a4dcc9b7b5698afc56a35e66dc099c2429",
      "title": "Generative Adversarial Networks-Based Channel Estimation for Intelligent Reflecting Surface Assisted mmWave MIMO Systems",
      "abstract": "Channel estimation is a challenging task in intelligent reflecting surface (IRS)-assisted communication systems due to the large amount of passive IRS elements. Recently, deep learning (DL) based channel estimation schemes for multiple-input multiple-output (MIMO) communication systems have achieved remarkable success. However, the performance of channel estimation algorithms still needs to be improved. Meanwhile, the loss functions in traditional DL-based methods are not well designed and investigated. In this paper, we propose a generative adversarial network (GAN) variant based channel estimation method to improve the channel estimation accuracy. Specifically, two DL networks are trained adversarially with the received signals as the conditional input to learn an adaptive loss function. Furthermore, the GAN variant can also learn the mapping from the received signals to the real channels. To improve the training stability of GANs, a loss function is proposed to ensure the correct optimization direction of training the generator. To further improve the estimation performance, we investigate the influence of the hyper-parameter of the loss function on the performance of our model. Our extensive simulation results show that the proposed method outperforms traditional DL-based methods and shows great robustness.",
      "authors": [
        "Ming Ye",
        "Cunhua Pan",
        "Yinfei Xu",
        "Chunguo Li"
      ],
      "year": 2024,
      "citation_count": 3,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/df09f8a4dcc9b7b5698afc56a35e66dc099c2429",
      "pdf_link": "",
      "venue": "IEEE Transactions on Cognitive Communications and Networking",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "316fd1658e4ae59cdbeaf5caa03f46d4d32d616d",
      "title": "Melanoma classification using generative adversarial network and proximal policy optimization",
      "abstract": "In oncology, melanoma is a serious concern, often arising from DNA changes caused mainly by ultraviolet radiation. This cancer is known for its aggressive growth, highlighting the necessity of early detection. Our research introduces a novel deep learning framework for melanoma classification, trained and validated using the extensive SIIM‐ISIC Melanoma Classification Challenge‐ISIC‐2020 dataset. The framework features three dilated convolution layers that extract critical feature vectors for classification. A key aspect of our model is incorporating the Off‐policy Proximal Policy Optimization (Off‐policy PPO) algorithm, which effectively handles data imbalance in the training set by rewarding the accurate classification of underrepresented samples. In this framework, the model is visualized as an agent making a series of decisions, where each sample represents a distinct state. Additionally, a Generative Adversarial Network (GAN) augments training data to improve generalizability, paired with a new regularization technique to stabilize GAN training and prevent mode collapse. The model achieved an F‐measure of 91.836% and a geometric mean of 91.920%, surpassing existing models and demonstrating the model's practical utility in clinical environments. These results demonstrate its potential in enhancing early melanoma detection and informing more accurate treatment approaches, significantly advancing in combating this aggressive cancer.",
      "authors": [
        "Xiangui Ju",
        "Chi-Ho Lin",
        "Suan Lee",
        "Sizheng Wei"
      ],
      "year": 2024,
      "citation_count": 3,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/316fd1658e4ae59cdbeaf5caa03f46d4d32d616d",
      "pdf_link": "",
      "venue": "Photochemistry and Photobiology",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "87220aa1684992aba1c48ab72934cfe3a8dd3c59",
      "title": "Distance Regression Enhanced With Temporal Information Fusion and Adversarial Training for Robot-Assisted Endomicroscopy",
      "abstract": "Probe-based confocal laser endomicroscopy (pCLE) has a role in characterising tissue intraoperatively to guide tumour resection during surgery. To capture good quality pCLE data which is important for diagnosis, the probe-tissue contact needs to be maintained within a working range of micrometre scale. This can be achieved through micro-surgical robotic manipulation which requires the automatic estimation of the probe-tissue distance. In this paper, we propose a novel deep regression framework composed of the Deep Regression Generative Adversarial Network (DR-GAN) and a Sequence Attention (SA) module. The aim of DR-GAN is to train the network using an enhanced image-based supervision approach. It extents the standard generator by using a well-defined function for image generation, instead of a learnable decoder. Also, DR-GAN uses a novel learnable neural perceptual loss which combines for the first time spatial and frequency domain features. This effectively suppresses the adverse effects of noise in the pCLE data. To incorporate temporal information, we’ve designed the SA module which is a cross-attention module, enhanced with Radial Basis Function based encoding (SA-RBF). Furthermore, to train the regression framework, we designed a multi-step training mechanism. During inference, the trained network is used to generate data representations which are fused along time in the SA-RBF module to boost the regression stability. Our proposed network advances SOTA networks by addressing the challenge of excessive noise in the pCLE data and enhancing regression stability. It outperforms SOTA networks applied on the pCLE Regression dataset (PRD) in terms of accuracy, data quality and stability.",
      "authors": [
        "Chi Xu",
        "Haozheng Xu",
        "S. Giannarou"
      ],
      "year": 2024,
      "citation_count": 3,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/87220aa1684992aba1c48ab72934cfe3a8dd3c59",
      "pdf_link": "",
      "venue": "IEEE Transactions on Medical Imaging",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "d2b0b0e427f9518be18156dc6025acc5c7d32d0a",
      "title": "A dual GAN with identity blocks and pancreas-inspired loss for renewable energy optimization",
      "abstract": "Integrating energy and solar imagery is essential for electrical engineers in renewable energy prediction, consumption analysis, regression modeling, and fault detection applications. A significant challenge in these areas is the limited availability of high-quality datasets, which can hinder the accuracy of the predictive models. To address this issue, this paper proposes leveraging Generative Adversarial Networks (GANs) to generate synthetic samples for training. Despite their potential, traditional GAN face challenges such as mode collapse, vanishing gradients, and pixel integrity issues. This paper introduces a novel architecture, Penca-GAN, which enhances GANs through three key modifications: (1) dual loss functions to ensure pixel integrity and promote diversity in augmented images, effectively mitigating mode collapse and improving the quality of synthetic data; (2) the integration of an identity block to stabilize training, preserving essential input features and facilitating smoother gradient flow; and (3) a pancreas-inspired metaheuristic loss function that dynamically adapts to variations in training data to maintain pixel coherence and diversity. Extensive experiments on three renewable energy datasets—SKY images, Solar images, and Wind Turbine images—demonstrate the effectiveness of the Penca-GAN architecture. Our comparative analysis revealed that Penca-GAN consistently achieved the lowest Fréchet Inception Distance (FID) scores (164.45 for SKY, 113.54 for Solar, and 109.34 for Wind Turbine), indicating superior image quality compared to other architectures. Additionally, it attains the highest Inception Score (IS) across all datasets, scoring 71.43 for SKY, 87.65 for Solar, and 90.32 for Wind Turbine. Furthermore, the application of Penca-GAN significantly enhanced the fault detection capabilities, achieving accuracy improvements from 85.92 to 90.04% for solar panels and from 86.06 to 90.43% for wind turbines. These results underscore Penca-GAN’s robust performance in generating high-fidelity synthetic images, significantly advancing renewable energy applications, and improving model performance in critical tasks such as fault detection and energy prediction.",
      "authors": [
        "Mostafa Elbaz",
        "Wael Said",
        "G. Mahmoud",
        "H. Marie"
      ],
      "year": 2025,
      "citation_count": 3,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/d2b0b0e427f9518be18156dc6025acc5c7d32d0a",
      "pdf_link": "",
      "venue": "Scientific Reports",
      "paper_type": "",
      "keywords": []
    },
    {
      "id": "50374aab2ed51f528fbaba4cd1c1482c45b843b6",
      "title": "Cyclic Consistent Image Style Transformation: From Model to System",
      "abstract": "Generative Adversarial Networks (GANs) have achieved remarkable success in various tasks, including image generation, editing, and reconstruction, as well as in unsupervised and representation learning. Despite their impressive capabilities, GANs are often plagued by challenges such as unstable training dynamics and limitations in generating complex patterns. To address these challenges, we propose a novel image style transfer method, named C3GAN, which leverages CycleGAN architecture to achieve consistent and stable transformation of image style. In this context, “image style” refers to the distinct visual characteristics or artistic elements, such as the color schemes, textures, and brushstrokes that define the overall appearance of an image. Our method incorporates cyclic consistency, ensuring that the style transformation remains coherent and visually appealing, thus enhancing the training stability and overcoming the generative limitations of traditional GAN models. Additionally, we have developed a robust and efficient image style transfer system by integrating Flask for web development and MySQL for database management. Our system demonstrates superior performance in transferring complex styles compared to existing model-based approaches. This paper presents the development of a comprehensive image style transfer system based on our advanced C3GAN model, effectively addressing the challenges of GANs and expanding application potential in domains such as artistic creation and cinematic special effects.",
      "authors": [
        "Jun Peng",
        "Kaiyi Chen",
        "Yuqing Gong",
        "Tianxiang Zhang",
        "Baohua Su"
      ],
      "year": 2024,
      "citation_count": 3,
      "layer": 3,
      "new_direction": 0,
      "url": "https://www.semanticscholar.org/paper/50374aab2ed51f528fbaba4cd1c1482c45b843b6",
      "pdf_link": "",
      "venue": "Applied Sciences",
      "paper_type": "",
      "keywords": []
    }
  ],
  "edges": [
    {
      "source": "84de7d27e2f6160f634a483e8548c499a2cda7fa",
      "target": "045884983c01e75cda7d299e0d31530dd4019b69",
      "weight": 0.2574455698508033
    },
    {
      "source": "84de7d27e2f6160f634a483e8548c499a2cda7fa",
      "target": "71a373b66f3c48c49901183d2df269e2fee78c44",
      "weight": 0.3245910545990298
    },
    {
      "source": "84de7d27e2f6160f634a483e8548c499a2cda7fa",
      "target": "a3a910ba06e4d5564ac3763f617f220d8fd4a146",
      "weight": 0.3006221988529048
    },
    {
      "source": "84de7d27e2f6160f634a483e8548c499a2cda7fa",
      "target": "a40eff8cfc5fad3870fa6be8aa55f314316013af",
      "weight": 0.0417248255732771
    },
    {
      "source": "84de7d27e2f6160f634a483e8548c499a2cda7fa",
      "target": "9d305eb1ff2b48c1e8fd53747983bcdae6ab1753",
      "weight": 0.28168780560918133
    },
    {
      "source": "84de7d27e2f6160f634a483e8548c499a2cda7fa",
      "target": "70f107e0c675dcac8fd9a4f9a11fd78c1ae8700f",
      "weight": 0.26392234944828746
    },
    {
      "source": "84de7d27e2f6160f634a483e8548c499a2cda7fa",
      "target": "0fe35c17baf4a451ed11981ac518b89abf618278",
      "weight": 0.27502344618957264
    },
    {
      "source": "29858b40a15704398aecdca6bd2820f2fcc99891",
      "target": "1f76f23c919c9b4503a9a369c11ef303822646cd",
      "weight": 0.25814988163431296
    },
    {
      "source": "29858b40a15704398aecdca6bd2820f2fcc99891",
      "target": "a3a910ba06e4d5564ac3763f617f220d8fd4a146",
      "weight": 0.3221837144200937
    },
    {
      "source": "29858b40a15704398aecdca6bd2820f2fcc99891",
      "target": "d3c97a9cae3cee24a66f42c5800e438290b7a8ea",
      "weight": 0.23502586569830844
    },
    {
      "source": "ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921",
      "target": "71a373b66f3c48c49901183d2df269e2fee78c44",
      "weight": 0.22244816342235865
    },
    {
      "source": "670f9d0d8cafaeaeea564c88645b9816b1146cef",
      "target": "a3a910ba06e4d5564ac3763f617f220d8fd4a146",
      "weight": 0.31434182564818847
    },
    {
      "source": "670f9d0d8cafaeaeea564c88645b9816b1146cef",
      "target": "cb2bd9549791520deccadfde221f8ca699675a96",
      "weight": 0.3833562736880223
    },
    {
      "source": "670f9d0d8cafaeaeea564c88645b9816b1146cef",
      "target": "6c4fe31504d47b8547e47267c0cb4efa464f022b",
      "weight": 0.356447335154355
    },
    {
      "source": "670f9d0d8cafaeaeea564c88645b9816b1146cef",
      "target": "29858b40a15704398aecdca6bd2820f2fcc99891",
      "weight": 0.40394892945520255
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "9d305eb1ff2b48c1e8fd53747983bcdae6ab1753",
      "weight": 0.3996646543709006
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "1e3194bf2bdc22a5d1750579a3d2553b61aa4045",
      "weight": 0.25373679790734593
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "7564221c59886c6411b6fa474852d8012908cbfa",
      "weight": 0.26272438780486873
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "8c5bae51a1292767c13b5fed339ea94dc971ff9b",
      "weight": 0.2654313733604533
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "e32e9735b387080492cbf08f85c5e93fcef95b3a",
      "weight": 0.2889397527950865
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "d54d8c402785006faaf5de19e81f04eb484a3aa2",
      "weight": 0.27960039404064063
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "fae3d474c4d7745be06458df0c20bf837a6055ef",
      "weight": 0.2557976817297642
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "13fd8d61a6ea97c70f5154a23611c80203527818",
      "weight": 0.05974588377796752
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "466f2700541252556dea82ec3ba625c6e7a61c29",
      "weight": 0.2790413063497098
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "cd682f085af85526631dc33617ac4aaae7309634",
      "weight": 0.2391805508442961
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "2f12a10172f33523b288269e59211261ca2f6f67",
      "weight": 0.03426335377803547
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "72a6044a0108e0f8f1e68cd70ada46c81a416324",
      "weight": 0.09110676036754596
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "a4d0c0ca6445af0dc2e513c2e3ec5b852a0b5afa",
      "weight": 0.23662976199442454
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "fc62dad5dc03f7b2a6d9b8e7d3934108f4b511f8",
      "weight": 0.3037163852384269
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "142c254eb3c3ff50b82beeb0e2de5c8d7393f922",
      "weight": 0.2615969407441787
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "744fe47157477235032f7bb3777800f9f2f45e52",
      "weight": 0.2714425812868912
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "245f8b05bdd1ac65a09a476440dc4b05ac05d4a0",
      "weight": 0.29974695126603296
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "698d3b667a7f3073eed8368d9daf84f990c24a65",
      "weight": 0.2483385648161281
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "22530627d05baba39628e9d365b2f7fd8e81fe11",
      "weight": 0.2922507186473745
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921",
      "weight": 0.2368387077782052
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "024d30897e0a2b036bc122163a954b7f1a1d0679",
      "weight": 0.2954619172990798
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "94087f564f2fc3760f170c35801df0dc511aecb9",
      "weight": 0.2602657326099928
    },
    {
      "source": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "target": "7281ed8e5c3ef03dde6bbf4bf5df247f00182311",
      "weight": 0.2818498615363888
    },
    {
      "source": "3bf2147008e0bcb5d80298448fc4bf7f5d3c30ea",
      "target": "88cffe6fdf149250c09ae90498431379dd813d3a",
      "weight": 0.3907905663622161
    },
    {
      "source": "024d30897e0a2b036bc122163a954b7f1a1d0679",
      "target": "cb2bd9549791520deccadfde221f8ca699675a96",
      "weight": 0.26762098970917025
    },
    {
      "source": "024d30897e0a2b036bc122163a954b7f1a1d0679",
      "target": "8c5bae51a1292767c13b5fed339ea94dc971ff9b",
      "weight": 0.24418886947115956
    },
    {
      "source": "024d30897e0a2b036bc122163a954b7f1a1d0679",
      "target": "e32e9735b387080492cbf08f85c5e93fcef95b3a",
      "weight": 0.25700696658305533
    },
    {
      "source": "024d30897e0a2b036bc122163a954b7f1a1d0679",
      "target": "d54d8c402785006faaf5de19e81f04eb484a3aa2",
      "weight": 0.2401174610532354
    },
    {
      "source": "024d30897e0a2b036bc122163a954b7f1a1d0679",
      "target": "cd682f085af85526631dc33617ac4aaae7309634",
      "weight": 0.2238077704621914
    },
    {
      "source": "024d30897e0a2b036bc122163a954b7f1a1d0679",
      "target": "72a6044a0108e0f8f1e68cd70ada46c81a416324",
      "weight": 0.041665613266306675
    },
    {
      "source": "024d30897e0a2b036bc122163a954b7f1a1d0679",
      "target": "a4d0c0ca6445af0dc2e513c2e3ec5b852a0b5afa",
      "weight": 0.220084816534414
    },
    {
      "source": "024d30897e0a2b036bc122163a954b7f1a1d0679",
      "target": "245f8b05bdd1ac65a09a476440dc4b05ac05d4a0",
      "weight": 0.25024994917186105
    },
    {
      "source": "024d30897e0a2b036bc122163a954b7f1a1d0679",
      "target": "698d3b667a7f3073eed8368d9daf84f990c24a65",
      "weight": 0.2792834332260524
    },
    {
      "source": "024d30897e0a2b036bc122163a954b7f1a1d0679",
      "target": "ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921",
      "weight": 0.24169895420673
    },
    {
      "source": "024d30897e0a2b036bc122163a954b7f1a1d0679",
      "target": "488bb25e0b1777847f04c943e6dbc4f84415b712",
      "weight": 0.09546191729907978
    },
    {
      "source": "6c4fe31504d47b8547e47267c0cb4efa464f022b",
      "target": "a3a910ba06e4d5564ac3763f617f220d8fd4a146",
      "weight": 0.28505546530315007
    },
    {
      "source": "6c4fe31504d47b8547e47267c0cb4efa464f022b",
      "target": "c9f6ff493aade94a2fd6f4e89201e3d7333aedcb",
      "weight": 0.05211319434493271
    },
    {
      "source": "698d3b667a7f3073eed8368d9daf84f990c24a65",
      "target": "a3a910ba06e4d5564ac3763f617f220d8fd4a146",
      "weight": 0.25655815900218176
    },
    {
      "source": "698d3b667a7f3073eed8368d9daf84f990c24a65",
      "target": "cb2bd9549791520deccadfde221f8ca699675a96",
      "weight": 0.3682555302313338
    },
    {
      "source": "698d3b667a7f3073eed8368d9daf84f990c24a65",
      "target": "f92e1f06c6f12a287d82ecf06b555b9fcf0b9d99",
      "weight": 0.04819234007422476
    },
    {
      "source": "698d3b667a7f3073eed8368d9daf84f990c24a65",
      "target": "bffb2fe8b60d7acd307f28ff04b1f3f486511639",
      "weight": 0.2421337858817753
    },
    {
      "source": "698d3b667a7f3073eed8368d9daf84f990c24a65",
      "target": "4795c82ec752177a2904da44b05231da93d69c4f",
      "weight": 0.22810211330046817
    },
    {
      "source": "698d3b667a7f3073eed8368d9daf84f990c24a65",
      "target": "237729237fde44eb7ab8f35aafb82c9b8a816e44",
      "weight": 0.037886192376920154
    },
    {
      "source": "698d3b667a7f3073eed8368d9daf84f990c24a65",
      "target": "670f9d0d8cafaeaeea564c88645b9816b1146cef",
      "weight": 0.2462338766780824
    },
    {
      "source": "698d3b667a7f3073eed8368d9daf84f990c24a65",
      "target": "f9d11bdadd0a10f9cf74da34796328cb77de134d",
      "weight": 0.308197920109599
    },
    {
      "source": "698d3b667a7f3073eed8368d9daf84f990c24a65",
      "target": "44d1a62a864ee8a41f0477529ec0662758d4be74",
      "weight": 0.05281739667674541
    },
    {
      "source": "698d3b667a7f3073eed8368d9daf84f990c24a65",
      "target": "63470afe06145e08c3b851491450f68c83cc938f",
      "weight": 0.3400227626479817
    },
    {
      "source": "698d3b667a7f3073eed8368d9daf84f990c24a65",
      "target": "13fd8d61a6ea97c70f5154a23611c80203527818",
      "weight": 0.06674751842640562
    },
    {
      "source": "698d3b667a7f3073eed8368d9daf84f990c24a65",
      "target": "9f1c57e9807835eba3d6b7991e8b371e9df5ec77",
      "weight": 0.2609881308853965
    },
    {
      "source": "698d3b667a7f3073eed8368d9daf84f990c24a65",
      "target": "29c53d37cb9bec0210e1584493479df13be85d90",
      "weight": 0.33157516774623386
    },
    {
      "source": "698d3b667a7f3073eed8368d9daf84f990c24a65",
      "target": "a4d0c0ca6445af0dc2e513c2e3ec5b852a0b5afa",
      "weight": 0.23593533321080257
    },
    {
      "source": "698d3b667a7f3073eed8368d9daf84f990c24a65",
      "target": "245f8b05bdd1ac65a09a476440dc4b05ac05d4a0",
      "weight": 0.31155315529819966
    },
    {
      "source": "698d3b667a7f3073eed8368d9daf84f990c24a65",
      "target": "042116e805aa3b5171efaf0c822dc142310ceefe",
      "weight": 0.25504408217494473
    },
    {
      "source": "8b1ba1037aefddec9ce9d07858f661b72a1b41fe",
      "target": "6d94348f7f752cfd095fb9aedaef7ad00ba8c5e3",
      "weight": 0.5013924584831375
    },
    {
      "source": "63470afe06145e08c3b851491450f68c83cc938f",
      "target": "a3a910ba06e4d5564ac3763f617f220d8fd4a146",
      "weight": 0.3232073018682292
    },
    {
      "source": "63470afe06145e08c3b851491450f68c83cc938f",
      "target": "cb2bd9549791520deccadfde221f8ca699675a96",
      "weight": 0.3551533886986724
    },
    {
      "source": "63470afe06145e08c3b851491450f68c83cc938f",
      "target": "7564221c59886c6411b6fa474852d8012908cbfa",
      "weight": 0.2506206002092803
    },
    {
      "source": "63470afe06145e08c3b851491450f68c83cc938f",
      "target": "670f9d0d8cafaeaeea564c88645b9816b1146cef",
      "weight": 0.3714934549318284
    },
    {
      "source": "63470afe06145e08c3b851491450f68c83cc938f",
      "target": "29858b40a15704398aecdca6bd2820f2fcc99891",
      "weight": 0.3084168739808695
    },
    {
      "source": "63470afe06145e08c3b851491450f68c83cc938f",
      "target": "466f2700541252556dea82ec3ba625c6e7a61c29",
      "weight": 0.28445491485975144
    },
    {
      "source": "cb2bd9549791520deccadfde221f8ca699675a96",
      "target": "87220aa1684992aba1c48ab72934cfe3a8dd3c59",
      "weight": 0.040159093421284424
    },
    {
      "source": "cb2bd9549791520deccadfde221f8ca699675a96",
      "target": "a3a910ba06e4d5564ac3763f617f220d8fd4a146",
      "weight": 0.3391413404730178
    },
    {
      "source": "3228c8073f6aae9c287dbeea949fbad68f9d5ba1",
      "target": "6cfb89a73b12caf20dbcdb7c5f6d9a85f02b0730",
      "weight": 0.7401218845715136
    },
    {
      "source": "27e13389203b2f8f6138afed867965a3a38cbd8e",
      "target": "567a5d09647f787a37ce8ac300a221d8c4337688",
      "weight": 0.2920656513174207
    },
    {
      "source": "27e13389203b2f8f6138afed867965a3a38cbd8e",
      "target": "b81957019c4e323552e0113da78a7611c160651e",
      "weight": 0.3850526154322089
    },
    {
      "source": "27e13389203b2f8f6138afed867965a3a38cbd8e",
      "target": "cd682f085af85526631dc33617ac4aaae7309634",
      "weight": 0.26907164238399983
    },
    {
      "source": "237729237fde44eb7ab8f35aafb82c9b8a816e44",
      "target": "cb2bd9549791520deccadfde221f8ca699675a96",
      "weight": 0.2225488165802523
    },
    {
      "source": "042116e805aa3b5171efaf0c822dc142310ceefe",
      "target": "bffb2fe8b60d7acd307f28ff04b1f3f486511639",
      "weight": 0.34568417117117445
    },
    {
      "source": "042116e805aa3b5171efaf0c822dc142310ceefe",
      "target": "d54d8c402785006faaf5de19e81f04eb484a3aa2",
      "weight": 0.25446835487014147
    },
    {
      "source": "042116e805aa3b5171efaf0c822dc142310ceefe",
      "target": "744fe47157477235032f7bb3777800f9f2f45e52",
      "weight": 0.24142497666230356
    },
    {
      "source": "82f766d3c572b4c690b439edab5d32b3ba72852e",
      "target": "a4f020c2339f1cf3595bef233b429f93460f0c0c",
      "weight": 0.25555595036754386
    },
    {
      "source": "29b8b97d554f5139fcf2064ce292204500eee31c",
      "target": "13fd8d61a6ea97c70f5154a23611c80203527818",
      "weight": 0.04381554089074336
    },
    {
      "source": "29b8b97d554f5139fcf2064ce292204500eee31c",
      "target": "6a514c0c8c031bb4e1cc2ae9032780df408442a5",
      "weight": 0.23867049673476182
    },
    {
      "source": "29b8b97d554f5139fcf2064ce292204500eee31c",
      "target": "2f12a10172f33523b288269e59211261ca2f6f67",
      "weight": 0.028351360221663627
    },
    {
      "source": "29b8b97d554f5139fcf2064ce292204500eee31c",
      "target": "fc62dad5dc03f7b2a6d9b8e7d3934108f4b511f8",
      "weight": 0.23692784735802486
    },
    {
      "source": "29b8b97d554f5139fcf2064ce292204500eee31c",
      "target": "245f8b05bdd1ac65a09a476440dc4b05ac05d4a0",
      "weight": 0.28117413512991835
    },
    {
      "source": "a4d0c0ca6445af0dc2e513c2e3ec5b852a0b5afa",
      "target": "045884983c01e75cda7d299e0d31530dd4019b69",
      "weight": 0.22420123235590214
    },
    {
      "source": "a4d0c0ca6445af0dc2e513c2e3ec5b852a0b5afa",
      "target": "9d305eb1ff2b48c1e8fd53747983bcdae6ab1753",
      "weight": 0.2819002804914108
    },
    {
      "source": "a4d0c0ca6445af0dc2e513c2e3ec5b852a0b5afa",
      "target": "cd682f085af85526631dc33617ac4aaae7309634",
      "weight": 0.22060140150663082
    },
    {
      "source": "13fd8d61a6ea97c70f5154a23611c80203527818",
      "target": "7564221c59886c6411b6fa474852d8012908cbfa",
      "weight": 0.2532783862523837
    },
    {
      "source": "e32e9735b387080492cbf08f85c5e93fcef95b3a",
      "target": "32038e56d0174b33a93c66258f346c1a173fe81d",
      "weight": 0.3070809793017353
    },
    {
      "source": "245f8b05bdd1ac65a09a476440dc4b05ac05d4a0",
      "target": "e32e9735b387080492cbf08f85c5e93fcef95b3a",
      "weight": 0.2842307153202132
    },
    {
      "source": "245f8b05bdd1ac65a09a476440dc4b05ac05d4a0",
      "target": "531836a1c3fbbf10eba5375d8558f218cdb9805e",
      "weight": 0.0817680707535126
    },
    {
      "source": "245f8b05bdd1ac65a09a476440dc4b05ac05d4a0",
      "target": "13fd8d61a6ea97c70f5154a23611c80203527818",
      "weight": 0.08162482682072962
    },
    {
      "source": "a0cca4fe677af57d1a8491d698c0d709535c44dd",
      "target": "9602146b95175c69ff187a9ee3bfe45fbc01fa1e",
      "weight": 0.2512249846407758
    },
    {
      "source": "531836a1c3fbbf10eba5375d8558f218cdb9805e",
      "target": "a3a910ba06e4d5564ac3763f617f220d8fd4a146",
      "weight": 0.2538538198267724
    },
    {
      "source": "531836a1c3fbbf10eba5375d8558f218cdb9805e",
      "target": "9d305eb1ff2b48c1e8fd53747983bcdae6ab1753",
      "weight": 0.2586927666935127
    },
    {
      "source": "531836a1c3fbbf10eba5375d8558f218cdb9805e",
      "target": "8c5bae51a1292767c13b5fed339ea94dc971ff9b",
      "weight": 0.24037011183906756
    },
    {
      "source": "531836a1c3fbbf10eba5375d8558f218cdb9805e",
      "target": "0984634505e7b4a8004eaf26416ffedd81cd5861",
      "weight": 0.2691782775585533
    },
    {
      "source": "29c53d37cb9bec0210e1584493479df13be85d90",
      "target": "cb2bd9549791520deccadfde221f8ca699675a96",
      "weight": 0.33559968594425216
    },
    {
      "source": "29c53d37cb9bec0210e1584493479df13be85d90",
      "target": "f9d11bdadd0a10f9cf74da34796328cb77de134d",
      "weight": 0.30353466349773695
    },
    {
      "source": "29c53d37cb9bec0210e1584493479df13be85d90",
      "target": "13fd8d61a6ea97c70f5154a23611c80203527818",
      "weight": 0.0704287399735441
    },
    {
      "source": "22530627d05baba39628e9d365b2f7fd8e81fe11",
      "target": "a3a910ba06e4d5564ac3763f617f220d8fd4a146",
      "weight": 0.39681589031747627
    },
    {
      "source": "22530627d05baba39628e9d365b2f7fd8e81fe11",
      "target": "84de7d27e2f6160f634a483e8548c499a2cda7fa",
      "weight": 0.1183448446533702
    },
    {
      "source": "fae3d474c4d7745be06458df0c20bf837a6055ef",
      "target": "7564221c59886c6411b6fa474852d8012908cbfa",
      "weight": 0.23529733610426612
    },
    {
      "source": "fae3d474c4d7745be06458df0c20bf837a6055ef",
      "target": "0d2818f1070fa5a6cf5d14a87a5d71b4107b4d60",
      "weight": 0.24532719640241357
    },
    {
      "source": "6cfb89a73b12caf20dbcdb7c5f6d9a85f02b0730",
      "target": "045884983c01e75cda7d299e0d31530dd4019b69",
      "weight": 0.4153484221715026
    },
    {
      "source": "32e277b85802685105254430c4170ad2b1a16c04",
      "target": "cb2bd9549791520deccadfde221f8ca699675a96",
      "weight": 0.3222926248674592
    },
    {
      "source": "32e277b85802685105254430c4170ad2b1a16c04",
      "target": "9f1c57e9807835eba3d6b7991e8b371e9df5ec77",
      "weight": 0.3062895503809746
    },
    {
      "source": "32e277b85802685105254430c4170ad2b1a16c04",
      "target": "cd682f085af85526631dc33617ac4aaae7309634",
      "weight": 0.24619513775591634
    },
    {
      "source": "9d4b4b44da22d4afdf127a1e33108f37bf1ec4e4",
      "target": "cfbafb898a5fd26324c30eecf384dfdc34521090",
      "weight": 0.42401413033075364
    },
    {
      "source": "9d4b4b44da22d4afdf127a1e33108f37bf1ec4e4",
      "target": "9602146b95175c69ff187a9ee3bfe45fbc01fa1e",
      "weight": 0.3521722856609316
    },
    {
      "source": "9d4b4b44da22d4afdf127a1e33108f37bf1ec4e4",
      "target": "32038e56d0174b33a93c66258f346c1a173fe81d",
      "weight": 0.33595146062741976
    },
    {
      "source": "ad37850e17ce5ad9ca954ec97c1fe95c31cefc9e",
      "target": "13fd8d61a6ea97c70f5154a23611c80203527818",
      "weight": 0.07626585227305302
    },
    {
      "source": "30831a581be8b76a99ef079f82e3c1b5f8c2dc05",
      "target": "36f7724f28f497d55f720719fb58f1c146ecbc32",
      "weight": 0.3598591855543292
    },
    {
      "source": "fc62dad5dc03f7b2a6d9b8e7d3934108f4b511f8",
      "target": "466f2700541252556dea82ec3ba625c6e7a61c29",
      "weight": 0.23191075768491015
    },
    {
      "source": "fc62dad5dc03f7b2a6d9b8e7d3934108f4b511f8",
      "target": "f47efc7762b9025ce17fad7a8ffc81c672362851",
      "weight": 0.3062180973691969
    },
    {
      "source": "32038e56d0174b33a93c66258f346c1a173fe81d",
      "target": "cfbafb898a5fd26324c30eecf384dfdc34521090",
      "weight": 0.34251396956029323
    },
    {
      "source": "e4abcf52b65969f8fed43eff8f5cc512553b41d0",
      "target": "df09f8a4dcc9b7b5698afc56a35e66dc099c2429",
      "weight": 0.6618992900534604
    },
    {
      "source": "b48b68f52b2ebaa8c7b428e98eafe1953045067f",
      "target": "9602146b95175c69ff187a9ee3bfe45fbc01fa1e",
      "weight": 0.3148125537935294
    },
    {
      "source": "6c01187f5930e9618b05611dca1065b926ed4ab6",
      "target": "b0f12decb3b54ad0eec46d7c29385d714cb879f0",
      "weight": 0.2921726266958933
    },
    {
      "source": "72a6044a0108e0f8f1e68cd70ada46c81a416324",
      "target": "d54d8c402785006faaf5de19e81f04eb484a3aa2",
      "weight": 0.2765739646547284
    },
    {
      "source": "f9d11bdadd0a10f9cf74da34796328cb77de134d",
      "target": "8ac65e097e13c58825e5dd7b83da911cd37a0d33",
      "weight": 0.27741262667653743
    },
    {
      "source": "4136412ac44e9185125246be447d2c06e8676dcc",
      "target": "744fe47157477235032f7bb3777800f9f2f45e52",
      "weight": 0.27464133908231114
    },
    {
      "source": "4136412ac44e9185125246be447d2c06e8676dcc",
      "target": "7281ed8e5c3ef03dde6bbf4bf5df247f00182311",
      "weight": 0.32473737347485876
    },
    {
      "source": "7ece301f8d69674b49c3485af49668ed9f6084c8",
      "target": "a40eff8cfc5fad3870fa6be8aa55f314316013af",
      "weight": 0.32705368773481924
    },
    {
      "source": "2cc9e70cd4664533af9bf34b2da7a1c2694616f8",
      "target": "29c53d37cb9bec0210e1584493479df13be85d90",
      "weight": 0.3716495812445173
    },
    {
      "source": "7564221c59886c6411b6fa474852d8012908cbfa",
      "target": "f47efc7762b9025ce17fad7a8ffc81c672362851",
      "weight": 0.3469693878708876
    },
    {
      "source": "01e9750abbaca78cecbb33cbb7aebfd7a5de91f0",
      "target": "f47efc7762b9025ce17fad7a8ffc81c672362851",
      "weight": 0.3323858461700556
    },
    {
      "source": "627d4f69b76bb3fc88283de9e8e9f7ee6c598ea7",
      "target": "6fba827469a0cd3d090ec9898593445783ab484e",
      "weight": 0.3837032602774625
    },
    {
      "source": "9f074217d51ffb0da3b9716af4adae56215de488",
      "target": "fae3d474c4d7745be06458df0c20bf837a6055ef",
      "weight": 0.2712701918551811
    },
    {
      "source": "9f1c57e9807835eba3d6b7991e8b371e9df5ec77",
      "target": "32038e56d0174b33a93c66258f346c1a173fe81d",
      "weight": 0.3056141696409408
    },
    {
      "source": "94087f564f2fc3760f170c35801df0dc511aecb9",
      "target": "d2b0b0e427f9518be18156dc6025acc5c7d32d0a",
      "weight": 0.35538806652267824
    },
    {
      "source": "94087f564f2fc3760f170c35801df0dc511aecb9",
      "target": "8ac65e097e13c58825e5dd7b83da911cd37a0d33",
      "weight": 0.2841081990025159
    },
    {
      "source": "bd8b0558c9d72fa09f849768879777f04599f7d4",
      "target": "94087f564f2fc3760f170c35801df0dc511aecb9",
      "weight": 0.36575731021725805
    },
    {
      "source": "f47efc7762b9025ce17fad7a8ffc81c672362851",
      "target": "8ac65e097e13c58825e5dd7b83da911cd37a0d33",
      "weight": 0.3435598717643614
    },
    {
      "source": "50374aab2ed51f528fbaba4cd1c1482c45b843b6",
      "target": "8ac65e097e13c58825e5dd7b83da911cd37a0d33",
      "weight": 0.33212982686796033
    }
  ]
}