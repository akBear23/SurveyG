\subsection{Inherent Instabilities: Mode Collapse and Training Divergence}

The initial promise of Generative Adversarial Networks (GANs), as introduced by \cite{Goodfellow2014}, was quickly tempered by a set of pervasive and critical challenges that severely hampered their practical application. Foremost among these were profound training instabilities and the phenomenon of mode collapse, which collectively prevented early GANs from reliably generating diverse and high-quality synthetic data \cite{jabbar2020aj0, wiatrak20194ib, wang2019w53}. Understanding these fundamental problems is crucial for appreciating the necessity and ingenuity behind the stabilization techniques developed subsequently.

At the core of these issues lay the original GAN objective function, which aimed to minimize the Jensen-Shannon (JS) divergence between the real data distribution ($p_{data}$) and the generator's distribution ($p_g$). While theoretically elegant, this objective proved highly problematic in practice. In high-dimensional data spaces, it is common for the real and generated data distributions to be non-overlapping or to lie on disjoint low-dimensional manifolds. In such scenarios, the JS divergence can become saturated, leading to a vanishing gradient problem for the generator \cite{Goodfellow2014}. When the discriminator rapidly learns to perfectly distinguish between real and fake samples, it assigns near-zero probability to generated samples. This provides the generator with a gradient that is effectively zero, offering little to no meaningful learning signal to improve its output. Consequently, the generator's parameters either cease to update, leading to stagnation, or oscillate wildly, resulting in outright non-convergence and training divergence.

Beyond vanishing gradients, the adversarial training process itself, framed as a minimax game, is inherently prone to instability. The non-cooperative nature of the generator and discriminator's objectives can lead to complex and often oscillatory dynamics, where each network's updates undo the progress of the other \cite{gonzlezprieto20214wh, liang2018r52}. This constant chasing of evolving strategies can prevent the system from settling into a stable Nash equilibrium, manifesting as erratic training curves, fluctuating sample quality, and a general inability to converge to a robust solution. Such training divergence is characterized not only by vanishing gradients but also by exploding gradients, where updates become excessively large, further destabilizing the learning process.

A direct and particularly debilitating consequence of these instabilities was mode collapse. This phenomenon occurs when the generator fails to capture the full diversity of the real data distribution, instead producing only a limited set of samples that consistently fool the discriminator \cite{jabbar2020aj0, che2016kho}. Rather than exploring the entire data landscape, the generator finds a few "safe" modes or local optima in the minimax game where it can effectively deceive the current discriminator. For example, if trained on a dataset of diverse animal images, a mode-collapsed GAN might only generate variations of a single animal, such as cats, completely ignoring other categories like dogs or birds. This issue is exacerbated by the vanishing gradient problem, as the generator lacks the necessary signal to venture into unexplored regions of the data distribution. Early research, such as Mode Regularized Generative Adversarial Networks by \cite{che2016kho}, directly acknowledged and attempted to mitigate this problem by introducing regularization techniques to encourage a more uniform distribution of probability mass across data modes, highlighting the immediate recognition of mode collapse as a critical limitation.

These inherent instabilities—vanishing and exploding gradients, oscillatory training, non-convergence, and mode collapse—posed significant barriers to the widespread adoption and practical utility of early GANs. They underscored the need for fundamental advancements beyond the original formulation. While initial empirical "tricks" and architectural guidelines (as discussed in Section \ref{sec:early_heuristics}) offered some practical improvements, the pervasive nature of these problems necessitated more rigorous theoretical and algorithmic solutions. The understanding of these fundamental flaws in the original GAN objective function and the complex dynamics of adversarial training became the primary motivation for a concerted research effort, leading to the development of alternative objective functions, sophisticated regularization techniques, and novel architectural designs that would transform GANs into more robust and powerful generative models, which will be explored in subsequent sections.